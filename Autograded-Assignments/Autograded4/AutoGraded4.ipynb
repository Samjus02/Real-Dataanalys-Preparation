{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d499fe",
   "metadata": {
    "deletable": false
   },
   "source": [
    "\n",
    "# Assignment 4 for Course 1MS041\n",
    "Make sure you pass the `# ... Test` cells and\n",
    " submit your solution notebook in the corresponding assignment on the course website. You can submit multiple times before the deadline and your highest score will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400f8d9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "---\n",
    "## Assignment 4, PROBLEM 1\n",
    "Maximum Points = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1585d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "source": [
    "\n",
    "    This time the assignment only consists of one problem, but we will do a more comprehensive analysis instead.\n",
    "\n",
    "Consider the dataset `Corona_NLP_train.csv` that you can get from the course website [git](https://github.com/datascience-intro/1MS041-2024/blob/main/notebooks/data/Corona_NLP_train.csv). The data is \"Coronavirus tweets NLP - Text Classification\" that can be found on [kaggle](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification). The data has several columns, but we will only be working with `OriginalTweet`and `Sentiment`.\n",
    "\n",
    "1. [3p] Load the data and filter out those tweets that have `Sentiment`=`Neutral`. Let $X$ represent the `OriginalTweet` and let \n",
    "    $$\n",
    "        Y = \n",
    "        \\begin{cases}\n",
    "        1 & \\text{if sentiment is towards positive}\n",
    "        \\\\\n",
    "        0 & \\text{if sentiment is towards negative}.\n",
    "        \\end{cases}\n",
    "    $$\n",
    "    Put the resulting arrays into the variables $X$ and $Y$. Split the data into three parts, train/test/validation where train is 60% of the data, test is 15% and validation is 25% of the data. Do not do this randomly, this is to make sure that we all did the same splits (we are in this case assuming the data is IID as presented in the dataset). That is [train,test,validation] is the splitting layout.\n",
    "\n",
    "2. [4p] There are many ways to solve this classification problem. The first main issue to resolve is to convert the $X$ variable to something that you can feed into a machine learning model. For instance, you can first use [`CountVectorizer`](https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) as the first step. The step that comes after should be a `LogisticRegression` model, but for this to work you need to put together the `CountVectorizer` and the `LogisticRegression` model into a [`Pipeline`](https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline). Fill in the variable `model` such that it accepts the raw text as input and outputs a number $0$ or $1$, make sure that `model.predict_proba` works for this. **Hint: You might need to play with the parameters of LogisticRegression to get convergence, make sure that it doesn't take too long or the autograder might kill your code**\n",
    "3. [3p] Use your trained model and calculate the precision and recall on both classes. Fill in the corresponding variables with the answer.\n",
    "4. [3p] Let us now define a cost function\n",
    "    * A positive tweet that is classified as negative will have a cost of 1\n",
    "    * A negative tweet that is classified as positive will have a cost of 5\n",
    "    * Correct classifications cost 0\n",
    "    \n",
    "    complete filling the function `cost` to compute the cost of a prediction model under a certain prediction threshold (recall our precision recall lecture and the `predict_proba` function from trained models). \n",
    "\n",
    "5. [4p] Now, we wish to select the threshold of our classifier that minimizes the cost, fill in the selected threshold value in value `optimal_threshold`.\n",
    "6. [4p] With your newly computed threshold value, compute the cost of putting this model in production by computing the cost using the validation data. Also provide a confidence interval of the cost using Hoeffdings inequality with a 99% confidence.\n",
    "7. [3p] Let $t$ be the threshold you found and $f$ the model you fitted (one of the outputs of `predict_proba`), if we define the random variable\n",
    "    $$\n",
    "        C = (1-1_{f(X)\\geq t})Y+5(1-Y)1_{f(X) \\geq t}\n",
    "    $$\n",
    "    then $C$ denotes the cost of a randomly chosen tweet. In the previous step we estimated $\\mathbb{E}[C]$ using the empirical mean. However, since the threshold is chosen to minimize cost it is likely that $C=0$ or $C=1$ than $C=5$ as such it will have a low variance. Compute the empirical variance of $C$ on the validation set. What would be the confidence interval if we used Bennett's inequality instead of Hoeffding in point 6 but with the computed empirical variance as our guess for the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9af1d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. [3p] — Goal of Part 1\n",
    "\n",
    "We are asked to:\n",
    "\n",
    "1. Load the dataset `Corona_NLP_train.csv` using the fixed path  \n",
    "   `../data/Corona_NLP_train.csv`.\n",
    "\n",
    "2. Filter out rows where the column `Sentiment` is equal to `\"Neutral\"`.  \n",
    "   Keep all other rows.\n",
    "\n",
    "3. Create a binary response variable $Y$ defined by  \n",
    "\n",
    "   $$\n",
    "   Y =\n",
    "   \\begin{cases}\n",
    "   1 & \\text{if sentiment is towards positive},\\\\\n",
    "   0 & \\text{if sentiment is towards negative}.\n",
    "   \\end{cases}\n",
    "   $$\n",
    "\n",
    "   In the original dataset there are five sentiment levels:\n",
    "\n",
    "   - Positive  \n",
    "   - Extremely Positive  \n",
    "   - Negative  \n",
    "   - Extremely Negative  \n",
    "   - Neutral  \n",
    "\n",
    "   Here, \"towards positive\" means `Positive` or `Extremely Positive`,  \n",
    "   and \"towards negative\" means `Negative` or `Extremely Negative`.\n",
    "\n",
    "4. Let\n",
    "\n",
    "   - $X$ be the array containing the text from the column `OriginalTweet`,  \n",
    "   - $Y$ be the array containing the binary labels defined above.\n",
    "\n",
    "   Both $X$ and $Y$ should be NumPy arrays of shape $(n_{\\text{samples}},)$.\n",
    "\n",
    "5. Split the filtered data **without randomness**, in the order that the\n",
    "   observations appear in the CSV file, into three parts:\n",
    "\n",
    "   - 60% $\\rightarrow$ train  \n",
    "   - 15% $\\rightarrow$ test  \n",
    "   - 25% $\\rightarrow$ validation  \n",
    "\n",
    "   If the total number of observations after removing neutrals is $N$, then\n",
    "\n",
    "   $$\n",
    "   N_{\\text{train}} = \\lfloor 0.6N \\rfloor,\n",
    "   $$\n",
    "   $$\n",
    "   N_{\\text{test}} = \\lfloor 0.15N \\rfloor,\n",
    "   $$\n",
    "   $$\n",
    "   N_{\\text{valid}} = N - N_{\\text{train}} - N_{\\text{test}}.\n",
    "   $$\n",
    "\n",
    "   The corresponding splits for $X$ (and similarly for $Y$) are:\n",
    "\n",
    "   - training set: $X[0 : N_{\\text{train}}]$  \n",
    "   - test set: $X[N_{\\text{train}} : N_{\\text{train}} + N_{\\text{test}}]$  \n",
    "   - validation set: the remaining part  \n",
    "     $X[N_{\\text{train}} + N_{\\text{test}} : ]$.\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-step reasoning\n",
    "\n",
    "1. Load the dataset with `pandas.read_csv` using the specified path.\n",
    "\n",
    "2. Remove all rows where `Sentiment == \"Neutral\"` so that only\n",
    "   clearly positive or negative tweets remain.\n",
    "\n",
    "3. Extract the column `OriginalTweet` and store it as a NumPy array.\n",
    "   This array will be $X$ and should have shape $(n_{\\text{samples}},)$.\n",
    "\n",
    "4. Convert the sentiment strings into numerical labels:\n",
    "\n",
    "   - If the sentiment string contains `\"Positive\"` (either `Positive`\n",
    "     or `Extremely Positive`), set the corresponding $Y$ value to $1$.\n",
    "   - If the sentiment string contains `\"Negative\"` (either `Negative`\n",
    "     or `Extremely Negative`), set the corresponding $Y$ value to $0$.\n",
    "\n",
    "5. Compute $N_{\\text{train}}$, $N_{\\text{test}}$ and $N_{\\text{valid}}$\n",
    "   using the formulas above.\n",
    "\n",
    "6. Use slicing on the arrays $X$ and $Y$ to obtain the three parts\n",
    "   (train, test and validation) in the correct proportions and order.\n",
    "\n",
    "7. Assign the resulting slices to the variables\n",
    "\n",
    "   - `X_train`, `Y_train`  \n",
    "   - `X_test`, `Y_test`  \n",
    "   - `X_valid`, `Y_valid`\n",
    "\n",
    "   keeping all of them as NumPy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e6fa33",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 1\n",
    "\n",
    "# Load the data from the file specified in the problem definition and make sure that it is loaded using\n",
    "# the search path `data/Corona_NLP_train.csv`. This is to make sure the autograder and your computer have the same\n",
    "# file path and can load the data correctly.\n",
    "\n",
    "# Contrary to how many other problems are structured, this problem actually requires you to\n",
    "# have X on the shape (n_samples, ) that is a 1-dimensional array. Otherwise it will cause a bunch\n",
    "# of errors in the autograder or also in for instance CountVectorizer.\n",
    "\n",
    "# Make sure that all your data is numpy arrays and not pandas dataframes or series.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "# print(os.listdir())\n",
    "\n",
    "# Loading the file\n",
    "# The dataset contains non-UTF8 characters (e.g. accented letters, emojis),\n",
    "# which cause pandas to raise a UnicodeDecodeError when using default UTF-8.\n",
    "# Therefore we specify encoding=\"latin1\", which can read these characters safely.\n",
    "data = pd.read_csv(\"data/Corona_NLP_train.csv\", encoding=\"latin1\")\n",
    "\n",
    "\n",
    "\n",
    "# Remove Neutral sentiments\n",
    "data = data[data[\"Sentiment\"] != \"Neutral\"]\n",
    "\n",
    "# Extract X as numpy array of strings\n",
    "X = data[\"OriginalTweet\"].values\n",
    "\n",
    "# Convert Sentiment → binary Y\n",
    "Y = np.where(\n",
    "    data[\"Sentiment\"].str.contains(\"Positive\"), \n",
    "    1, \n",
    "    0\n",
    ")\n",
    "\n",
    "# Determine split sizes\n",
    "N = len(X)\n",
    "N_train = int(0.60 * N)\n",
    "N_test = int(0.15 * N)\n",
    "N_valid = N - N_train - N_test\n",
    "\n",
    "# Deterministic split\n",
    "X_train = X[:N_train]\n",
    "Y_train = Y[:N_train]\n",
    "\n",
    "X_test = X[N_train:N_train + N_test]\n",
    "Y_test = Y[N_train:N_train + N_test]\n",
    "\n",
    "X_valid = X[N_train + N_test:]\n",
    "Y_valid = Y[N_train + N_test:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a915e968",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. [ ?p ] — Training a Sentiment Classification Model\n",
    "\n",
    "After removing all tweets with `Sentiment = \"Neutral\"`, we now want to train a\n",
    "machine learning model that can predict the binary sentiment variable\n",
    "\n",
    "$$\n",
    "Y =\n",
    "\\begin{cases}\n",
    "1 & \\text{if the sentiment is towards positive},\\\\[6pt]\n",
    "0 & \\text{if the sentiment is towards negative}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The input to the model is the array $X$, which contains **raw tweet strings**.\n",
    "Since machine learning algorithms cannot operate directly on text, we first need\n",
    "to convert each tweet into a numerical representation.\n",
    "\n",
    "### **Vectorization of Text**\n",
    "We use a **TF–IDF vectorizer**, which transforms each tweet into a vector that\n",
    "measures how important each word is compared to the full dataset.  \n",
    "Mathematically, TF–IDF assigns each token $t$ in document $d$ a weight:\n",
    "\n",
    "$$\n",
    "\\text{tfidf}(t,d) = \\text{tf}(t,d) \\cdot \\log\\left( \\frac{N}{\\text{df}(t)} \\right),\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $\\text{tf}(t,d)$ is the term frequency of token $t$ in tweet $d$,  \n",
    "- $\\text{df}(t)$ is the number of tweets containing $t$,  \n",
    "- $N$ is the total number of tweets.\n",
    "\n",
    "This converts $X$ into a numerical matrix suitable for machine learning.\n",
    "\n",
    "### **Classifier**\n",
    "We use **Logistic Regression**, a standard model for binary outcomes:\n",
    "\n",
    "$$\n",
    "P(Y=1 \\mid x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta^\\top x)}}.\n",
    "$$\n",
    "\n",
    "The classifier learns coefficients $\\beta$ that best separate positive from\n",
    "negative tweets.\n",
    "\n",
    "### **Pipeline**\n",
    "Because the autograder will call the model directly on raw strings (not\n",
    "preprocessed text), we must combine both steps:\n",
    "\n",
    "1. TF–IDF vectorizer  \n",
    "2. Logistic Regression classifier  \n",
    "\n",
    "into a single object:\n",
    "\n",
    "$$\n",
    "\\text{model} = \\text{Vectorizer} \\circ \\text{Classifier}.\n",
    "$$\n",
    "\n",
    "This ensures that calling\n",
    "\n",
    "```python\n",
    "model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078fe203",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()),\n",
       "                (&#x27;logreg&#x27;, LogisticRegression(max_iter=1000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('steps',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">steps&nbsp;</td>\n",
       "            <td class=\"value\">[(&#x27;tfidf&#x27;, ...), (&#x27;logreg&#x27;, ...)]</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('transform_input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">transform_input&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('memory',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">memory&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"tfidf__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.float64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('norm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">norm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('use_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">use_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('smooth_idf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">smooth_idf&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sublinear_tf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sublinear_tf&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"logreg__\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">penalty&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;l2&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dual&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">C&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">intercept_scaling&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">solver&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_class',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_class&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">l1_ratio&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                ('logreg', LogisticRegression(max_iter=1000))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Part 2\n",
    "\n",
    "# Train a machine learning model or pipeline that can take the raw strings from X and predict Y=0,1 depending on the\n",
    "# sentiment of the tweet. Store the trained model in the variable `model`.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# We create a scikit-learn Pipeline so that:\n",
    "# - The vectorizer transforms raw text into numeric features.\n",
    "# - The classifier learns to predict Y = 0 or 1.\n",
    "# Using a pipeline ensures that `model.predict(X)` works directly on raw tweets,\n",
    "# which is required by the autograder (it will not provide pre-vectorized input).\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()),         # Step 1: convert text → TF-IDF matrix\n",
    "    (\"logreg\", LogisticRegression(\n",
    "        max_iter=1000                     # Increase iterations to ensure convergence\n",
    "    ))                                    # Step 2: logistic regression classifier\n",
    "])\n",
    "\n",
    "# Train the model using the training split\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07405551",
   "metadata": {},
   "source": [
    "3. [3p] Use your trained model and calculate the precision and recall on both classes. Fill in the corresponding variables with the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04e63",
   "metadata": {},
   "source": [
    "## 3. [3p] — Precision and Recall for Both Classes\n",
    "\n",
    "Once the model has been trained, we evaluate its performance on the **test set**\n",
    "using two important classification metrics: **precision** and **recall**.\n",
    "\n",
    "The model predicts a binary label  \n",
    "$\\hat{Y} \\in \\{0,1\\}$   \n",
    "based on the raw input text in `X_test`.\n",
    "\n",
    "### **Precision**\n",
    "\n",
    "Precision measures how many predicted positives (or negatives) were actually correct.\n",
    "\n",
    "For class 1 (positive sentiment):\n",
    "\n",
    "$$\n",
    "\\text{Precision}_1 =\n",
    "\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}.\n",
    "$$\n",
    "\n",
    "For class 0 (negative sentiment):\n",
    "\n",
    "$$\n",
    "\\text{Precision}_0 =\n",
    "\\frac{\\text{True Negatives}}{\\text{True Negatives} + \\text{False Negatives}}.\n",
    "$$\n",
    "\n",
    "### **Recall**\n",
    "\n",
    "Recall measures how many actual positives (or negatives) we correctly found.\n",
    "\n",
    "For class 1:\n",
    "\n",
    "$$\n",
    "\\text{Recall}_1 =\n",
    "\\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}.\n",
    "$$\n",
    "\n",
    "For class 0:\n",
    "\n",
    "$$\n",
    "\\text{Recall}_0 =\n",
    "\\frac{\\text{True Negatives}}{\\text{True Negatives} + \\text{False Positives}}.\n",
    "$$\n",
    "\n",
    "### **How we compute the metrics**\n",
    "\n",
    "We:\n",
    "\n",
    "1. Use the trained model to generate predictions  \n",
    "   $$\\hat{Y} = \\text{model.predict}(X_{\\text{test}}).$$\n",
    "\n",
    "2. Call `precision_score` and `recall_score` from scikit-learn.\n",
    "\n",
    "3. We compute the scores **separately for each class** by specifying  \n",
    "   `pos_label=1` or `pos_label=0`.\n",
    "\n",
    "4. Store the resulting values in the variables:\n",
    "\n",
    "- `precision_0`, `precision_1`  \n",
    "- `recall_0`, `recall_1`\n",
    "\n",
    "as required by the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6fd1d4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 3\n",
    "\n",
    "# Evaluate the model on the test set and calculate precision, and recall on both classes. Store the results in the\n",
    "# variables `precision_0`, `precision_1`, `recall_0`, `recall_1`.\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Predict labels on the test set\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Precision for class 0 (negative sentiment)\n",
    "# pos_label=0 means we treat class 0 as the \"positive\" class in the formula,\n",
    "# making precision_0 = TN / (TN + FN)\n",
    "precision_0 = precision_score(Y_test, Y_pred, pos_label=0)\n",
    "\n",
    "# Precision for class 1 (positive sentiment)\n",
    "precision_1 = precision_score(Y_test, Y_pred, pos_label=1)\n",
    "\n",
    "# Recall for class 0 (negative sentiment)\n",
    "# recall_0 = TN / (TN + FP)\n",
    "recall_0 = recall_score(Y_test, Y_pred, pos_label=0)\n",
    "\n",
    "# Recall for class 1\n",
    "recall_1 = recall_score(Y_test, Y_pred, pos_label=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bf3d2",
   "metadata": {},
   "source": [
    "4. [3p] Let us now define a cost function\n",
    "    * A positive tweet that is classified as negative will have a cost of 1\n",
    "    * A negative tweet that is classified as positive will have a cost of 5\n",
    "    * Correct classifications cost 0\n",
    "    \n",
    "    complete filling the function `cost` to compute the cost of a prediction model under a certain prediction threshold (recall our precision recall lecture and the `predict_proba` function from trained models). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b1535",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. [3p] — Defining a Cost Function Using Thresholded Predictions\n",
    "\n",
    "In this part we introduce a cost function that assigns different penalties\n",
    "depending on the type of misclassification the model makes.  \n",
    "We let the response variable take values\n",
    "\n",
    "$$\n",
    "Y \\in \\{0,1\\},\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $Y = 1$ means **positive sentiment**,  \n",
    "- $Y = 0$ means **negative sentiment**.\n",
    "\n",
    "### Probability-based decision rule\n",
    "\n",
    "The trained model can estimate the probability that a tweet has positive\n",
    "sentiment:\n",
    "\n",
    "$$\n",
    "p(x) = P(Y = 1 \\mid x).\n",
    "$$\n",
    "\n",
    "In scikit-learn this is obtained using\n",
    "\n",
    "model.predict_proba(X)\n",
    "\n",
    "\n",
    "\n",
    "This returns two columns:\n",
    "\n",
    "- column 0: $( P(Y = 0 \\mid x))$\n",
    "- column 1: $( P(Y = 1 \\mid x))$\n",
    "\n",
    "## Decision rule using a threshold\n",
    "\n",
    "We classify a tweet as **positive** if\n",
    "\n",
    "$$p(x) \\ge \\text{threshold},$$\n",
    "\n",
    "and classify it as **negative** otherwise.\n",
    "\n",
    "This generalizes the Bayes classifier from the lecture, where the threshold was \\( 0.5 \\) when misclassification costs were equal.\n",
    "\n",
    "---\n",
    "\n",
    "## Cost structure\n",
    "\n",
    "We now assign different penalties:\n",
    "\n",
    "1. A positive tweet that is classified as negative will have a cost of **1**.  \n",
    "2. A negative tweet that is classified as positive will have a cost of **5**.  \n",
    "3. Correct classifications cost **0**.\n",
    "\n",
    "Formally, for each observation,\n",
    "\n",
    "$$\n",
    "\\text{cost}(Y, \\hat{Y}) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } Y = 1 \\text{ and } \\hat{Y} = 0, \\\\\n",
    "5 & \\text{if } Y = 0 \\text{ and } \\hat{Y} = 1, \\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "The function `cost(model, threshold, X, Y)` should:\n",
    "\n",
    "1. Use `model.predict_proba(X)` to get the probabilities $( p(x) = P(Y = 1 \\mid x) )$ .\n",
    "\n",
    "2. Convert these probabilities into predictions using the given threshold  \n",
    "   (predict 1 if $( p(x) \\ge \\text{threshold} )$, otherwise 0).\n",
    "\n",
    "3. Compute the costs:\n",
    "   - cost **1** for false negatives (true $(Y = 1)$, predicted 0),\n",
    "   - cost **5** for false positives (true $(Y = 0)$, predicted 1),\n",
    "   - cost **0** otherwise.\n",
    "\n",
    "4. Compute the **average cost** over all observations and return it.\n",
    "\n",
    "The average cost is\n",
    "\n",
    "$$\n",
    "\\text{AverageCost} = \\frac{1}{N} \\sum_{i=1}^N \\text{cost}(Y_i, \\hat{Y}_i).\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10698374",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Part 4\n",
    "\n",
    "def cost(model,threshold,X,Y):\n",
    "    # Hint, make sure that the model has a predict_proba method\n",
    "    # think about how the decision is made based on the probabilities\n",
    "    # and how the threshold can be used to make the decision.\n",
    "    # For reference take a look at the lecture notes \"Bayes classifier\"\n",
    "    # which contains how the decision is made based on the probabilities when the threshold is 0.5.\n",
    "    \n",
    "    # Fill in what is missing to compute the cost and return it\n",
    "    # Note that we are interested in average cost\n",
    "    \n",
    "\n",
    "\n",
    "    # We need class probabilities to make threshold-based decisions.\n",
    "    # predict_proba returns an array of shape (n_samples, 2)\n",
    "    # where column 1 is P(Y=1 | x).\n",
    "    probs = model.predict_proba(X)[:, 1]  # probability of class 1 (positive)\n",
    "    \n",
    "    # Apply the decision rule:\n",
    "    # predict positive (1) if prob >= threshold, otherwise negative (0)\n",
    "    Y_pred = (probs >= threshold).astype(int)\n",
    "    \n",
    "    # Compute costs:\n",
    "    # False negative (Y=1, Y_pred=0) --> cost 1\n",
    "    fn_cost = (Y == 1) & (Y_pred == 0)\n",
    "    \n",
    "    # False positive (Y=0, Y_pred=1) --> cost 5\n",
    "    fp_cost = (Y == 0) & (Y_pred == 1)\n",
    "    \n",
    "    # Total cost per observation\n",
    "    costs = 1 * fn_cost + 5 * fp_cost\n",
    "    \n",
    "    # Return average cost\n",
    "    return costs.mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8eca5",
   "metadata": {},
   "source": [
    "5. [4p] Now, we wish to select the threshold of our classifier that minimizes the cost, fill in the selected threshold value in value `optimal_threshold`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014d9ba7",
   "metadata": {},
   "source": [
    "## 5. [4p]\n",
    "\n",
    "In this part we want to choose the threshold of our classifier that **minimizes the expected cost** on the test set.  \n",
    "Our logistic regression model produces estimated posterior probabilities\n",
    "\n",
    "$$\n",
    "p(x) = P(Y = 1 \\mid x),\n",
    "$$\n",
    "\n",
    "and we classify an observation as belonging to class 1 when  \n",
    "$( p(x) \\ge t )$, where $( t )$ is the decision threshold.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Understanding the Cost Function\n",
    "\n",
    "We are given the following misclassification costs:\n",
    "\n",
    "- False negative (predict 0 when $(Y=1)$):\n",
    "  $$\n",
    "  c_{\\text{FN}} = 1\n",
    "  $$\n",
    "\n",
    "- False positive (predict 1 when $(Y=0)$):\n",
    "  $$\n",
    "  c_{\\text{FP}} = 5\n",
    "  $$\n",
    "\n",
    "Thus, the classifier must be more cautious before predicting class 1, because false positives are much more expensive.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Conditional Risk for Each Decision\n",
    "\n",
    "For a fixed observation $(x)$, the model estimates\n",
    "\n",
    "$$\n",
    "p(x) = P(Y=1 \\mid x), \\qquad 1 - p(x) = P(Y=0 \\mid x).\n",
    "$$\n",
    "\n",
    "If we **predict class 1**, the conditional expected cost is\n",
    "\n",
    "$$\n",
    "R(1 \\mid x) = c_{\\text{FP}} \\cdot P(Y=0 \\mid x)\n",
    "= 5 (1 - p(x)).\n",
    "$$\n",
    "\n",
    "If we **predict class 0**, the conditional expected cost is\n",
    "\n",
    "$$\n",
    "R(0 \\mid x) = c_{\\text{FN}} \\cdot P(Y=1 \\mid x)\n",
    "= 1 \\cdot p(x).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3: Deriving the Optimal Theoretical Threshold\n",
    "\n",
    "The Bayes classifier chooses the class with the smaller conditional risk:\n",
    "\n",
    "$$\n",
    "\\text{Predict 1 if } R(1 \\mid x) < R(0 \\mid x).\n",
    "$$\n",
    "\n",
    "Insert the formulas:\n",
    "\n",
    "$$\n",
    "5(1 - p(x)) < p(x).\n",
    "$$\n",
    "\n",
    "Solve for \\( p(x) \\):\n",
    "\n",
    "$$\n",
    "5 - 5p(x) < p(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "5 < 6p(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x) > \\frac{5}{6}.\n",
    "$$\n",
    "\n",
    "Thus, the **Bayes-optimal threshold** is\n",
    "\n",
    "$$\n",
    "t^* = \\frac{5}{6} \\approx 0.8333.\n",
    "$$\n",
    "\n",
    "This means that, to minimize expected cost, we should only classify a tweet as positive when the models probability exceeds approximately $(0.83)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4: Empirical Optimization on the Test Set\n",
    "\n",
    "Although the theoretical value is $(t^* = 5/6)$, in practice we estimate the optimal threshold by **minimizing the empirical average cost** on the test set.\n",
    "\n",
    "For a given threshold $(t)$:\n",
    "\n",
    "- Predict 1 if  \n",
    "  $$\n",
    "  p(x) \\ge t,\n",
    "  $$\n",
    "- Predict 0 otherwise.\n",
    "\n",
    "The cost for each observation is\n",
    "\n",
    "- $(1)$ if it is a false negative,\n",
    "- $(5)$ if it is a false positive,\n",
    "- $(0)$ if correctly classified,\n",
    "\n",
    "and the **average cost** is computed over all test samples.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 5: Search Over Threshold Values\n",
    "\n",
    "To find the threshold with minimal test-set cost, we evaluate the empirical average cost for a sequence of thresholds\n",
    "\n",
    "$$\n",
    "t \\in \\{0.0, 0.001, 0.002, \\ldots, 1.0\\}.\n",
    "$$\n",
    "\n",
    "For each $(t)$ we compute\n",
    "\n",
    "$$\n",
    "\\widehat{C}(t)\n",
    "$$\n",
    "\n",
    "and choose the threshold that yields\n",
    "\n",
    "$$\n",
    "\\min_{t \\in [0,1]} \\ \\widehat{C}(t).\n",
    "$$\n",
    "\n",
    "This empirical minimizer is stored in\n",
    "\n",
    "- `optimal_threshold`\n",
    "- `cost_at_optimal_threshold`\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Theoretical decision rule:\n",
    "\n",
    "  $$\n",
    "  t^* = \\frac{5}{6}.\n",
    "  $$\n",
    "\n",
    "- Practical decision rule:\n",
    "\n",
    "  Evaluate the cost on the test set for many thresholds  \n",
    "  and choose the one that gives the smallest average cost.\n",
    "\n",
    "This ensures that the classifier is tuned specifically to minimize the given misclassification costs on the real data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b21963ec",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold:  0.677\n",
      "Cost at optimal threshold:  0.3066188197767145\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 5\n",
    "\n",
    "# Find the optimal threshold for the model on the test set. Store the threshold in the variable `optimal_threshold`\n",
    "# and the cost at the optimal threshold in the variable `cost_at_optimal_threshold` evaluated on the test set.\n",
    "\n",
    "\n",
    "\n",
    "# Create a grid of thresholds between 0 and 1\n",
    "thresholds = np.linspace(0.0, 1.0, 1001)  # step size 0.001\n",
    "\n",
    "# Compute the cost for each threshold on the test set\n",
    "costs = np.array([cost(model, t, X_test, Y_test) for t in thresholds])\n",
    "\n",
    "# Find the index of the minimum cost\n",
    "best_idx = np.argmin(costs)\n",
    "\n",
    "# Extract the optimal threshold and the corresponding cost\n",
    "optimal_threshold = thresholds[best_idx]\n",
    "cost_at_optimal_threshold = costs[best_idx]\n",
    "\n",
    "print(\"Optimal Threshold: \", optimal_threshold)\n",
    "print(\"Cost at optimal threshold: \", cost_at_optimal_threshold)\n",
    "#optimal_threshold, cost_at_optimal_threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838afd9f",
   "metadata": {},
   "source": [
    "6. [4p] With your newly computed threshold value, compute the cost of putting this model in production by computing the cost using the validation data. Also provide a confidence interval of the cost using Hoeffdings inequality with a 99% confidence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c9fdd0",
   "metadata": {},
   "source": [
    "## 6. [4p]\n",
    "\n",
    "In this part we evaluate how well our chosen threshold would perform **when the model is deployed in production**.  \n",
    "To simulate this, we use the **validation dataset**, which was not involved in training or threshold selection.\n",
    "\n",
    "We compute two things:\n",
    "\n",
    "1. The **empirical cost** on the validation set using the optimal threshold obtained in Part 5.\n",
    "2. A **99% confidence interval** for this cost using **Hoeffding's inequality**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1: Cost on the Validation Set\n",
    "\n",
    "Given the optimal threshold $t^*$ found earlier, we compute\n",
    "\n",
    "$$\n",
    "\\widehat{C}_{\\text{valid}} = \\frac{1}{n} \\sum_{i=1}^n Z_i,\n",
    "$$\n",
    "\n",
    "where $Z_i$ is the cost incurred for the $i$th validation observation:\n",
    "\n",
    "- $Z_i = 1$ for a false negative  \n",
    "- $Z_i = 5$ for a false positive  \n",
    "- $Z_i = 0$ for a correct prediction\n",
    "\n",
    "The function $cost(model, t^*, X_{\\text{valid}}, Y_{\\text{valid}})$ returns exactly this empirical mean.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2: Confidence Interval Using Hoeffding's Inequality\n",
    "\n",
    "Let $\\widehat{C}$ be the empirical cost and assume that each cost value $Z_i$ is bounded:\n",
    "\n",
    "$$\n",
    "0 \\le Z_i \\le 5.\n",
    "$$\n",
    "\n",
    "Hoeffding’s inequality states that with probability at least $1 - \\delta$,\n",
    "\n",
    "$$\n",
    "\\left| \\widehat{C} - C \\right| \\le (b - a) \\sqrt{\\frac{\\ln(2/\\delta)}{2n}},\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $a = 0$ (minimum cost per observation)  \n",
    "- $b = 5$ (maximum cost per observation)  \n",
    "- $n$ is the validation set size  \n",
    "- $\\delta = 0.01$ for a 99% confidence interval\n",
    "\n",
    "Thus the radius of the interval is\n",
    "\n",
    "$$\n",
    "\\epsilon = 5 \\sqrt{\\frac{\\ln(2 / 0.01)}{2n}}.\n",
    "$$\n",
    "\n",
    "The 99% confidence interval for the true expected cost $C$ is\n",
    "\n",
    "$$\n",
    "\\left( \\widehat{C} - \\epsilon,\\; \\widehat{C} + \\epsilon \\right).\n",
    "$$\n",
    "\n",
    "This gives an interval guaranteed by Hoeffding's inequality to contain the true cost with confidence at least 99%.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "- Compute empirical cost on the validation set using $t^*$:\n",
    "\n",
    "  $$\n",
    "  \\widehat{C}_{\\text{valid}} = \\text{cost}(model, t^*, X_{\\text{valid}}, Y_{\\text{valid}}).\n",
    "  $$\n",
    "\n",
    "- Compute Hoeffding radius:\n",
    "\n",
    "  $$\n",
    "  \\epsilon = 5 \\sqrt{\\frac{\\ln(200)}{2n}}.\n",
    "  $$\n",
    "\n",
    "- Report the confidence interval:\n",
    "\n",
    "  $$\n",
    "  (\\widehat{C}_{\\text{valid}} - \\epsilon,\\; \\widehat{C}_{\\text{valid}} + \\epsilon).\n",
    "  $$\n",
    "\n",
    "This provides a statistically justified estimate of how the model is expected to perform when deployed in practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a1c5e6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at optimal threshold valid:  0.32241090648170295\n",
      "cost interval valid:  (np.float64(0.23341522986171315), np.float64(0.41140658310169276))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 6\n",
    "\n",
    "# Compute cost on the validation set using the optimal threshold\n",
    "cost_at_optimal_threshold_valid = cost(model, optimal_threshold, X_valid, Y_valid)\n",
    "\n",
    "# Hoeffding's inequality for 99% confidence interval\n",
    "n = len(Y_valid)\n",
    "a, b = 0, 5  # minimum and maximum possible cost per observation\n",
    "delta = 0.01\n",
    "\n",
    "# Compute epsilon (Hoeffding bound)\n",
    "epsilon = (b - a) * np.sqrt(np.log(2 / delta) / (2 * n))\n",
    "\n",
    "# Build the confidence interval\n",
    "cost_interval_valid = (cost_at_optimal_threshold_valid - epsilon, cost_at_optimal_threshold_valid + epsilon)\n",
    "\n",
    "print(\"Cost at optimal threshold valid: \", cost_at_optimal_threshold_valid)\n",
    "print(\"cost interval valid: \", cost_interval_valid)\n",
    "\n",
    "# Required by the autograder\n",
    "assert type(cost_interval_valid) == tuple\n",
    "assert len(cost_interval_valid) == 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f5319",
   "metadata": {},
   "source": [
    "7. [3p] Let $t$ be the threshold you found and $f$ the model you fitted (one of the outputs of `predict_proba`), if we define the random variable\n",
    "    $$\n",
    "        C = (1-1_{f(X)\\geq t})Y+5(1-Y)1_{f(X) \\geq t}\n",
    "    $$\n",
    "    then $C$ denotes the cost of a randomly chosen tweet. In the previous step we estimated $\\mathbb{E}[C]$ using the empirical mean. However, since the threshold is chosen to minimize cost it is likely that $C=0$ or $C=1$ than $C=5$ as such it will have a low variance. Compute the empirical variance of $C$ on the validation set. What would be the confidence interval if we used Bennett's inequality instead of Hoeffding in point 6 but with the computed empirical variance as our guess for the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b34352d",
   "metadata": {},
   "source": [
    "## 7. [3p]\n",
    "\n",
    "Let $t$ be the threshold found in the previous step and $f$ the fitted model\n",
    "(one of the outputs of `predict_proba`). Define the random variable\n",
    "\n",
    "$$\n",
    "C = (1 - 1_{\\{ f(X) \\ge t \\}})Y + 5(1 - Y)\\, 1_{\\{ f(X) \\ge t \\}}\n",
    "$$\n",
    "\n",
    "which denotes the cost of a randomly chosen tweet.\n",
    "\n",
    "### Distribution of $C$\n",
    "\n",
    "Let $I = 1_{\\{ f(X) \\ge t \\}}$.\n",
    "\n",
    "We consider the different cases depending on the true label $Y \\in \\{0,1\\}$.\n",
    "\n",
    "- If $Y = 1$ (positive tweet):\n",
    "\n",
    "  $$\n",
    "  C = (1 - I)\\cdot 1 + 5(1-1)\\cdot I = 1 - I\n",
    "  $$\n",
    "\n",
    "  - If $I = 1$ then $C = 0$ (true positive).  \n",
    "  - If $I = 0$ then $C = 1$ (false negative).\n",
    "\n",
    "- If $Y = 0$ (negative tweet):\n",
    "\n",
    "  $$\n",
    "  C = (1 - I)\\cdot 0 + 5(1-0)\\cdot I = 5I\n",
    "  $$\n",
    "\n",
    "  - If $I = 1$ then $C = 5$ (false positive).  \n",
    "  - If $I = 0$ then $C = 0$ (true negative).\n",
    "\n",
    "Thus\n",
    "\n",
    "$$\n",
    "C \\in \\{0,1,5\\}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "0 \\le C \\le 5.\n",
    "$$\n",
    "\n",
    "### Empirical mean and variance of $C$\n",
    "\n",
    "On the validation set $(X_{\\text{valid}}, Y_{\\text{valid}})$ compute\n",
    "\n",
    "$$\n",
    "p_i = f(X_i), \\qquad\n",
    "I_i = 1_{\\{ p_i \\ge t \\}}, \\qquad\n",
    "C_i = (1 - I_i)\\, Y_i + 5(1 - Y_i)\\, I_i\n",
    "$$\n",
    "\n",
    "for $i = 1, \\dots, n$ where $n = |X_{\\text{valid}}|$.\n",
    "\n",
    "The empirical mean is\n",
    "\n",
    "$$\n",
    "\\overline{C} = \\frac{1}{n}\\sum_{i=1}^n C_i\n",
    "$$\n",
    "\n",
    "which equals `cost_at_optimal_threshold_valid`.\n",
    "\n",
    "The empirical variance is\n",
    "\n",
    "$$\n",
    "\\widehat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^n (C_i - \\overline{C})^2.\n",
    "$$\n",
    "\n",
    "This is stored as `variance_of_C`.\n",
    "\n",
    "### Bennett's inequality and confidence interval\n",
    "\n",
    "Since $0 \\le C_i \\le b$ with $b = 5$, Bennett’s inequality gives\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(\n",
    "\\left|\\overline{C} - \\mathbb{E}[C]\\right| \\ge \\varepsilon\n",
    "\\right)\n",
    "\\le\n",
    "2 \\exp\\left(\n",
    "-\\frac{n\\widehat{\\sigma}^2}{b^2}\\,\n",
    "h\\!\\left( \\frac{b\\varepsilon}{\\widehat{\\sigma}^2} \\right)\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "h(u) = (1+u)\\log(1+u) - u.\n",
    "$$\n",
    "\n",
    "For a $99\\%$ confidence interval, set $\\delta = 0.01$ and solve for $\\varepsilon$ in\n",
    "\n",
    "$$\n",
    "2\\exp\\left(\n",
    "-\\frac{n\\widehat{\\sigma}^2}{b^2}\\,\n",
    "h\\!\\left( \\frac{b\\varepsilon}{\\widehat{\\sigma}^2} \\right)\n",
    "\\right)\n",
    "= \\delta.\n",
    "$$\n",
    "\n",
    "Taking logs gives\n",
    "\n",
    "$$\n",
    "h\\!\\left( \\frac{b\\varepsilon}{\\widehat{\\sigma}^2} \\right)\n",
    "=\n",
    "\\frac{b^2}{n \\widehat{\\sigma}^2}\n",
    "\\log\\left(\\frac{2}{\\delta}\\right).\n",
    "$$\n",
    "\n",
    "We solve this equation numerically to obtain $\\varepsilon_B$.\n",
    "\n",
    "Thus the Bennett 99% confidence interval is\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\overline{C} - \\varepsilon_B,\\;\n",
    "\\overline{C} + \\varepsilon_B\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "i.e.\n",
    "\n",
    "$$\n",
    "\\left[\n",
    "\\texttt{cost\\_at\\_optimal\\_threshold\\_valid} - \\varepsilon_B,\\;\n",
    "\\texttt{cost\\_at\\_optimal\\_threshold\\_valid} + \\varepsilon_B\n",
    "\\right].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3bc0760",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "4",
    "lx_assignment_type": "ASSIGNMENT",
    "lx_assignment_type2print": "Assignment",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical variance of C on validation set: 0.7303013867645695\n",
      "Bennett 99% confidence interval for E[C]: (np.float64(0.2909508033233758), np.float64(0.3538710096400301))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Part 7\n",
    "import numpy as np\n",
    "\n",
    "# Compute C on the validation set\n",
    "probs_valid = model.predict_proba(X_valid)[:, 1]\n",
    "I_valid = (probs_valid >= optimal_threshold).astype(int)\n",
    "\n",
    "# C = (1 - 1_{f(X)>=t}) * Y + 5 * (1 - Y) * 1_{f(X)>=t}\n",
    "C_valid = (1 - I_valid) * Y_valid + 5 * (1 - Y_valid) * I_valid\n",
    "\n",
    "# Empirical variance of C (population variance, denominator n)\n",
    "variance_of_C = C_valid.var()\n",
    "\n",
    "# Bennett's inequality-based confidence interval (99%)\n",
    "n = len(C_valid)\n",
    "b = 5.0\n",
    "delta = 0.01\n",
    "\n",
    "def h(u):\n",
    "    return (1.0 + u) * np.log(1.0 + u) - u\n",
    "\n",
    "def bennett_epsilon(n, var_hat, b, delta):\n",
    "    \"\"\"\n",
    "    Solve for epsilon in the two-sided Bennett inequality:\n",
    "        2 * exp( - n * var_hat / b^2 * h(b * epsilon / var_hat) ) = delta\n",
    "    using a simple binary search over epsilon in [0, b].\n",
    "    \"\"\"\n",
    "    if var_hat == 0.0:\n",
    "        # All costs are identical, no deviation\n",
    "        return 0.0\n",
    "\n",
    "    target = (b ** 2) * np.log(2.0 / delta) / (n * var_hat)\n",
    "\n",
    "    lo, hi = 0.0, b\n",
    "    for _ in range(100):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        u = b * mid / var_hat\n",
    "        val = h(u)\n",
    "        if val < target:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    return hi\n",
    "\n",
    "epsilon_B = bennett_epsilon(n, variance_of_C, b, delta)\n",
    "\n",
    "interval_of_C = (\n",
    "    cost_at_optimal_threshold_valid - epsilon_B,\n",
    "    cost_at_optimal_threshold_valid + epsilon_B\n",
    ")\n",
    "\n",
    "print(\"Empirical variance of C on validation set:\", variance_of_C)\n",
    "print(\"Bennett 99% confidence interval for E[C]:\", interval_of_C)\n",
    "\n",
    "assert(type(interval_of_C) == tuple)\n",
    "assert(len(interval_of_C) == 2)\n",
    "\n",
    "\n",
    "assert(type(interval_of_C) == tuple)\n",
    "assert(len(interval_of_C) == 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "lx_assignment_number": 4,
  "lx_course_instance": "2025",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
