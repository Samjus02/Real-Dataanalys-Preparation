{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "051cadc0",
   "metadata": {},
   "source": [
    "# Exam vB, PROBLEM 1\n",
    "Maximum Points = 14\n",
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. [4p]\n",
    "Fill in the remaining part of the function `problem1_rejection` in order to produce samples from the below density using rejection sampling:\n",
    "\n",
    "$$f[x] = C x^{0.2} (1 - x)^{1.3}$$\n",
    "\n",
    "for $0 \\le x \\le 1$, where $C$ is a value such that $f$ above is a density (i.e. integrates to one).\n",
    "\n",
    "Hint: you do not need to know the value of $C$ to perform rejection sampling.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. [2p]\n",
    "Produce 100000 samples (use fewer if it takes too long) and put the answer in `problem1_samples` from the above distribution and plot the histogram.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. [2p]\n",
    "Define $X$ as a random variable with the density given in part 1. Denote $Y = \\sin(10X)$ and use the above 100000 samples to estimate\n",
    "\n",
    "$$E[Y]$$\n",
    "\n",
    "and store the result in `problem1_expectation`.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. [2p]\n",
    "Use Hoeffdings inequality to produce a 95% confidence interval of the expectation above and store the result as a tuple in the variable `problem1_interval`.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. [4p]\n",
    "Can you calculate an approximation of the value of $C$ from part 1 using random samples? Provide a plot of the histogram from part 2 together with the true density as a curve, recall that this requires the value of $C$. Explain what method you used and what answer you got.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e7697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the necessary packages that could be necessary:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1eeb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. [4p]\n",
    "Fill in the remaining part of the function `problem1_rejection` in order to produce samples from the below density using rejection sampling:\n",
    "\n",
    "$$f[x] = C x^{0.2} (1 - x)^{1.3}$$\n",
    "\n",
    "for $0 \\le x \\le 1$, where $C$ is a value such that $f$ above is a density (i.e. integrates to one).\n",
    "\n",
    "Hint: you do not need to know the value of $C$ to perform rejection sampling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bf4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "def problem1_rejection(n_samples=1):\n",
    "    # Distribution from part 1\n",
    "    # write the code in this function to produce samples from the distribution in the assignment\n",
    "    # Return a numpy array of length n_samples\n",
    "    \n",
    "    \n",
    "    return XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "problem1_samples = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "problem1_expectation = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543140e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "problem1_interval = [XXX,XXX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e01868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "problem1_C = XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b231a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 5\n",
    "# Write your code to produce the plot here\n",
    "#XXXXXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe9465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection(10), np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_expectation, float))\n",
    "except:\n",
    "    print(\"Try again. your problem1_expectation is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_expectation is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection_2(10), np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c195bb4",
   "metadata": {},
   "source": [
    "## Exam vB, PROBLEM 2\n",
    "**Maximum Points = 13**\n",
    "\n",
    "Let us build a proportional model ($P(Y = 1 | X) = G(\\beta_0 + \\beta \\cdot X)$ where $G$ is the logistic function)\n",
    "for the spam vs not spam data. Here we assume that the features are presence vs not presence of a\n",
    "word, let $X_1, X_2, X_3$ denote the presence (1) or absence (0) of the words (“free”, “prize”, “win”).\n",
    "\n",
    "---\n",
    "\n",
    "### 1. [2p]\n",
    "Load the file `data/spam.csv` and create two numpy arrays, `problem2_X` which has\n",
    "shape $(n_{\\text{emails}}, 3)$ where each feature in `problem2_X` corresponds to\n",
    "$X_1, X_2, X_3$ from above, `problem2_Y` which has shape $(n_{\\text{emails}},)$ and\n",
    "consists of a 1 if the email is spam and 0 if it is not.\n",
    "\n",
    "Split this data into a train–calibration–test set where we have the split 40%, 20%, 40%.\n",
    "Put this data in the designated variables in the code cell.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. [4p]\n",
    "Follow the calculation from the lecture notes where we derive the logistic regression\n",
    "and implement the final loss function inside the class `ProportionalSpam`.\n",
    "You can use the Test cell to check that it gives the correct value for a test-point.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. [4p]\n",
    "Train the model `problem2_ps` on the training data.  \n",
    "The goal is to calibrate the probabilities output from the model.\n",
    "\n",
    "Start by creating a new variable `problem2_X_pred` (shape $(n_{\\text{samples}}, 1)$)\n",
    "which consists of the predictions of `problem2_ps` on the calibration dataset.\n",
    "\n",
    "Then train a calibration model using `sklearn.tree.DecisionTreeRegressor`,\n",
    "store this trained model in `problem2_calibrator`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. [3p]\n",
    "Use the trained model `problem2_ps` and the calibrator `problem2_calibrator` to make\n",
    "final predictions on the testing data, store the prediction in\n",
    "`problem2_final_predictions`.\n",
    "\n",
    "Compute the $0 - 1$ test-loss and store it in `problem2_01_loss` and provide a\n",
    "99% confidence interval of it.  \n",
    "Store this interval in the variable `problem2_interval`\n",
    "(this should again be a tuple as in Problem 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "problem2_X = XXX\n",
    "problem2_Y = XXX\n",
    "\n",
    "problem2_X_train = XXX\n",
    "problem2_X_calib = XXX\n",
    "problem2_X_test = XXX\n",
    "\n",
    "problem2_Y_train = XXX\n",
    "problem2_Y_calib = XXX\n",
    "problem2_Y_test = XXX\n",
    "\n",
    "print(problem2_X_train.shape,\n",
    "      problem2_X_calib.shape,\n",
    "      problem2_X_test.shape,\n",
    "      problem2_Y_train.shape,\n",
    "      problem2_Y_calib.shape,\n",
    "      problem2_Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6420a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "\n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self, X, Y, coeffs):\n",
    "        return XXX\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "        # Use the f above together with an optimization method from scipy\n",
    "        # to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X, Y, coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1] + 1)\n",
    "        self.result = optimize.minimize(opt_loss,\n",
    "                                        initial_arguments,\n",
    "                                        method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "            return np.round(\n",
    "                10 * G(np.dot(X, self.coeffs[1:]) + self.coeffs[0])\n",
    "            ) / 10  # This rounding is to help you with the calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8069354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3\n",
    "problem2_ps = XXX\n",
    "problem2_X_pred = XXX\n",
    "problem2_calibrator = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fef171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4\n",
    "\n",
    "# These are the predicted probabilities\n",
    "problem2_final_predictions = XXX\n",
    "\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# recall the Bayes classifier?\n",
    "problem2_01_loss = XXX\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "problem2_interval = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186dff70",
   "metadata": {},
   "source": [
    "Local Test for Exam vB, PROBLEM 2 Evaluate cell below to make sure your answer is valid.\n",
    "You should not modify anything in the cell below when evaluating it to do a local test of your\n",
    "solution. You may need to include and evaluate code snippets from lecture notebooks in cells above\n",
    "to make the local test work correctly sometimes (see error messages for clues). This is meant to\n",
    "help you become efficient at recalling materials covered in lectures that relate to this problem. Such\n",
    "local tests will generally not be available in the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db783179",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(\n",
    "        np.array([[1,0,1],[0,1,1]]),\n",
    "        np.array([1,0]),\n",
    "        np.array([1.2,0.4,0.3,0.9])\n",
    "    )\n",
    "    assert (np.abs(test_loss - 1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a991e",
   "metadata": {},
   "source": [
    "## Exam vB, PROBLEM 3\n",
    "**Maximum Points = 13**\n",
    "\n",
    "Consider the following four Markov chains, answer each question for all chains:\n",
    "![Markov chain diagrams](exam240607-markovImages.png)\n",
    "\n",
    "### 1. [2p]\n",
    "What is the transition matrix?\n",
    "\n",
    "### 2. [2p]\n",
    "Is the Markov chain irreducible?\n",
    "\n",
    "### 3. [3p]\n",
    "Is the Markov chain aperiodic?  \n",
    "What is the period for each state?\n",
    "\n",
    "Hint: Recall our definition of period:  \n",
    "Let $$T := \\{ t \\in \\mathbb{N} : P^t(x, x) > 0 \\}$$  \n",
    "and the greatest common divisor of $T$ is the period.\n",
    "\n",
    "### 4. [3p]\n",
    "Does the Markov chain have a stationary distribution, and if so, what is it?\n",
    "\n",
    "### 5. [3p]\n",
    "Is the Markov chain reversible?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 1\n",
    "#------------------------TRANSITION MATRIX -------------------------------\n",
    "# Answer each one by supplying the transition matrix as a numpy array\n",
    "# of shape (n_states,n_states), where state (A,B,...) corresponds to index (0,1,...)\n",
    "problem3_A = XXX\n",
    "problem3_B = XXX\n",
    "problem3_C = XXX\n",
    "problem3_D = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08453f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2\n",
    "#------------------------REDUCIBLE -------------------------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_irreducible = XXX\n",
    "problem3_B_irreducible = XXX\n",
    "problem3_C_irreducible = XXX\n",
    "problem3_D_irreducible = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c029c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3\n",
    "#------------------------APERIODIC-------------------------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_is_aperiodic = XXX\n",
    "problem3_B_is_aperiodic = XXX\n",
    "problem3_C_is_aperiodic = XXX\n",
    "problem3_D_is_aperiodic = XXX\n",
    "\n",
    "# Answer the following with the period of the states as a numpy array\n",
    "# of shape (n_states,)\n",
    "problem3_A_periods = XXX\n",
    "problem3_B_periods = XXX\n",
    "problem3_C_periods = XXX\n",
    "problem3_D_periods = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4\n",
    "#------------------------STATIONARY DISTRIBUTION-----------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_has_stationary = XXX\n",
    "problem3_B_has_stationary = XXX\n",
    "problem3_C_has_stationary = XXX\n",
    "problem3_D_has_stationary = XXX\n",
    "\n",
    "# Answer the following with the stationary distribution as a numpy array of shape (n_states,)\n",
    "# if the Markov chain has a stationary distribution otherwise answer with False\n",
    "problem3_A_stationary_dist = XXX\n",
    "problem3_B_stationary_dist = XXX\n",
    "problem3_C_stationary_dist = XXX\n",
    "problem3_D_stationary_dist = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 5\n",
    "#------------------------REVERSIBLE-----------------\n",
    "# Answer each one with a True or False\n",
    "problem3_A_is_reversible = XXX\n",
    "problem3_B_is_reversible = XXX\n",
    "problem3_C_is_reversible = XXX\n",
    "problem3_D_is_reversible = XXX\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
