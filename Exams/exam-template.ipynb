{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0960f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b217ac",
   "metadata": {},
   "source": [
    "PROBLEM 1: Data analysis using markov chians \n",
    "\n",
    "In this problem, you will empirically analyze a Markov chain \n",
    "with a finite state space. Transition probabilities are unknown.\n",
    "\n",
    "The state space is:\n",
    "    S = {0, 1, 2, 3}\n",
    "\n",
    "You are given the data for the observed X_t for t  = 0..19\n",
    "\n",
    "Tasks:\n",
    "1. Estimate the transition matrix P from the observed transitions.\n",
    "2. Verify that the estimated matrix is a probability transition matrix.\n",
    "3. Compute the stationary distribution pi of the chain.\n",
    "4. Simulate the chain using the estimated transition matrix\n",
    "5. Compute the expected hitting times via\n",
    "\n",
    "   (a) Simulation\n",
    "\n",
    "   (b) Solving linear equations (analytical hitting times). \n",
    "\n",
    "Compare the estimates and interpret the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a471499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# state space\n",
    "S = [0, 1, 2, 3]\n",
    "N_states = len(S)\n",
    "\n",
    "# Observed transitions: each row is (current_state, next_state)\n",
    "X_t = np.array([\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 0],\n",
    "    [0, 1],\n",
    "    [1, 1],\n",
    "    [1, 2],\n",
    "    [2, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [3, 0],\n",
    "    [0, 2],\n",
    "    [2, 1],\n",
    "    [1, 3],\n",
    "    [3, 1],\n",
    "    [1, 0],\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 2],\n",
    "    [2, 0],\n",
    "], dtype=int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c22d60",
   "metadata": {},
   "source": [
    "Below are methods that you need to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b339dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1\n",
    "import numpy as np\n",
    "\n",
    "def comp_transition_matrix(transitions, n_states):\n",
    "    \"\"\"\n",
    "    Estimate the transition matrix P from observed transitions.\n",
    "\n",
    "    Args:\n",
    "        transitions : numpy array of shape (n_samples, 2)\n",
    "                      Each row is [current_state, next_state]\n",
    "        n_states    : total number of states\n",
    "\n",
    "    Returns:\n",
    "        P_hat       : estimated transition matrix (n_states x n_states)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an empty transition matrix (all zeros)\n",
    "    P_hat = np.zeros((n_states, n_states))\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 1: Count how many times each transition occurs\n",
    "    # --------------------------------------------------\n",
    "    for row in transitions:\n",
    "        current_state = row[0]   # state at time t\n",
    "        next_state = row[1]      # state at time t+1\n",
    "\n",
    "        # Increase count for transition current_state -> next_state\n",
    "        P_hat[current_state, next_state] = P_hat[current_state, next_state] + 1\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Step 2: Normalize each row so it sums to 1\n",
    "    # (convert counts into probabilities)\n",
    "    # --------------------------------------------------\n",
    "    for i in range(n_states):\n",
    "        row_sum = np.sum(P_hat[i])\n",
    "\n",
    "        # Only normalize if we have observed outgoing transitions\n",
    "        if row_sum > 0:\n",
    "            for j in range(n_states):\n",
    "                P_hat[i, j] = P_hat[i, j] / row_sum\n",
    "        # If row_sum == 0, leave the row as zeros\n",
    "\n",
    "    return P_hat\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def is_transition_matrix(P):\n",
    "    \"\"\"\n",
    "    Check if P is a valid transition matrix.\n",
    "\n",
    "    Conditions:\n",
    "    1) P must be a square matrix\n",
    "    2) All entries must be >= 0\n",
    "    3) Each row must sum to 1 (within numerical tolerance)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check that P is a square matrix\n",
    "    n_rows, n_cols = P.shape\n",
    "    if n_rows != n_cols:\n",
    "        return False\n",
    "\n",
    "    # Loop over each row\n",
    "    for i in range(n_rows):\n",
    "\n",
    "        # Condition 1: no negative probabilities\n",
    "        for j in range(n_cols):\n",
    "            if P[i, j] < 0:\n",
    "                return False\n",
    "\n",
    "        # Condition 2: row sums to 1 (allowing small numerical errors)\n",
    "        row_sum = np.sum(P[i])\n",
    "        if not np.isclose(row_sum, 1.0):\n",
    "            return False\n",
    "\n",
    "    # If all checks passed\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Compute the stationary distribution using eigenvectors.\n",
    "\n",
    "    Uses the fact that:\n",
    "        pi^T P = pi^T\n",
    "    which means:\n",
    "        pi^T is an eigenvector of P^T with eigenvalue 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute eigenvalues and eigenvectors of P^T\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(P.T)\n",
    "\n",
    "    # Find index of eigenvalue closest to 1\n",
    "    idx = np.argmin(np.abs(eigenvalues - 1))\n",
    "\n",
    "    # Extract corresponding eigenvector\n",
    "    pi = np.real(eigenvectors[:, idx])\n",
    "\n",
    "    # Normalize so that probabilities sum to 1\n",
    "    pi = pi / np.sum(pi)\n",
    "\n",
    "    return pi\n",
    "\n",
    "def stationary_distribution2(P):\n",
    "    \"\"\"\n",
    "    Compute the stationary distribution by solving a linear system.\n",
    "\n",
    "    Solves:\n",
    "        (P^T - I) pi = 0\n",
    "    with constraint:\n",
    "        sum(pi) = 1\n",
    "    \"\"\"\n",
    "\n",
    "    n_states = P.shape[0]\n",
    "\n",
    "    # Create matrix A = P^T - I\n",
    "    A = P.T - np.eye(n_states)\n",
    "\n",
    "    # Replace last equation with sum(pi) = 1\n",
    "    A[-1, :] = 1\n",
    "\n",
    "    # Right-hand side vector\n",
    "    b = np.zeros(n_states)\n",
    "    b[-1] = 1\n",
    "\n",
    "    # Solve linear system\n",
    "    pi = np.linalg.solve(A, b)\n",
    "\n",
    "    return pi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def simulate_chain(P, start_state, n_steps):\n",
    "    \"\"\"\n",
    "    Simulate a Markov chain trajectory with a fixed random seed.\n",
    "\n",
    "    Args:\n",
    "        P           : transition matrix (n_states x n_states)\n",
    "        start_state : initial state of the chain\n",
    "        n_steps     : number of steps to simulate\n",
    "\n",
    "    Returns:\n",
    "        path        : array of visited states of length n_steps + 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Fixed random seed (DO NOT change)\n",
    "    seed = 1234\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Array to store the visited states\n",
    "    path = np.zeros(n_steps + 1, dtype=int)\n",
    "\n",
    "    # Set initial state\n",
    "    path[0] = start_state\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # Simulate the Markov chain step by step\n",
    "    # ---------------------------------------\n",
    "    for t in range(n_steps):\n",
    "        current_state = path[t]\n",
    "\n",
    "        # Sample next state according to transition probabilities\n",
    "        # P[current_state] is a probability vector over all states\n",
    "        next_state = rng.choice(len(P), p=P[current_state])\n",
    "\n",
    "        # Store next state\n",
    "        path[t + 1] = next_state\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def hitting_times_sim(P, start_state, n_sim=10_000):\n",
    "    \"\"\"\n",
    "    Estimate expected hitting times E[T_{start -> j}] for ALL states j\n",
    "    using Monte Carlo simulation.\n",
    "\n",
    "    Args:\n",
    "        P           : transition matrix\n",
    "        start_state : initial state\n",
    "        n_sim       : number of simulations\n",
    "\n",
    "    Returns:\n",
    "        est         : 1D array where est[j] is the estimated expected\n",
    "                      number of steps to hit state j from start_state\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of states\n",
    "    N_states = P.shape[0]\n",
    "\n",
    "    # Array to store estimated hitting times\n",
    "    est = np.zeros(N_states, dtype=float)\n",
    "\n",
    "    # Fixed random seed (same simulations every run)\n",
    "    seed = 1234\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Loop over all target states j\n",
    "    # --------------------------------------------------\n",
    "    for j in range(N_states):\n",
    "\n",
    "        hitting_times = []\n",
    "\n",
    "        # --------------------------------------------------\n",
    "        # Run many simulations\n",
    "        # --------------------------------------------------\n",
    "        for sim in range(n_sim):\n",
    "\n",
    "            current_state = start_state\n",
    "            t = 0\n",
    "\n",
    "            # If start_state == j, hitting time is 0\n",
    "            if current_state == j:\n",
    "                hitting_times.append(0)\n",
    "                continue\n",
    "\n",
    "            # Simulate until we hit state j\n",
    "            while True:\n",
    "                # Sample next state\n",
    "                current_state = rng.choice(N_states, p=P[current_state])\n",
    "                t += 1\n",
    "\n",
    "                if current_state == j:\n",
    "                    hitting_times.append(t)\n",
    "                    break\n",
    "\n",
    "        # Average hitting time for state j\n",
    "        est[j] = np.mean(hitting_times)\n",
    "\n",
    "    return est\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def theoretical_hitting_times(P, start_state):\n",
    "    \"\"\"\n",
    "    Compute theoretical (analytical) expected hitting times from start_state\n",
    "    to ALL target states j by solving linear systems.\n",
    "\n",
    "    Returns:\n",
    "        hit_theor: 1D array where hit_theor[j] = E[T_{start_state -> j}]\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of states\n",
    "    N_states = P.shape[0]\n",
    "\n",
    "    # Array to store theoretical hitting times for each target state j\n",
    "    hit_theor = np.full(N_states, np.nan, dtype=float)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Loop over each target state j\n",
    "    # ------------------------------------------------------------\n",
    "    for j in range(N_states):\n",
    "\n",
    "        # If target is the start state, hitting time is 0 (already there)\n",
    "        if j == start_state:\n",
    "            hit_theor[j] = 0.0\n",
    "            continue\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Build the linear system for target j\n",
    "        #\n",
    "        # For all states i != j:\n",
    "        #   h(i) = 1 + sum_k P[i,k] h(k)\n",
    "        #\n",
    "        # Move terms to left:\n",
    "        #   h(i) - sum_k P[i,k] h(k) = 1\n",
    "        #\n",
    "        # We solve this only for states != j (since h(j)=0 is known).\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        # Indices of states that are NOT the target j\n",
    "        states = [s for s in range(N_states) if s != j]\n",
    "\n",
    "        # Create matrix A and vector b for A * h = b\n",
    "        # Size: (N_states-1) x (N_states-1)\n",
    "        A = np.zeros((N_states - 1, N_states - 1))\n",
    "        b = np.ones(N_states - 1)  # right-hand side is 1's\n",
    "\n",
    "        # Fill A\n",
    "        for row_idx, i in enumerate(states):\n",
    "            for col_idx, k in enumerate(states):\n",
    "                # This represents: (I - P_restricted)\n",
    "                if i == k:\n",
    "                    A[row_idx, col_idx] = 1.0 - P[i, k]\n",
    "                else:\n",
    "                    A[row_idx, col_idx] = -P[i, k]\n",
    "\n",
    "            # Note:\n",
    "            # We do NOT include transitions to j in the unknowns, because h(j)=0.\n",
    "            # So those terms disappear automatically.\n",
    "\n",
    "        # Solve for h over states != j\n",
    "        h = np.linalg.solve(A, b)\n",
    "\n",
    "        # Extract the value corresponding to start_state\n",
    "        start_index_in_states = states.index(start_state)\n",
    "        hit_theor[j] = h[start_index_in_states]\n",
    "\n",
    "    return hit_theor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250cf14",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e017a69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Problem 1: Markov chain estimation + hitting times ===\n",
      "Estimated P_hat:\n",
      " [[0.2   0.6   0.2   0.   ]\n",
      " [0.167 0.167 0.5   0.167]\n",
      " [0.2   0.2   0.2   0.4  ]\n",
      " [0.5   0.25  0.    0.25 ]]\n",
      "Is valid transition matrix? True\n",
      "This is stationary distribution:  [0.25 0.3  0.25 0.2 ]\n",
      "\n",
      "Comparison table:\n",
      "    target_state  MC_estimate  theoretical  abs_diff\n",
      "0             0       0.0000     0.000000  0.000000\n",
      "1             1       2.0154     2.024390  0.008990\n",
      "2             2       3.2912     3.317073  0.025873\n",
      "3             3       5.6374     5.682927  0.045527\n"
     ]
    }
   ],
   "source": [
    "def problem1_main():\n",
    "    print(\"\\n=== Problem 1: Markov chain estimation + hitting times ===\")\n",
    "\n",
    "    # 1) Estimate P\n",
    "    P_hat = comp_transition_matrix(X_t, N_states)\n",
    "    print(\"Estimated P_hat:\\n\", np.round(P_hat, 3))\n",
    "\n",
    "    # 2) Validate\n",
    "    print(\"Is valid transition matrix?\", is_transition_matrix(P_hat))\n",
    "    \n",
    "    # Check stationary distribution:\n",
    "    print(\"This is stationary distribution: \", stationary_distribution(P_hat))\n",
    "\n",
    "    # 3) Expected steps from given start state to all states\n",
    "    start_state = 0\n",
    "\n",
    "    # simulation\n",
    "    mc = hitting_times_sim(P_hat, start_state=start_state, n_sim=5000)\n",
    "\n",
    "    # Theory (linear system)\n",
    "    th = theoretical_hitting_times(P_hat, start_state=start_state)\n",
    "\n",
    "    # 4) Compare\n",
    "    df = pd.DataFrame({\n",
    "        \"target_state\": np.arange(N_states),\n",
    "        \"MC_estimate\": mc,\n",
    "        \"theoretical\": th,\n",
    "        \"abs_diff\": np.abs(mc - th),\n",
    "    })\n",
    "    print(\"\\nComparison table:\\n\", df)\n",
    "    \n",
    "problem1_main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a45403",
   "metadata": {},
   "source": [
    "PROBLEM 2: Cost-Sensitive Classification\n",
    "\n",
    "You are given a binary classification problem for fraud detection.\n",
    "\n",
    "Class labels:\n",
    "\n",
    "    y = 1 => fraud\n",
    "\n",
    "    y = 0 => ok\n",
    "\n",
    "\n",
    "\n",
    "The costs of classification outcomes are:\n",
    "    TP = 0, TN = 0, FP = 100, FN = 500\n",
    "\n",
    "Tasks:\n",
    "1. Train an SVM classifier.\n",
    "2. Compute classification costs at a fixed threshold (0.5).\n",
    "3. Evaluate total cost for multiple probability thresholds.\n",
    "4. Find the threshold that minimizes total cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6371ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250243</td>\n",
       "      <td>-0.863902</td>\n",
       "      <td>-0.307019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.380736</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>-0.559577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126431</td>\n",
       "      <td>2.055912</td>\n",
       "      <td>0.973126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806991</td>\n",
       "      <td>2.104160</td>\n",
       "      <td>-0.211368</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059649</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>-0.437259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3  fraud\n",
       "0 -0.250243 -0.863902 -0.307019      0\n",
       "1 -0.380736  0.018756 -0.559577      0\n",
       "2  1.126431  2.055912  0.973126      1\n",
       "3  0.806991  2.104160 -0.211368      1\n",
       "4  0.059649  0.652374 -0.437259      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "costs = {\"TP\": 0, \"TN\": 0, \"FP\": 100, \"FN\": 500}\n",
    "\n",
    "\n",
    "def generate_fraud_table(seed=0, n=3000, fraud_rate=0.05):\n",
    "    \"\"\"\n",
    "    Generate a simple fraud dataset as a single table. The table contains:\n",
    "        - numerical features: x1, x2, x3\n",
    "        - binary target column: fraud (1 = fraud, 0 = legitimate)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Target variable\n",
    "    fraud = (rng.random(n) < fraud_rate).astype(int)\n",
    "\n",
    "    # Features\n",
    "    x1 = rng.normal(0, 1, size=n)\n",
    "    x2 = rng.normal(0, 1, size=n)\n",
    "    x3 = rng.normal(0, 1, size=n)\n",
    "\n",
    "    #  fraud cases are shifted\n",
    "    x1[fraud == 1] += 2.0\n",
    "    x2[fraud == 1] += 1.0\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": x1,\n",
    "        \"x2\": x2,\n",
    "        \"x3\": x3,\n",
    "        \"fraud\": fraud,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "fraud_data = generate_fraud_table()\n",
    "\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031231e8",
   "metadata": {},
   "source": [
    "Fill in the methods in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d03aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "def train_test_split_table(df):\n",
    "    \"\"\"\n",
    "    Split a data table into training and test sets.\n",
    "\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # implement splitting\n",
    "    # first, decide what are features and what are target \n",
    "    X = df[[\"x1\", \"x2\", \"x3\"]]\n",
    "    y = df[\"fraud\"]\n",
    "    \n",
    "    n = len(y)\n",
    "    n_train = int(n*0.8)\n",
    "    #n_test = int(n*0.2)\n",
    "    #print(\"length of y\", n)\n",
    "\n",
    "    # then split into train and test\n",
    "    X_train = X[:n_train]\n",
    "    X_test = X[n_train:] #X[n_train:n_train+n_test]\n",
    "    y_train = y[:n_train]\n",
    "    y_test = y[n_train:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def fit_linear_svm(fraud_data):\n",
    "    \"\"\"\n",
    "    Fit a linear SVM classifier.\n",
    "\n",
    "    Args: data table\n",
    "\n",
    "    Returns:\n",
    "        predicted labels of length len(y_test) \n",
    "    \"\"\"\n",
    "    # define our model\n",
    "    clf = LinearSVC(\n",
    "        C=1.0,\n",
    "        max_iter=10_000,\n",
    "        random_state=0\n",
    "    )\n",
    "\n",
    "    # split the data into trian and test:\n",
    "    X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "    #   Fit the SVM using X_train and y_train and predict the label using y_test. return y_pred\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return clf\n",
    "\n",
    "\n",
    "def confusion_counts(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes TP, TN, FP, FN.\n",
    "    \"\"\"\n",
    "    \n",
    "    #TP_est, TN_est, FP_est, FN_est = 0,0,0,0 \n",
    "    \n",
    "    TP_est = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    TN_est = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    FP_est = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    FN_est = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    return {\"TP\": TP_est, \"TN\": TN_est, \"FP\": FP_est, \"FN\": FN_est}\n",
    "\n",
    "\n",
    "def total_cost(counts):\n",
    "    \"\"\"\n",
    "    Compute total cost from confusion counts.\n",
    "\n",
    "    \"\"\"\n",
    "    # Multiply counts by costs and sum\n",
    "    tp_cost = costs[\"TP\"] * counts[\"TP\"]\n",
    "    tn_cost = costs[\"TN\"] * counts[\"TN\"]\n",
    "    fp_cost = costs[\"FP\"] * counts[\"FP\"]\n",
    "    fn_cost = costs[\"FN\"] * counts[\"FN\"]\n",
    "\n",
    "    total_cost = tp_cost + tn_cost + fp_cost + fn_cost\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# evaluate how the classification cost changes when you change the decision threshold.\n",
    "def sweep_thresholds(y_true, thresholds, X, clf):\n",
    "    \"\"\"\n",
    "    Evaluate total cost for a range of thresholds.\n",
    "    \n",
    "    Here, clf is your trained SVM classifier\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # note: here, I define y_probs to be just a decision function. Think: does it need to be calibrated to be used in this problem?\n",
    "    y_probs = clf.decision_function(X)\n",
    "\n",
    "    for t in thresholds:\n",
    "        # 1) compute the prediction for a chosen theshold\n",
    "        y_pred = (y_probs >= t).astype(int)\n",
    "\n",
    "        # 2) Confusion matrix counts  (previoulsy implemented by you)\n",
    "        counts = confusion_counts(y_true, y_pred)\n",
    "\n",
    "        # 3) Total cost (previoulsly implemented by you)\n",
    "        cost = total_cost(counts)\n",
    "\n",
    "        # 4) Store results\n",
    "        results.append({\n",
    "            \"threshold\": t,\n",
    "            \"TP\": counts[\"TP\"],\n",
    "            \"TN\": counts[\"TN\"],\n",
    "            \"FP\": counts[\"FP\"],\n",
    "            \"FN\": counts[\"FN\"],\n",
    "            \"total_cost\": cost,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12c44a4",
   "metadata": {},
   "source": [
    "When you are done, run the following cell (no need to implement anything else)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4235863e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset head:\n",
      "         x1        x2        x3  fraud\n",
      "0 -0.250243 -0.863902 -0.307019      0\n",
      "1 -0.380736  0.018756 -0.559577      0\n",
      "2  1.126431  2.055912  0.973126      1\n",
      "3  0.806991  2.104160 -0.211368      1\n",
      "4  0.059649  0.652374 -0.437259      0 \n",
      "\n",
      "Threshold sweep results:\n",
      "    threshold  TP   TN   FP  FN  total_cost\n",
      "0        -2.0  29  185  386   0       38600\n",
      "1        -1.8  29  241  330   0       33000\n",
      "2        -1.6  29  306  265   0       26500\n",
      "3        -1.4  29  387  184   0       18400\n",
      "4        -1.2  29  438  133   0       13300\n",
      "5        -1.0  29  482   89   0        8900\n",
      "6        -0.8  27  518   53   2        6300\n",
      "7        -0.6  26  537   34   3        4900\n",
      "8        -0.4  24  553   18   5        4300\n",
      "9        -0.2  19  564    7  10        5700\n",
      "10        0.0  14  566    5  15        8000\n",
      "11        0.2  12  567    4  17        8900\n",
      "12        0.4   7  568    3  22       11300\n",
      "13        0.6   3  569    2  26       13200\n",
      "14        0.8   2  571    0  27       13500\n",
      "15        1.0   1  571    0  28       14000\n",
      "16        1.2   1  571    0  28       14000\n",
      "17        1.4   0  571    0  29       14500\n",
      "18        1.6   0  571    0  29       14500\n",
      "19        1.8   0  571    0  29       14500\n",
      "20        2.0   0  571    0  29       14500\n",
      "Optimal threshold: threshold       -0.4\n",
      "TP              24.0\n",
      "TN             553.0\n",
      "FP              18.0\n",
      "FN               5.0\n",
      "total_cost    4300.0\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    df = fraud_data\n",
    "\n",
    "    print(\"Dataset head:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n",
    "    # split in train and test:\n",
    "    _, X_test, _, y_test = train_test_split_table(df)\n",
    "    # Fit linear SVM\n",
    "    clf = fit_linear_svm(df)\n",
    "\n",
    "    # thresholds\n",
    "    thresholds = np.linspace(-2.0, 2.0, 21)\n",
    "    \n",
    "    df_results = sweep_thresholds(\n",
    "        y_test,\n",
    "        thresholds,\n",
    "        X_test,\n",
    "        clf,\n",
    "    )\n",
    "\n",
    "    print(\"Threshold sweep results:\")\n",
    "    print(df_results)\n",
    "\n",
    "    # 6) Identify optimal threshold\n",
    "    best_row = df_results.loc[df_results[\"total_cost\"].idxmin()]\n",
    "    print(\"Optimal threshold:\", best_row)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f8baea",
   "metadata": {},
   "source": [
    "PROBLEM 3: Confidence estimation of the cost\n",
    "\n",
    "In Problem 2, you trained a classifier, selected a decision threshold, evaluated its performance on a test set, and computed the cost\n",
    "\n",
    "In this problem, you will quantify the uncertainty of this estimated cost. Each observation in the test set produces a cost depending on the\n",
    "classification outcome:\n",
    "\n",
    "    TN: 0\n",
    "   \n",
    "    FP: 100\n",
    "\n",
    "    TP: 0\n",
    "\n",
    "    FN: 500\n",
    "\n",
    "Thus, the cost per observation is a bounded random variable taking\n",
    "values in the interval [0, 500].\n",
    "\n",
    "Tasks:\n",
    "1. Compute the average cost per observation on the test set.\n",
    "2. Use Hoeffdingâ€™s inequality to construct a 95% confidence interval\n",
    "   for the true expected cost of the classifier.\n",
    "3. Interpret the resulting interval:\n",
    "   - What does it say about the reliability of your estimate?\n",
    "   - Is the interval likely to be tight or conservative? Why?\n",
    "\n",
    "You may assume that test observations are independent and identically\n",
    "distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfb275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cost per observation: 13.333333333333334\n",
      "95% Hoeffding CI: (0.0, np.float64(41.05546443720779))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def per_observation_cost(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Per-observation costs:\n",
    "      TN: 0, FP: 100, TP: 0, FN: 500\n",
    "    Returns: array of shape (n,)\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    costs = np.zeros_like(y_true, dtype=float)\n",
    "\n",
    "    # FP: y_true=0, y_pred=1 -> 100\n",
    "    costs[(y_true == 0) & (y_pred == 1)] = 100.0\n",
    "\n",
    "    # FN: y_true=1, y_pred=0 -> 500\n",
    "    costs[(y_true == 1) & (y_pred == 0)] = 500.0\n",
    "\n",
    "    # TP and TN stay 0\n",
    "    return costs\n",
    "\n",
    "\n",
    "def hoeffding_ci(per_obs_costs, a, b, delta=0.05):\n",
    "    \"\"\"\n",
    "    Hoeffding CI for E[C], where each C_i in [a,b].\n",
    "    Returns (lower, upper).\n",
    "    \"\"\"\n",
    "    c = np.asarray(per_obs_costs, dtype=float)\n",
    "    n = len(c)\n",
    "    mean_cost = np.mean(c)\n",
    "\n",
    "    epsilon = (b - a) * np.sqrt(np.log(2.0 / delta) / (2.0 * n))\n",
    "    lower = max(a, mean_cost - epsilon)\n",
    "    upper = min(b, mean_cost + epsilon)\n",
    "\n",
    "    return (lower, upper), mean_cost\n",
    "\n",
    "\n",
    "# Usage\n",
    "a, b = 0.0, 500.0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_table(fraud_data)\n",
    "\n",
    "clf = LinearSVC(\n",
    "    C=1.0,\n",
    "    max_iter=10_000,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "costs = per_observation_cost(y_test, y_pred)\n",
    "ci, avg_cost = hoeffding_ci(costs, a, b, delta=0.05)\n",
    "\n",
    "print(\"Average cost per observation:\", avg_cost)\n",
    "print(\"95% Hoeffding CI:\", ci)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
