{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b465e0d9",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 17th of January 2025, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40240477",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a59a3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c67547",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea1654",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "This problem is about SVD and anomaly detection. In all the problems where you are asked to produce a matrix or vector, they should be **numpy arrays**. \n",
    "\n",
    "1. [4p] Load the file `data/SVD.csv` as instructed in the code cell. Compute the Singular Value Decomposition, i.e. construct the three matrices $U$, $D$, $V$ such that if $X$ is the data matrix of shape `n_samples x n_dimensions` then $X = UDV^T$. Put the resulting matrices in their variables, check that the shapes align with the instructions in the code cell. Finally, extract the first right and left singular vectors and store those as 1-d arrays in the instructed variables.\n",
    "2. [3p] The first goal is to calculate the explained variance, check the lecture notes for definition. Calculate the explained variance of using $1$, $2$,... number of singular vectors and select how many singular vectors are needed in order to explain at least $95\\%$ of the variance.\n",
    "3. [3p] With the number of components chosen in part 2, construct the best approximating matrix with the rank as the number of components. Explain what each row represents in the approximating matrix in terms of the original data, write your answer as free text in the Markdown cell below as instructed in the cells.\n",
    "4. [4p] Create a vector which corresponds to the row-wise (Euclidean) distance between the original matrix `problem1_data`and the approximating matrix `problem1_approximation` and plot the empirical distribution function of that distance. Based on the empirical distribution function choose a threshold such that 10 samples are above it and the rest below. Store the 10 samples in the instructed variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b66e0d",
   "metadata": {},
   "source": [
    "-----\n",
    "This problem is about SVD and anomaly detection. In all the problems where you are asked to produce a matrix or vector, they should be **numpy arrays**. \n",
    "\n",
    "1. [4p] Load the file `data/SVD.csv` as instructed in the code cell. Compute the Singular Value Decomposition, i.e. construct the three matrices $U$, $D$, $V$ such that if $X$ is the data matrix of shape `n_samples x n_dimensions` then $X = UDV^T$. Put the resulting matrices in their variables, check that the shapes align with the instructions in the code cell. Finally, extract the first right and left singular vectors and store those as 1-d arrays in the instructed variables.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ea11d5a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U:  (1010, 100)\n",
      "Shape of D:  (100, 100)\n",
      "Shape of V:  (100, 100)\n"
     ]
    }
   ],
   "source": [
    "# Part 1: 4 points\n",
    "\n",
    "# Load the data from the file data/SVD.csv and store the data in a numpy array called problem1_data below\n",
    "# Double check that the numbers have been parsed correctly by checking the dtype of the array by calling problem1_data.dtype\n",
    "problem1_data = pd.read_csv(\"data/SVD.csv\", header=None).to_numpy(dtype=float)\n",
    "#print(problem1_data)\n",
    "\n",
    "# The matrix of left singular vectors of problem1_data with shape n_samples x n_dimensions\n",
    "U, S, V_T = np.linalg.svd(problem1_data, full_matrices=False)\n",
    "problem1_U = U\n",
    "print(\"Shape of U: \", U.shape)\n",
    "# The vector of singular values of problem1_data with shape n_dimensions\n",
    "# print(\"Shape of S: \", S.shape)\n",
    "problem1_D = np.diag(S)\n",
    "print(\"Shape of D: \", problem1_D.shape)\n",
    "# The matrix of right singular vectors of problem1_data with shape n_dimensions x n_dimensions\n",
    "problem1_V = V_T.T\n",
    "print(\"Shape of V: \", problem1_V.shape)\n",
    "# The first right singular vector of problem1_data with shape (n_dimensions,)\n",
    "# hint sometimes one needs to invoke flatten() to avoid having shape (n_dimensions, 1) or (1, n_dimensions)\n",
    "problem1_first_right_singular_vector = problem1_V[:,0]\n",
    "\n",
    "# The first left singular vector of problem1_data with shape (n_samples,)\n",
    "# hint sometimes one needs to invoke flatten() to avoid having shape (n_samples, 1) or (1, n_samples)\n",
    "problem1_first_left_singular_vector = problem1_U[:,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe8bd2",
   "metadata": {},
   "source": [
    "-----\n",
    "2. [3p] The first goal is to calculate the explained variance, check the lecture notes for definition. Calculate the explained variance of using $1$, $2$,... number of singular vectors and select how many singular vectors are needed in order to explain at least $95\\%$ of the variance.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b5e94",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Part 2: 3 points\n",
    "# ------------------------------------------------------------\n",
    "# Goal:\n",
    "#   1) Compute how much variance is explained when using\n",
    "#      the first 1, 2, 3, ..., n_dimensions singular vectors.\n",
    "#   2) Find the smallest number of singular vectors needed\n",
    "#      to explain at least 95% of the total variance.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Singular values from SVD\n",
    "# ------------------------------------------------------------\n",
    "# S comes from:\n",
    "#     U, S, V_T = np.linalg.svd(X, full_matrices=False)\n",
    "#\n",
    "# S is a 1D numpy array containing the singular values:\n",
    "#     S = [σ₁, σ₂, σ₃, ..., σ_r]\n",
    "#\n",
    "# These values are:\n",
    "#   - Non-negative\n",
    "#   - Sorted in descending order (σ₁ ≥ σ₂ ≥ σ₃ ≥ ...)\n",
    "#\n",
    "# Each singular value σ_k corresponds to how much \"energy\"\n",
    "# or \"variance\" the data has along the k-th singular direction.\n",
    "singular_values = S\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Explained variance per singular component\n",
    "# ------------------------------------------------------------\n",
    "# The variance explained by a singular component is proportional\n",
    "# to the square of its singular value:\n",
    "#\n",
    "#     variance_k ∝ σ_k²\n",
    "#\n",
    "# To turn these into FRACTIONS (so they sum to 1), we divide\n",
    "# by the total variance, which is the sum of all σ_k².\n",
    "#\n",
    "# Result:\n",
    "#   problem1_explained_variance[k] =\n",
    "#       σ_k² / (σ₁² + σ₂² + ... + σ_r²)\n",
    "#\n",
    "# Shape:\n",
    "#   (n_dimensions,)\n",
    "problem1_explained_variance = singular_values**2 / np.sum(singular_values**2)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Cumulative explained variance\n",
    "# ------------------------------------------------------------\n",
    "# np.cumsum computes a cumulative sum:\n",
    "#\n",
    "# If problem1_explained_variance = [v1, v2, v3, ...]\n",
    "#\n",
    "# Then cumulative_explained_variance =\n",
    "#   [ v1,\n",
    "#     v1 + v2,\n",
    "#     v1 + v2 + v3,\n",
    "#     ... ]\n",
    "#\n",
    "# This tells us how much TOTAL variance is explained when using\n",
    "# the first k singular vectors.\n",
    "#\n",
    "# The last value should be exactly 1 (or extremely close due to\n",
    "# floating-point precision).\n",
    "cumulative_explained_variance = np.cumsum(problem1_explained_variance)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Number of components needed to explain at least 95% variance\n",
    "# ------------------------------------------------------------\n",
    "# cumulative_explained_variance >= 0.95\n",
    "#   → produces a boolean array like:\n",
    "#     [False, False, True, True, ...]\n",
    "#\n",
    "# np.argmax(...) returns the index of the FIRST True value.\n",
    "#\n",
    "# Since Python uses 0-based indexing, we add 1 to convert\n",
    "# the index into a count of singular values.\n",
    "#\n",
    "# Result:\n",
    "#   problem1_num_components = smallest k such that\n",
    "#   the first k singular vectors explain at least 95% of the variance.\n",
    "problem1_num_components = np.argmax(cumulative_explained_variance >= 0.95) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d50b6",
   "metadata": {},
   "source": [
    "-----\n",
    "3. [3p] With the number of components chosen in part 2, construct the best approximating matrix with the rank as the number of components. Explain what each row represents in the approximating matrix in terms of the original data, write your answer as free text in the Markdown cell below as instructed in the cells.\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fb3ce2",
   "metadata": {},
   "source": [
    "### Explanation of the rank-$k$ approximating matrix\n",
    "\n",
    "Using the number of components selected in Part 2, we construct a rank-$k$ approximation of the original data matrix using the truncated Singular Value Decomposition (SVD). The approximation is given by\n",
    "\n",
    "$X_k = U_k D_k V_k^T$,\n",
    "\n",
    "where $U_k$ contains the first $k$ left singular vectors, $D_k$ is a diagonal matrix containing the largest $k$ singular values, and $V_k$ contains the first $k$ right singular vectors.\n",
    "\n",
    "Each row of the approximating matrix $X_k$ represents a reconstructed version of the corresponding row in the original data matrix. Specifically, each row is the best least-squares approximation of the original data point using only the top $k$ singular components. This means that the original data point is first projected onto a lower-dimensional subspace spanned by the dominant singular vectors and then mapped back to the original feature space.\n",
    "\n",
    "As a result, the rank-$k$ approximation captures the most important structure and patterns in the data while discarding smaller singular components, which typically correspond to noise or less significant variation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "517b319e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (1010, 100)\n",
      "Approximated X shape: (1010, 100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 3: 3 points\n",
    "# Construct the best rank-k approximation of X using SVD,\n",
    "# where k is the number of components chosen in Part 2.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# We already computed the SVD in Part 1:\n",
    "# X = problem1_U @ problem1_D @ problem1_V.T\n",
    "#\n",
    "# The best rank-k approximation is obtained by keeping only\n",
    "# the first k singular values and their corresponding singular vectors.\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# NOTE:\n",
    "# We do NOT need to redefine or extract singular values here.\n",
    "# The vector `s` already exists from Part 1 and contains the singular values.\n",
    "# Recomputing them would be redundant.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# s = np.diag(problem1_D)  # NOT needed, since s already exists from Part 1\n",
    "\n",
    "\n",
    "# Number of components selected in Part 2\n",
    "k = problem1_num_components\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Truncate matrices to keep only the first k components\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Keep the first k columns of U (left singular vectors)\n",
    "# Shape: (n_samples, k)\n",
    "problem1_U_k = problem1_U[:, :k]\n",
    "\n",
    "# problem1_D has shape (r, r) and is a diagonal matrix containing the singular values\n",
    "# on its diagonal, ordered from largest to smallest.\n",
    "#\n",
    "# The slicing [:k, :k] means:\n",
    "# - :k on rows  → take rows 0 to k-1\n",
    "# - :k on cols  → take columns 0 to k-1\n",
    "#\n",
    "# This extracts the top-left k x k submatrix of problem1_D, which contains\n",
    "# only the largest k singular values and discards the remaining smaller ones.\n",
    "#\n",
    "# Keeping only this block is necessary for constructing the rank-k SVD\n",
    "# approximation, where only the most important k components are retained.\n",
    "problem1_D_k = problem1_D[:k, :k]\n",
    "\n",
    "\n",
    "# Keep the first k columns of V (right singular vectors)\n",
    "# Shape: (n_dimensions, k)\n",
    "problem1_V_k = problem1_V[:, :k]\n",
    "\n",
    "# - `problem1_D_k = D[:k, :k]` → keeps the top $k$ singular values → shape (k, k)  \n",
    "# - `problem1_U_k = U[:, :k]` → keeps the first $k$ left singular vectors → shape (n_samples, k)  \n",
    "# - `:` means “take everything”; `:k` means “take indices 0 to k-1”  \n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Construct the rank-k approximation\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# The rank-k approximation is given by:\n",
    "# X_k = U_k @ D_k @ V_k^T\n",
    "#\n",
    "# This matrix is the best approximation of X among all\n",
    "# matrices of rank k in the least-squares sense.\n",
    "problem1_approximation = problem1_U_k @ problem1_D_k @ problem1_V_k.T\n",
    "\n",
    "\n",
    "# Optional sanity check: the approximated matrix must have\n",
    "# the same shape as the original data matrix X\n",
    "print(\"Original X shape:\", X.shape)\n",
    "print(\"Approximated X shape:\", problem1_approximation.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d90bbc",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put the explanation for **part 3** of the rows of the approximating matrix below this line in this cell. In order to enter edit mode you can doubleclick this cell or select it and just press enter.\n",
    "\n",
    "I looked at wikipedia and old posts stack overflow to solve the problem. What does each row represent in the matrix? Each row represents the results of a multiplication between right and left singular vector values with singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cb70e",
   "metadata": {},
   "source": [
    "-----\n",
    "4. [4p] Create a vector which corresponds to the row-wise (Euclidean) distance between the original matrix `problem1_data`and the approximating matrix `problem1_approximation` and plot the empirical distribution function of that distance. Based on the empirical distribution function choose a threshold such that 10 samples are above it and the rest below. Store the 10 samples in the instructed variable.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ae2296",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold: 8.743481393856763\n",
      "# > threshold: 9\n",
      "# >= threshold: 10\n",
      "outliers shape: (10, 100)\n"
     ]
    }
   ],
   "source": [
    "# errors per row\n",
    "problem1_reconstruction_error = np.linalg.norm(problem1_data - problem1_approximation, axis=1)\n",
    "\n",
    "# EDF\n",
    "sorted_errors = np.sort(problem1_reconstruction_error)\n",
    "n = len(sorted_errors)\n",
    "edf_values = np.arange(1, n + 1) / n\n",
    "\n",
    "plt.figure()\n",
    "plt.step(sorted_errors, edf_values, where=\"post\")\n",
    "plt.xlabel(\"Reconstruction error (row-wise Euclidean distance)\")\n",
    "plt.ylabel(\"Empirical distribution function (EDF)\")\n",
    "plt.title(\"EDF of reconstruction error\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# pick the top-10 outliers robustly\n",
    "outlier_indices = np.argsort(problem1_reconstruction_error)[-10:]\n",
    "problem1_outliers = problem1_data[outlier_indices]\n",
    "\n",
    "# choose a threshold that matches \"top 10\" idea\n",
    "# (this is the 10th largest error value)\n",
    "problem1_threshold = sorted_errors[-10]\n",
    "\n",
    "# NOTE:\n",
    "# If there are ties at threshold, \"> threshold\" might give fewer than 10.\n",
    "# That's unavoidable sometimes. The outlier selection above is still exactly 10.\n",
    "count_above = np.sum(problem1_reconstruction_error > problem1_threshold)\n",
    "count_at_or_above = np.sum(problem1_reconstruction_error >= problem1_threshold)\n",
    "\n",
    "print(\"threshold:\", problem1_threshold)\n",
    "print(\"# > threshold:\", count_above)\n",
    "print(\"# >= threshold:\", count_at_or_above)\n",
    "print(\"outliers shape:\", problem1_outliers.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d0d75",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b664ad",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "2. [4p] A page loads in $\\text{Exp}(1)$ (Exponentially distributed with mean $1$) seconds if not preloaded and loads with $\\text{Exp}(10)$ (Exponentially distributed with mean $1/10$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $1$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6726777d",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "521439a9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the matrix after insertions from the for loop: \n",
      "[[ 0. 22.  0. 10.  4.  1.  7.  9. 13. 17.]\n",
      " [13.  0. 12. 27.  2. 30. 16. 18.  4.  6.]\n",
      " [19. 12.  0. 11. 14. 16.  2.  0.  4. 14.]\n",
      " [ 1. 10. 21.  0.  8.  7. 15. 21.  0. 23.]\n",
      " [13. 12.  8. 10.  0.  7. 12.  4.  2.  4.]\n",
      " [ 1. 19.  3.  6. 16.  0. 16.  2. 18. 21.]\n",
      " [ 4.  7. 20.  9.  0. 16.  0. 16. 27. 16.]\n",
      " [15.  5.  1. 12.  8.  3. 20.  0. 16. 13.]\n",
      " [12. 10. 12.  4.  6. 14.  7.  8.  0. 11.]\n",
      " [ 4. 31. 15. 17. 14.  8. 20. 15.  0.  0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'XXX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     33\u001b[39m     matrix[i, j] += \u001b[32m1\u001b[39m             \u001b[38;5;66;03m# record one observed transition i -> j\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis is the matrix after insertions from the for loop: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmatrix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m problem2_transition_matrix = \u001b[43mXXX\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Store the number of states in the variable problem2_n_states below\u001b[39;00m\n\u001b[32m     40\u001b[39m problem2_n_states = XXX\n",
      "\u001b[31mNameError\u001b[39m: name 'XXX' is not defined"
     ]
    }
   ],
   "source": [
    "# Part 1: 3 points\n",
    "\n",
    "# Load the data from the file data/websites.csv and estimate the transition matrix of the Markov chain\n",
    "# Store the estimated transition matrix in the variable problem2_transition_matrix below\n",
    "# A numpy array of shape (problem2_n_states, problem2_n_states)\n",
    "\n",
    "data = pd.read_csv(\"data/websites.csv\")\n",
    "\n",
    "source = data[\"source\"]\n",
    "#print(source.max())\n",
    "source_n = source.max()\n",
    "source_n_lowest = source.min()\n",
    "# print(f\"Lowest value in Source: {source_n_lowest}\")\n",
    "source_n = np.amax(source)\n",
    "# print(f\"Largest value in Source: {source_n}\")\n",
    "\n",
    "destination = data[\"destination\"]\n",
    "destination_n = source.max()\n",
    "\n",
    "source_n_lowest = source.min()\n",
    "# print(f\"Lowest value in Destination: {source_n_lowest}\")\n",
    "# print(f\"Largest value in Destination: {destination_n}\")\n",
    "\n",
    "# Since we get max value of Source and Destination to be 9, we need a 10x10 matrix, \n",
    "# since 0 is included in both. \n",
    "\n",
    "matrix = np.zeros((10, 10))\n",
    "# print(f\"This is matrix with only zeros, 10x10: \\n{matrix} \\nShape of this matrix is: {matrix.shape}\")\n",
    "\n",
    "for _, row in data.iterrows():\n",
    "    i = int(row[\"source\"])        # current page (state i)\n",
    "    j = int(row[\"destination\"])   # next page (state j)\n",
    "    matrix[i, j] += 1             # record one observed transition i -> j\n",
    "\n",
    "print(f\"This is the matrix after insertions from the for loop: \\n{matrix}\")\n",
    "\n",
    "\n",
    "\n",
    "problem2_transition_matrix = XXX\n",
    "\n",
    "# Store the number of states in the variable problem2_n_states below\n",
    "problem2_n_states = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57121b31",
   "metadata": {},
   "source": [
    "-----\n",
    "2. [4p] A page loads in $\\text{Exp}(1)$ (Exponentially distributed with mean $1$) seconds if not preloaded and loads with $\\text{Exp}(10)$ (Exponentially distributed with mean $1/10$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $1$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3adcdd2",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 2: 4 points\n",
    "\n",
    "# Simulate the website load times for the next page of 10000 users that are currently on page 1\n",
    "# (recall indexing starts at 0) when we only load the most likely page.\n",
    "# Store the simulated page load times in the variable below\n",
    "# A numpy array of shape (10000,)\n",
    "problem2_page_load_times_top = XXX\n",
    "\n",
    "# Repeat the simulation of load times for the next page of 10000 users that are currently on page 1\n",
    "# when we load the two most likely pages.\n",
    "# Store the simulated page load times in the variable below\n",
    "# A numpy array of shape (10000,)\n",
    "problem2_page_load_times_two = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6616c7e",
   "metadata": {},
   "source": [
    "-----\n",
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5eccd1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3: 3 points\n",
    "\n",
    "# Calculate the true expected load time for loading a page without pre-loading\n",
    "# the next page and store it in the variable below\n",
    "# A float\n",
    "problem2_avg = XXX\n",
    "\n",
    "# Is the average load time for loading a page without pre-loading the next page\n",
    "# larger than the average load time for loading a page after pre-loading\n",
    "# the next most likely page?\n",
    "# True / False\n",
    "problem2_comparison = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f007420",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put the explanation for **part 3** of how you made the decision about `problem2_comparison` below this line in this **cell**. In order to enter edit mode you can doubleclick this cell or select it and press enter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8d742",
   "metadata": {},
   "source": [
    "-----\n",
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to it. \n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfec65d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "# Begin by calculating the stationary distribution of the Markov chain and store it in the variable below\n",
    "# WARNING: Since the transition matrix is not symmetric, numpy might make the output of the eigenvectors complex,\n",
    "# you can use np.real() to get the real part of the eigenvectors\n",
    "# A numpy array of shape (problem2_n_states,)\n",
    "problem2_stationary_distribution = XXX\n",
    "\n",
    "# Now use the above stationary distribution to calculate the average load time for loading a page\n",
    "# after pre-loading the next most likely page according to the stationary distribution\n",
    "# Store the average load time in the variable below\n",
    "# A float\n",
    "problem2_avg_stationary = XXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08beccb8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21deee81",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n",
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n",
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n",
    "3. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1aadd3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RUN THIS CELL TO GET THE DATA\n",
    "\n",
    "# We start by loading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PROBLEM3_DF = pd.read_csv('data/fraud.csv')\n",
    "Y = PROBLEM3_DF['Class'].values\n",
    "X = PROBLEM3_DF[['V%d' % i for i in range(1,5)]+['Amount']].values\n",
    "\n",
    "# We will split the data into training, testing and validation sets\n",
    "from Utils import train_test_validation\n",
    "PROBLEM3_X_train, PROBLEM3_X_test, PROBLEM3_X_val, PROBLEM3_y_train, PROBLEM3_y_test, PROBLEM3_y_val = train_test_validation(X,Y,shuffle=True,random_state=1)\n",
    "\n",
    "# From this we will train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(PROBLEM3_X_train,PROBLEM3_y_train)\n",
    "\n",
    "# THE FOLLOWING CODE WILL PRODUCE THE ARRAYS YOU NEED FOR THE PROBLEM\n",
    "\n",
    "PROBLEM3_y_pred_proba_val = lr.predict_proba(PROBLEM3_X_val)[:,1]\n",
    "PROBLEM3_y_true_val = PROBLEM3_y_val\n",
    "\n",
    "PROBLEM3_y_pred_proba_test = lr.predict_proba(PROBLEM3_X_test)[:,1]\n",
    "PROBLEM3_y_true_test = PROBLEM3_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c588e528",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "# Part 1: 3 points\n",
    "\n",
    "# Implement the following function that calculates the cost of a binary classifier according to\n",
    "# the specification in the problem statement\n",
    "# See the comments inside the function for details of the parameters\n",
    "def cost(y_true, y_predict_proba, threshold):\n",
    "    # y_true is a numpy array of shape (n_samples,) with binary labels\n",
    "    # y_predict_proba is a numpy array of shape (n_samples,) with predicted probabilities\n",
    "    # threshold is a float between 0 and 1\n",
    "\n",
    "    # When returning the cost, you should return the average cost per sample\n",
    "    # thus it should be a value\n",
    "    XXX\n",
    "    return XXX  # A float\n",
    "\n",
    "\n",
    "# Provide the code below to plot the cost as a function of the threshold\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# The plot should be between 0 and 1 with 0.01 increments\n",
    "# The y-axis should be the cost and the x-axis should be the threshold\n",
    "XXX\n",
    "XXX\n",
    "XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25387d22",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "# Part 2: 2.5 points\n",
    "\n",
    "# Use the cost function you just implemented above to find the threshold that minimizes the cost\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the threshold in the variable below\n",
    "problem3_threshold = XXX  # A float between 0 and 1\n",
    "\n",
    "# Now calculate the cost of the classifier using the validation data and the threshold you just found\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the cost in the variable below\n",
    "problem3_cost_val = XXX  # A float\n",
    "\n",
    "# Using the threshold you just found, calculate the predicted labels of the classifier\n",
    "# on the validation data and put the predicted labels in the variable below\n",
    "# A numpy array of shape (n_samples,) with values 0 or 1\n",
    "problem3_y_pred_val = XXX\n",
    "\n",
    "# Calculate the precision and recall of the classifier of class 1 using the threshold you just found\n",
    "# Store in the variables below (floats between 0 and 1)\n",
    "problem3_precision_1 = XXX\n",
    "problem3_recall_1 = XXX\n",
    "\n",
    "# Calculate the precision and recall of the classifier of class 0 using the threshold you just found\n",
    "# Store in the variables below (floats between 0 and 1)\n",
    "problem3_precision_0 = XXX\n",
    "problem3_recall_0 = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362a128",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "# Part 3: 2.5 points\n",
    "\n",
    "# Find the threshold that minimizes the 0-1 loss using the validation data\n",
    "# specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the threshold in the variable below\n",
    "# A float between 0 and 1\n",
    "problem3_threshold_01 = XXX\n",
    "\n",
    "# Now calculate the difference in cost (using the cost function you implemented in Part 1)\n",
    "# between the optimal threshold chosen in Part 2 and the one chosen in this part.\n",
    "# The value should be positive.\n",
    "# A float\n",
    "problem3_cost_difference = XXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3d73e4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "# Using the threshold problem3_threshold use Hoeffding's inequality to provide a confidence interval\n",
    "# for the cost of the classifier with 95 % confidence using the test data.\n",
    "# Specifically the arrays PROBLEM3_y_true_test and PROBLEM3_y_pred_proba_test.\n",
    "# Store the lower and upper bounds of the confidence interval in the variables below\n",
    "\n",
    "problem3_lower_bound = XXX  # A float\n",
    "problem3_upper_bound = XXX  # A float\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67721024",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put your explanation for part 4 below this line in this **cell**. Doubleclick to enter edit mode as before.\n",
    "\n",
    "\n",
    "I assume that all variables are sub-Gaussian, to be able to use Hoeffdinger's inequality. \n",
    "I furthermore assume that the variables X are IID."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
