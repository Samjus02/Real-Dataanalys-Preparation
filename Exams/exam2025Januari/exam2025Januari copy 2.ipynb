{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b465e0d9",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 17th of January 2025, 8.00-13.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "40240477",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a59a3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c67547",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ea1654",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "This problem is about SVD and anomaly detection. In all the problems where you are asked to produce a matrix or vector, they should be **numpy arrays**. \n",
    "\n",
    "1. [4p] Load the file `data/SVD.csv` as instructed in the code cell. Compute the Singular Value Decomposition, i.e. construct the three matrices $U$, $D$, $V$ such that if $X$ is the data matrix of shape `n_samples x n_dimensions` then $X = UDV^T$. Put the resulting matrices in their variables, check that the shapes align with the instructions in the code cell. Finally, extract the first right and left singular vectors and store those as 1-d arrays in the instructed variables.\n",
    "2. [3p] The first goal is to calculate the explained variance, check the lecture notes for definition. Calculate the explained variance of using $1$, $2$,... number of singular vectors and select how many singular vectors are needed in order to explain at least $95\\%$ of the variance.\n",
    "3. [3p] With the number of components chosen in part 2, construct the best approximating matrix with the rank as the number of components. Explain what each row represents in the approximating matrix in terms of the original data, write your answer as free text in the Markdown cell below as instructed in the cells.\n",
    "4. [4p] Create a vector which corresponds to the row-wise (Euclidean) distance between the original matrix `problem1_data`and the approximating matrix `problem1_approximation` and plot the empirical distribution function of that distance. Based on the empirical distribution function choose a threshold such that 10 samples are above it and the rest below. Store the 10 samples in the instructed variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b66e0d",
   "metadata": {},
   "source": [
    "-----\n",
    "This problem is about SVD and anomaly detection. In all the problems where you are asked to produce a matrix or vector, they should be **numpy arrays**. \n",
    "\n",
    "1. [4p] Load the file `data/SVD.csv` as instructed in the code cell. Compute the Singular Value Decomposition, i.e. construct the three matrices $U$, $D$, $V$ such that if $X$ is the data matrix of shape `n_samples x n_dimensions` then $X = UDV^T$. Put the resulting matrices in their variables, check that the shapes align with the instructions in the code cell. Finally, extract the first right and left singular vectors and store those as 1-d arrays in the instructed variables.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8ea11d5a",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: (1010, 100) \n",
      "Shape of s: (100,) \n",
      "Shape of VT: (100, 100)\n",
      "\n",
      "\n",
      "Shape of U: (1010, 100) \n",
      "Shape of S: (100, 100) \n",
      "Shape of V: (100, 100)\n",
      "\n",
      "\n",
      "Shape of singular vectors: (100,)\n",
      "\n",
      "\n",
      "Shape of singular vectors: (1010,)\n"
     ]
    }
   ],
   "source": [
    "# Part 1: 4 points\n",
    "\n",
    "# Load the data from the file data/SVD.csv and store the data in a numpy array called problem1_data below\n",
    "# Double check that the numbers have been parsed correctly by checking the dtype of the array by calling problem1_data.dtype\n",
    "problem1_data = pd.read_csv(\"data/SVD.csv\", header=None).to_numpy()\n",
    "# print(problem1_data)\n",
    "\n",
    "U, s, VT = np.linalg.svd(problem1_data, full_matrices=False)\n",
    "\n",
    "print(f\"Shape of U: {U.shape} \\nShape of s: {s.shape} \\nShape of VT: {VT.shape}\")\n",
    "\n",
    "# The matrix of left singular vectors of problem1_data with shape n_samples x n_dimensions\n",
    "problem1_U = U\n",
    "\n",
    "# The vector of singular values of problem1_data with shape n_dimensions\n",
    "problem1_D = np.diag(s)\n",
    "\n",
    "# The matrix of right singular vectors of problem1_data with shape n_dimensions x n_dimensions\n",
    "problem1_V = VT.T\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Shape of U: {problem1_U.shape} \\nShape of S: {problem1_D.shape} \\nShape of V: {problem1_V.shape}\")\n",
    "\n",
    "# The first right singular vector of problem1_data with shape (n_dimensions,)\n",
    "# hint sometimes one needs to invoke flatten() to avoid having shape (n_dimensions, 1) or (1, n_dimensions)\n",
    "problem1_first_right_singular_vector = problem1_V[:, 0]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Shape of singular vectors: {problem1_first_right_singular_vector.shape}\")\n",
    "# The first left singular vector of problem1_data with shape (n_samples,)\n",
    "# hint sometimes one needs to invoke flatten() to avoid having shape (n_samples, 1) or (1, n_samples)\n",
    "problem1_first_left_singular_vector = problem1_U[:, 0]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Shape of singular vectors: {problem1_first_left_singular_vector.shape}\")\n",
    "\n",
    "#print(type(problem1_first_right_singular_vector))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe8bd2",
   "metadata": {},
   "source": [
    "-----\n",
    "2. [3p] The first goal is to calculate the explained variance, check the lecture notes for definition. Calculate the explained variance of using $1$, $2$,... number of singular vectors and select how many singular vectors are needed in order to explain at least $95\\%$ of the variance.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "598b5e94",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need 10 number of components to achieve 95%\n"
     ]
    }
   ],
   "source": [
    "# Part 2: 3 points\n",
    "\n",
    "# Calculate the explained variance of using 1,2,3,...,n_dimensions singular values and store it as a numpy array called\n",
    "# problem1_explained_variance below\n",
    "# A numpy array of shape (n_dimensions,), it should be an increasing sequence of positive numbers\n",
    "# and the last element should be 1\n",
    "\n",
    "\n",
    "# This is the definition from lecture notes:\n",
    "# Explained variance is how much percentage of the total variance is captured\n",
    "# by our singular vectors. Remember the interpretation of the singular values\n",
    "# as the standard deviation, as such the variance explained of the first k\n",
    "# components is just the sum of the singular values squared and divided by\n",
    "# the total variance.\n",
    "\n",
    "# This is the cummulative explained variance which is what they wanted. \n",
    "variances = s**2 \n",
    "problem1_explained_variance = np.cumsum(variances) / np.sum(variances)\n",
    "\n",
    "k = 0\n",
    "\n",
    "# This is just a function to find how many K we need to reconstruct with 95% variance. \n",
    "# One could also simply just look at the print of the problem1_explained_variance and see where\n",
    "# we meet the threshold and calculate the amount of components we needed. \n",
    "for i in range(len(problem1_explained_variance)):\n",
    "    # print(\"Loop\")\n",
    "    if problem1_explained_variance[i] >= 0.95:\n",
    "        k += 1\n",
    "        break\n",
    "    else: \n",
    "        k += 1\n",
    "        \n",
    "print(f\"We need {k} number of components to achieve 95%\")\n",
    "\n",
    "# print(f\"This is the explained variance: {problem1_explained_variance}\")\n",
    "# print(f\"This is the shape of the explained variance: {problem1_explained_variance.shape}\")\n",
    "\n",
    "\n",
    "# Store in the variable below the smallest number of singular values needed\n",
    "# to explain at least 95% of the variance\n",
    "problem1_num_components = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d50b6",
   "metadata": {},
   "source": [
    "-----\n",
    "3. [3p] With the number of components chosen in part 2, construct the best approximating matrix with the rank as the number of components. Explain what each row represents in the approximating matrix in terms of the original data, write your answer as free text in the Markdown cell below as instructed in the cells.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "517b319e",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 100)\n"
     ]
    }
   ],
   "source": [
    "# Part 3: 3 points\n",
    "\n",
    "# Calculate the approximating matrix of problem1_data using the first \n",
    "# problem1_num_components singular values and store it in the variable below\n",
    "# A numpy array of shape n_samples x n_dimensions\n",
    "\n",
    "reconstruct = U[:, :k] @ np.diag(s[:k]) @ VT[:k, :]\n",
    "print(reconstruct.shape)\n",
    "\n",
    "problem1_approximation = reconstruct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d90bbc",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put the explanation for **part 3** of the rows of the approximating matrix below this line in this cell. In order to enter edit mode you can doubleclick this cell or select it and just press enter.\n",
    "\n",
    "I looked at wikipedia and old posts stack overflow to solve the problem. What does each row represent in the matrix? Each row represents the results of a multiplication between right and left singular vector values with singular values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cb70e",
   "metadata": {},
   "source": [
    "-----\n",
    "4. [4p] Create a vector which corresponds to the row-wise (Euclidean) distance between the original matrix `problem1_data`and the approximating matrix `problem1_approximation` and plot the empirical distribution function of that distance. Based on the empirical distribution function choose a threshold such that 10 samples are above it and the rest below. Store the 10 samples in the instructed variable.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3ae2296",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem1_threshold: 0.02203521604468554\n",
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Part 4: 4 points\n",
    "# ------------------------------------------------------------\n",
    "# This part computes the reconstruction error of each sample,\n",
    "# visualizes its empirical distribution, and selects outliers\n",
    "# based on the largest reconstruction errors.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Alias the original data matrix and its low-rank SVD approximation\n",
    "# Both have shape (n_samples, n_dimensions)\n",
    "original = problem1_data\n",
    "approximation = problem1_approximation\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Compute row-wise reconstruction error\n",
    "# ------------------------------------------------------------\n",
    "# np.linalg.norm(..., axis=1) computes the Euclidean (L2) norm\n",
    "# across columns for each row:\n",
    "#\n",
    "# For each sample i:\n",
    "#   error_i = || original[i] - approximation[i] ||_2\n",
    "#\n",
    "# The result is a 1D NumPy array of length n_samples.\n",
    "#\n",
    "# Reminder:\n",
    "#   X.shape == (n_rows, n_columns)\n",
    "#   axis=0 → operate column-wise (down the rows)\n",
    "#   axis=1 → operate row-wise (across the columns)\n",
    "problem1_reconstruction_error = np.linalg.norm(original - approximation, axis=1)\n",
    "\n",
    "# Sanity check: should be (n_samples,)\n",
    "print(problem1_reconstruction_error.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Build and plot the empirical distribution function (EDF)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "from Utils import makeEDF, plotEDF\n",
    "\n",
    "# Sort the reconstruction errors (required for EDF construction)\n",
    "sorted_errors = np.sort(problem1_reconstruction_error)\n",
    "\n",
    "# Build the empirical distribution function:\n",
    "# Column 0: error values\n",
    "# Column 1: cumulative frequencies (EDF values)\n",
    "edf_residuals = makeEDF(sorted_errors)\n",
    "\n",
    "# Plot the EDF together with a 95% DKW confidence band\n",
    "plotEDF(\n",
    "    edf_residuals,\n",
    "    confidence_band=True,\n",
    "    alpha=0.95,\n",
    "    title=\"Empirical Distribution Function of reconstruction error\"\n",
    ")\n",
    "\n",
    "# Optional check:\n",
    "# print(f\"EDF shape: {edf_residuals.shape}\")  # (n_samples, 2)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Choose threshold so that exactly 10 samples are above it\n",
    "# ------------------------------------------------------------\n",
    "# sorted_errors[-1]  -> largest error\n",
    "# sorted_errors[-11] -> 11th largest error\n",
    "#\n",
    "# Choosing this value ensures that exactly 10 reconstruction\n",
    "# errors are strictly larger than the threshold.\n",
    "problem1_threshold = sorted_errors[-11]\n",
    "print(f\"Problem1_threshold: {problem1_threshold}\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Extract the outlier samples\n",
    "# ------------------------------------------------------------\n",
    "# Select rows of the original data whose reconstruction error\n",
    "# exceeds the chosen threshold.\n",
    "# The result should have shape (10, n_dimensions).\n",
    "errs = problem1_reconstruction_error\n",
    "problem1_outliers = problem1_data[errs > problem1_threshold]\n",
    "\n",
    "# Sanity check: should be (10, n_dimensions)\n",
    "print(problem1_outliers.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d0d75",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b664ad",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "2. [4p] A page loads in $\\text{Exp}(1)$ (Exponentially distributed with mean $1$) seconds if not preloaded and loads with $\\text{Exp}(10)$ (Exponentially distributed with mean $1/10$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $1$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b88b47",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "521439a9",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the transition matrix:\n",
      " [[0.         0.26506024 0.         0.12048193 0.04819277 0.01204819\n",
      "  0.08433735 0.10843373 0.15662651 0.20481928]\n",
      " [0.1015625  0.         0.09375    0.2109375  0.015625   0.234375\n",
      "  0.125      0.140625   0.03125    0.046875  ]\n",
      " [0.20652174 0.13043478 0.         0.11956522 0.15217391 0.17391304\n",
      "  0.02173913 0.         0.04347826 0.15217391]\n",
      " [0.00943396 0.09433962 0.19811321 0.         0.0754717  0.06603774\n",
      "  0.14150943 0.19811321 0.         0.21698113]\n",
      " [0.18055556 0.16666667 0.11111111 0.13888889 0.         0.09722222\n",
      "  0.16666667 0.05555556 0.02777778 0.05555556]\n",
      " [0.00980392 0.18627451 0.02941176 0.05882353 0.15686275 0.\n",
      "  0.15686275 0.01960784 0.17647059 0.20588235]\n",
      " [0.03478261 0.06086957 0.17391304 0.07826087 0.         0.13913043\n",
      "  0.         0.13913043 0.23478261 0.13913043]\n",
      " [0.16129032 0.05376344 0.01075269 0.12903226 0.08602151 0.03225806\n",
      "  0.21505376 0.         0.17204301 0.13978495]\n",
      " [0.14285714 0.11904762 0.14285714 0.04761905 0.07142857 0.16666667\n",
      "  0.08333333 0.0952381  0.         0.13095238]\n",
      " [0.03225806 0.25       0.12096774 0.13709677 0.11290323 0.06451613\n",
      "  0.16129032 0.12096774 0.         0.        ]]\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Part 1: 3 points\n",
    "\n",
    "# Load the data from the file data/websites.csv and estimate the transition matrix of the Markov chain\n",
    "# Store the estimated transition matrix in the variable problem2_transition_matrix below\n",
    "# A numpy array of shape (problem2_n_states, problem2_n_states)\n",
    "\n",
    "data = pd.read_csv(\"data/websites.csv\")\n",
    "# print(data.head(5))\n",
    "\n",
    "# This is how to determine the size of the matrix, i.e. the number of states it should have: \n",
    "source_values = data[\"source\"].values\n",
    "destination_values = data[\"destination\"].values\n",
    "\n",
    "source_min_val = source_values.min()\n",
    "source_max_val = source_values.max()\n",
    "\n",
    "destination_min_val = destination_values.min()\n",
    "destination_max_val = destination_values.max()\n",
    "\n",
    "# print(f\"Source min val: {source_min_val} Source max val: {source_max_val} \\nDestination min val: {destination_min_val} Destination max val: {destination_max_val}\")\n",
    "\n",
    "n_states = 10\n",
    "# The print statement ensured us that the matrix should be 10x10, since 0-9 is 10 values. \n",
    "\n",
    "counts = np.zeros((n_states, n_states))\n",
    "# print(counts) => Only zeros which is good!\n",
    "# print(counts.shape) => 10x10\n",
    "\n",
    "# Now we have to iterate through the dataset that we have and then calculate each count from \n",
    "# source -> destination and increment that into the counts matrix!\n",
    "# In order to iterate through the data, use iterrows, this is the example of how to use it: \n",
    "# students = {\"Name\": [\"Mary\", \"Joseph\"], \"Age\": [25, 30]}\n",
    "# students = pd.DataFrame(students)\n",
    "\n",
    "# for index, row in students.iterrows():\n",
    "#     print(f\"Index: {index}, Name: {row['Name']}, Age: {row['Age']}\")\n",
    "    \n",
    "# Output =      Index: 0, Name: Mary, Age: 25\n",
    "#               Index: 1, Name: Joseph, Age: 30\n",
    "\n",
    "# SO: \n",
    "for index, row in data.iterrows():\n",
    "    source = row[\"source\"]\n",
    "    destination = row[\"destination\"]\n",
    "    counts[source, destination] += 1 \n",
    "\n",
    "#print(f\"This is the counts matrix right now after insertion: \\n {counts}\")\n",
    "\n",
    "# In order to calculate the transition matrix, we simply need to sum up each row in the matrix, \n",
    "# then we simply divide each value in the row,column id with the total sum for that column. \n",
    "\n",
    "stationary = counts\n",
    "# print(stationary)\n",
    "\n",
    "for i in range(n_states):\n",
    "    #print(stationary[i])\n",
    "    row_sum = sum(stationary[i])\n",
    "    #print(row_sum)\n",
    "    for j in range(n_states):\n",
    "        if (stationary[i, j] == 0):\n",
    "            stationary[i, j] = 0\n",
    "        else:\n",
    "            stationary[i, j] = stationary[i, j] / row_sum\n",
    "\n",
    "problem2_transition_matrix = stationary\n",
    "\n",
    "print(f\"This is the transition matrix:\\n {problem2_transition_matrix}\")\n",
    "\n",
    "# Store the number of states in the variable problem2_n_states below\n",
    "problem2_n_states = n_states\n",
    "\n",
    "# This is just a check so that the transition matrix rows adds up to 1:\n",
    "for i in range(n_states):\n",
    "    row_sum = problem2_transition_matrix[i].sum()\n",
    "    if np.isclose(row_sum, 1.0):\n",
    "        print(\"True\")\n",
    "    else:\n",
    "        print(\"False\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2ad2cb",
   "metadata": {},
   "source": [
    "2. [4p] A page loads in $\\text{Exp}(1)$ (Exponentially distributed with mean $1$) seconds if not preloaded and loads with $\\text{Exp}(10)$ (Exponentially distributed with mean $1/10$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $1$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d3adcdd2",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 preloaded page: 5\n",
      "Top-2 preloaded pages: [3 5]\n",
      "Mean load time (top-1): 0.8106119346551004\n",
      "Mean load time (top-2): 0.6016664633960759\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Part 2: Simulating page load times with preloading\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# We start from page 1.\n",
    "# Indexing starts at 0, so page \"1\" corresponds to index 1.\n",
    "start_page = 1\n",
    "\n",
    "# Number of users we simulate (each user makes one page transition)\n",
    "load_pages = 10000\n",
    "\n",
    "# Number of pages (states in the Markov chain).\n",
    "# .shape[0] gives the number of rows in the transition matrix,\n",
    "# which equals the number of pages.\n",
    "n_states = problem2_transition_matrix.shape[0]\n",
    "\n",
    "# Extract the transition probabilities FROM the start page.\n",
    "# This is a 1D array where:\n",
    "#   - index i   = destination page i\n",
    "#   - value     = probability of moving to page i\n",
    "transition_probs = problem2_transition_matrix[start_page]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Finding which pages to preload\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# np.argmax(array):\n",
    "# - looks through the array\n",
    "# - finds the LARGEST value\n",
    "# - returns the INDEX of that value\n",
    "#\n",
    "# Here:\n",
    "# - we find which page has the highest transition probability\n",
    "top1_page = np.argmax(transition_probs)\n",
    "\n",
    "# np.argsort(array):\n",
    "# - sorts the array from smallest to largest\n",
    "# - BUT returns the INDICES that would sort the array\n",
    "#\n",
    "# Example:\n",
    "# array = [0.2, 0.5, 0.1]\n",
    "# np.argsort(array) -> [2, 0, 1]\n",
    "#\n",
    "# The last two indices correspond to the two largest probabilities\n",
    "top2_pages = np.argsort(transition_probs)[-2:]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Simulation when ONLY the most likely page is preloaded\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# np.random.choice:\n",
    "# - randomly selects values from {0, 1, ..., n_states-1}\n",
    "# - each value is chosen according to probabilities in p\n",
    "#\n",
    "# In simple terms:\n",
    "# - this simulates where each user goes next\n",
    "# - according to the Markov transition probabilities\n",
    "next_pages_top = np.random.choice(\n",
    "    n_states,              # possible pages: 0, 1, ..., n_states-1\n",
    "    size=load_pages,       # number of users (samples)\n",
    "    p=transition_probs     # probability of choosing each page\n",
    ")\n",
    "\n",
    "# (next_pages_top == top1_page):\n",
    "# - compares each sampled page with the preloaded page\n",
    "# - returns True if equal, False otherwise\n",
    "#\n",
    "# Result:\n",
    "# - a Boolean array telling us which users got a preloaded page\n",
    "is_preloaded_top = (next_pages_top == top1_page)\n",
    "\n",
    "# np.random.exponential(scale=1.0):\n",
    "# - draws samples from an exponential distribution\n",
    "# - 'scale' is the MEAN of the distribution\n",
    "#\n",
    "# scale = 1.0  -> Exp(1), mean load time = 1 second\n",
    "not_preloaded = np.random.exponential(scale=1.0, size=load_pages)\n",
    "\n",
    "# scale = 0.1 -> Exp(10), mean load time = 0.1 seconds\n",
    "# (preloading makes the page load much faster)\n",
    "preloaded = np.random.exponential(scale=0.1, size=load_pages)\n",
    "\n",
    "# np.where(condition, x, y):\n",
    "# - looks at each position in 'condition'\n",
    "# - if True  -> take value from x\n",
    "# - if False -> take value from y\n",
    "#\n",
    "# Here:\n",
    "# - if page was preloaded -> fast load time\n",
    "# - else                 -> slow load time\n",
    "problem2_page_load_times_top = np.where(\n",
    "    is_preloaded_top,\n",
    "    preloaded,\n",
    "    not_preloaded\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Simulation when the TWO most likely pages are preloaded\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Sample next pages again for a NEW experiment\n",
    "next_pages_two = np.random.choice(\n",
    "    n_states,\n",
    "    size=load_pages,\n",
    "    p=transition_probs\n",
    ")\n",
    "\n",
    "# np.isin(a, b):\n",
    "# - checks element-by-element if values in 'a' are present in 'b'\n",
    "# - returns True if the value exists in b, False otherwise\n",
    "#\n",
    "# Here:\n",
    "# - True if the next page is one of the two preloaded pages\n",
    "is_preloaded_two = np.isin(next_pages_two, top2_pages)\n",
    "\n",
    "# Generate load times again\n",
    "not_preloaded2 = np.random.exponential(scale=1.0, size=load_pages)\n",
    "preloaded2 = np.random.exponential(scale=0.1, size=load_pages)\n",
    "\n",
    "# Assign load times using the same logic as before\n",
    "problem2_page_load_times_two = np.where(\n",
    "    is_preloaded_two,\n",
    "    preloaded2,\n",
    "    not_preloaded2\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Optional sanity checks\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Print which pages were preloaded\n",
    "print(\"Top-1 preloaded page:\", top1_page)\n",
    "print(\"Top-2 preloaded pages:\", top2_pages)\n",
    "\n",
    "# Mean load times:\n",
    "# Preloading two pages should reduce the average load time\n",
    "print(\"Mean load time (top-1):\", problem2_page_load_times_top.mean())\n",
    "print(\"Mean load time (top-2):\", problem2_page_load_times_two.mean())\n",
    "\n",
    "\n",
    "\n",
    "# np.argmax → “Which page is most likely?”\n",
    "# np.argsort → “Which pages are the most likely in order?”\n",
    "# np.random.choice → “Simulate where users go next”\n",
    "# np.isin → “Was this page preloaded?”\n",
    "# np.where → “Choose fast or slow load time”\n",
    "# Exponential distribution → “Models random waiting times”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec5611",
   "metadata": {},
   "source": [
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0b5eccd1",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the mena of problem2_page_load_times_top:  0.8106119346551004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.True_"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Part 3: Compare empirical and theoretical average load times\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# If NO page is preloaded, every page load time follows Exp(1),\n",
    "# i.e. an exponential distribution with rate 1.\n",
    "# The expected value of an Exp(lambda) random variable is:\n",
    "#     E[T] = 1 / lambda\n",
    "# Here lambda = 1, so the theoretical expected load time is exactly 1 second.\n",
    "problem2_avg = 1.0\n",
    "\n",
    "\n",
    "# We now compare this theoretical average (no pre-loading)\n",
    "# with the EMPIRICAL average load time obtained in Part 2\n",
    "# when pre-loading the most likely next page.\n",
    "#\n",
    "# problem2_page_load_times_top contains 10,000 simulated load times.\n",
    "# Taking the mean gives an estimate of the expected load time\n",
    "# under pre-loading.\n",
    "#\n",
    "# If the theoretical mean (1.0) is larger than the empirical mean,\n",
    "# then pre-loading improves the expected load time.\n",
    "problem2_comparison = problem2_avg > np.mean(problem2_page_load_times_top)\n",
    "\n",
    "print(\"This is the mena of problem2_page_load_times_top: \", np.mean(problem2_page_load_times_top))\n",
    "\n",
    "# This boolean answers the question directly:\n",
    "# True  -> pre-loading improves load time\n",
    "# False -> no improvement observed\n",
    "problem2_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f007420",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "### Explanation (Part 3)\n",
    "\n",
    "If no page is preloaded, the load time of every page follows an exponential distribution with rate $\\lambda = 1$, denoted $\\mathrm{Exp}(1)$. The expected value of an exponential random variable with rate $\\lambda$ is given by\n",
    "$$\n",
    "\\mathbb{E}[T] = \\frac{1}{\\lambda}.\n",
    "$$\n",
    "Therefore, in the case of no preloading, the theoretical expected load time is\n",
    "$$\n",
    "\\mathbb{E}[T_{\\text{no preload}}] = 1 \\text{ second}.\n",
    "$$\n",
    "\n",
    "When preloading is used, the load time depends on whether the next visited page was preloaded. If the page is preloaded, the load time follows an $\\mathrm{Exp}(10)$ distribution with mean $1/10$ seconds; otherwise, it follows an $\\mathrm{Exp}(1)$ distribution with mean $1$ second. This results in a mixture of exponential distributions.\n",
    "\n",
    "To estimate the expected load time under preloading, we simulate $10{,}000$ users starting from page 1 and compute the empirical mean of the simulated load times. By the law of large numbers, this empirical mean approximates the true expected load time.\n",
    "\n",
    "Since the empirical average load time with preloading is smaller than the theoretical average load time of $1$ second without preloading, we conclude that preloading improves the expected page load time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8d26c3",
   "metadata": {},
   "source": [
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bbfec65d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary distribution: \n",
      " [0.08212278 0.12810291 0.09219365 0.10612032 0.0721337  0.10215028\n",
      " 0.11517528 0.09308925 0.08396098 0.12495085]\n",
      "Stationary expected loading time:  0.8018160947549082\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 4.1: Stationary distribution via eigenvector of P^T\n",
    "# ------------------------------------------------------------\n",
    "# A stationary distribution pi satisfies:\n",
    "#   pi P = pi\n",
    "# Equivalently, pi^T is a right eigenvector of P^T with eigenvalue 1.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Transition matrix and number of states\n",
    "P = problem2_transition_matrix\n",
    "n = problem2_n_states\n",
    "\n",
    "# Compute eigenvalues and eigenvectors of the transpose P^T\n",
    "# We use P^T because we want a LEFT eigenvector of P\n",
    "eigvals, eigvecs = np.linalg.eig(P.T)\n",
    "\n",
    "# Find the index of the eigenvalue that is closest to 1\n",
    "# (due to numerical precision, it may not be exactly 1)\n",
    "idx = np.argmin(np.abs(eigvals - 1.0))\n",
    "\n",
    "# Extract the corresponding eigenvector\n",
    "# Eigenvectors may be complex due to numerical reasons,\n",
    "# but the stationary distribution is real, so we take the real part\n",
    "pi = np.real(eigvecs[:, idx])\n",
    "\n",
    "# The eigenvector is only defined up to a multiplicative constant\n",
    "# (and sign), so if the sum is negative we flip the sign\n",
    "if pi.sum() < 0:\n",
    "    pi = -pi\n",
    "\n",
    "# Due to numerical noise, some entries may be very small negatives.\n",
    "# We clamp them to zero and normalize so the distribution sums to 1.\n",
    "pi = np.maximum(pi, 0.0)\n",
    "pi = pi / pi.sum()\n",
    "\n",
    "# Store the stationary distribution\n",
    "problem2_stationary_distribution = pi  # shape (n,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 4.2: Expected load time under stationary distribution\n",
    "# ------------------------------------------------------------\n",
    "# We assume that from each current page i, we preload the single\n",
    "# most likely next page according to the transition probabilities.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# For each page i, find the index of the most likely next page\n",
    "top_next = np.argmax(P, axis=1)  # shape (n,)\n",
    "\n",
    "# For each page i, extract the probability that the next page\n",
    "# equals the preloaded (most likely) one\n",
    "p_preloaded = P[np.arange(n), top_next]  # shape (n,)\n",
    "\n",
    "# Expected load time starting from page i:\n",
    "# - With probability p_preloaded[i], the page is preloaded:\n",
    "#       load time ~ Exp(10) with mean 0.1\n",
    "# - With probability 1 - p_preloaded[i], it is not preloaded:\n",
    "#       load time ~ Exp(1) with mean 1.0\n",
    "#\n",
    "# Therefore:\n",
    "#   E[T | i] = 0.1 * p_preloaded[i] + 1.0 * (1 - p_preloaded[i])\n",
    "#            = 1 - 0.9 * p_preloaded[i]\n",
    "expected_time_given_i = 1.0 - 0.9 * p_preloaded  # shape (n,)\n",
    "\n",
    "# Expected load time under the stationary distribution:\n",
    "#   E[T] = sum_i pi_i * E[T | i]\n",
    "problem2_avg_stationary = float(problem2_stationary_distribution @ expected_time_given_i)\n",
    "\n",
    "# Optional prints for inspection\n",
    "print(\"Stationary distribution: \\n\", problem2_stationary_distribution)\n",
    "print(\"Stationary expected loading time: \", problem2_avg_stationary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08beccb8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21deee81",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n",
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n",
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n",
    "4. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3f1aadd3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RUN THIS CELL TO GET THE DATA\n",
    "\n",
    "# We start by loading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PROBLEM3_DF = pd.read_csv('data/fraud.csv')\n",
    "Y = PROBLEM3_DF['Class'].values\n",
    "X = PROBLEM3_DF[['V%d' % i for i in range(1,5)]+['Amount']].values\n",
    "\n",
    "# We will split the data into training, testing and validation sets\n",
    "from Utils import train_test_validation\n",
    "PROBLEM3_X_train, PROBLEM3_X_test, PROBLEM3_X_val, PROBLEM3_y_train, PROBLEM3_y_test, PROBLEM3_y_val = train_test_validation(X,Y,shuffle=True,random_state=1)\n",
    "\n",
    "# From this we will train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(PROBLEM3_X_train,PROBLEM3_y_train)\n",
    "\n",
    "# THE FOLLOWING CODE WILL PRODUCE THE ARRAYS YOU NEED FOR THE PROBLEM\n",
    "\n",
    "PROBLEM3_y_pred_proba_val = lr.predict_proba(PROBLEM3_X_val)[:,1]\n",
    "PROBLEM3_y_true_val = PROBLEM3_y_val\n",
    "\n",
    "PROBLEM3_y_pred_proba_test = lr.predict_proba(PROBLEM3_X_test)[:,1]\n",
    "PROBLEM3_y_true_test = PROBLEM3_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a9131",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c588e528",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1: 3 points\n",
    "\n",
    "# Implement the following function that calculates the cost of a binary classifier according to\n",
    "# the specification in the problem statement\n",
    "# See the comments inside the function for details of the parameters\n",
    "def cost(y_true, y_predict_proba, threshold):\n",
    "    # y_true is a numpy array of shape (n_samples,) with binary labels\n",
    "    # y_predict_proba is a numpy array of shape (n_samples,) with predicted probabilities\n",
    "    # threshold is a float between 0 and 1\n",
    "\n",
    "    # When returning the cost, you should return the average cost per sample\n",
    "    # thus it should be a value\n",
    "    y_pred = (y_predict_proba >= threshold).astype(int)\n",
    "    \n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    tp_cost = 100\n",
    "    tn_cost = 0\n",
    "    fp_cost = 120\n",
    "    fn_cost = 600\n",
    "    \n",
    "    n = len(y_true)\n",
    "    total_cost = ((tp * tp_cost) + (tn * tn_cost) + (fp * fp_cost) + (fn * fn_cost))\n",
    "    return total_cost / n  # A float\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "costs = []\n",
    "\n",
    "for t in thresholds:\n",
    "    problem1_cost = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, t)\n",
    "    costs.append(problem1_cost)\n",
    "\n",
    "# Provide the code below to plot the cost as a function of the threshold\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# The plot should be between 0 and 1 with 0.01 increments\n",
    "# The y-axis should be the cost and the x-axis should be the threshold\n",
    "\n",
    "plt.plot(thresholds, costs)\n",
    "plt.xlabel(\"Thresholds\")\n",
    "plt.ylabel(\"Costs for each threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc909e0d",
   "metadata": {},
   "source": [
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25387d22",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the best threshold found: 0.2 with this cost found: 43.15492957746479\n",
      "Best cost at best threshold: 43.15492957746479\n",
      "Precision 0: 0.9695767195767195 \n",
      "Precision 1: 0.7961165048543689 \n",
      "Recall 0: 0.9208542713567839 \n",
      "Recall 1: 0.9144981412639405\n"
     ]
    }
   ],
   "source": [
    "# Part 2: 2.5 points\n",
    "\n",
    "# Use the cost function you just implemented above to find the threshold that minimizes the cost\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the threshold in the variable below\n",
    "\n",
    "best_t = 0\n",
    "best_cost = np.inf\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "for t in thresholds:\n",
    "    true_cost = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, t)\n",
    "    \n",
    "    if (true_cost < best_cost):\n",
    "        best_cost = true_cost\n",
    "        best_t = t\n",
    "print(f\"This is the best threshold found: {best_t} with this cost found: {best_cost}\")\n",
    "\n",
    "problem3_threshold = best_t  # A float between 0 and 1\n",
    "\n",
    "# Now calculate the cost of the classifier using the validation data and the threshold you just found\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the cost in the variable below\n",
    "\n",
    "# This is also just the same as best_cost variable:\n",
    "problem3_cost_val = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, best_t)  # A float\n",
    "\n",
    "print(f\"Best cost at best threshold: {problem3_cost_val}\")\n",
    "\n",
    "# Using the threshold you just found, calculate the predicted labels of the classifier\n",
    "# on the validation data and put the predicted labels in the variable below\n",
    "# A numpy array of shape (n_samples,) with values 0 or 1\n",
    "problem3_y_pred_val = (PROBLEM3_y_pred_proba_val >= problem3_threshold).astype(int)\n",
    "\n",
    "# Calculate the precision and recall of the classifier of class 1 using the threshold you just found\n",
    "# Store in the variables below (floats between 0 and 1)\n",
    "\n",
    "\n",
    "\n",
    "problem3_precision_1 = precision_score(PROBLEM3_y_true_val, problem3_y_pred_val, pos_label=1)\n",
    "problem3_recall_1 = recall_score(PROBLEM3_y_true_val, problem3_y_pred_val, pos_label=1)\n",
    "\n",
    "# Calculate the precision and recall of the classifier of class 0 using the threshold you just found\n",
    "# Store in the variables below (floats between 0 and 1)\n",
    "problem3_precision_0 = precision_score(PROBLEM3_y_true_val, problem3_y_pred_val, pos_label=0)\n",
    "problem3_recall_0 = recall_score(PROBLEM3_y_true_val, problem3_y_pred_val, pos_label=0)\n",
    "\n",
    "print(f\"Precision 0: {problem3_precision_0} \\nPrecision 1: {problem3_precision_1} \\nRecall 0: {problem3_recall_0} \\nRecall 1: {problem3_recall_1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb681689",
   "metadata": {},
   "source": [
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0362a128",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold (min cost): 0.2\n",
      "Threshold (min 0-1 loss): 0.6900000000000001\n",
      "0-1 loss at min-0-1 threshold: 0.0647887323943662\n",
      "Cost at min-cost threshold: 43.15492957746479\n",
      "Cost at min-0-1 threshold: 54.08450704225352\n",
      "Difference in cost: 10.929577464788728\n"
     ]
    }
   ],
   "source": [
    "# Part 3: 2.5 points\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "thresholds_01 = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "best_01_t = 0.0\n",
    "best_01_loss = np.inf\n",
    "\n",
    "for t in thresholds_01:\n",
    "    # predicted labels at threshold t\n",
    "    y_pred = (PROBLEM3_y_pred_proba_val >= t).astype(int)\n",
    "\n",
    "    # 0-1 loss = misclassification rate\n",
    "    loss01 = np.mean(y_pred != PROBLEM3_y_true_val)\n",
    "\n",
    "    if loss01 < best_01_loss:\n",
    "        best_01_loss = loss01\n",
    "        best_01_t = t\n",
    "\n",
    "problem3_threshold_01 = best_01_t  # threshold minimizing 0-1 loss (validation)\n",
    "\n",
    "# --- difference in COST between part 2 threshold and part 3 threshold ---\n",
    "\n",
    "# part 2 threshold (min-cost) should already be stored as problem3_threshold\n",
    "cost_at_part2_threshold = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold)\n",
    "\n",
    "# cost at part 3 threshold (min 0-1 loss)\n",
    "cost_at_part3_threshold = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold_01)\n",
    "\n",
    "problem3_cost_difference = abs(cost_at_part2_threshold - cost_at_part3_threshold)\n",
    "\n",
    "print(\"Threshold (min cost):\", problem3_threshold)\n",
    "print(\"Threshold (min 0-1 loss):\", problem3_threshold_01)\n",
    "print(\"0-1 loss at min-0-1 threshold:\", best_01_loss)\n",
    "print(\"Cost at min-cost threshold:\", cost_at_part2_threshold)\n",
    "print(\"Cost at min-0-1 threshold:\", cost_at_part3_threshold)\n",
    "print(\"Difference in cost:\", problem3_cost_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18362c7a",
   "metadata": {},
   "source": [
    "4. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eb3d73e4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is lower bound: 17.734792363077773 \n",
      "This is upper bound: 67.67365834114759\n"
     ]
    }
   ],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "# Using the threshold problem3_threshold use Hoeffding's inequality to provide a confidence interval\n",
    "# for the cost of the classifier with 95 % confidence using the test data.\n",
    "# Specifically the arrays PROBLEM3_y_true_test and PROBLEM3_y_pred_proba_test.\n",
    "# Store the lower and upper bounds of the confidence interval in the variables below\n",
    "\n",
    "a,b = 0, 600\n",
    "alpha = 0.05\n",
    "n = len(PROBLEM3_y_true_test)\n",
    "\n",
    "cost_test_data = cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold)\n",
    "\n",
    "epsilon = (b-a) * np.sqrt(np.log(alpha/2) / (-2*n))\n",
    "\n",
    "lower = (cost_test_data - epsilon)\n",
    "upper = (cost_test_data + epsilon)\n",
    "\n",
    "problem3_lower_bound = lower  # A float\n",
    "problem3_upper_bound = upper  # A float\n",
    "\n",
    "print(f\"This is lower bound: {problem3_lower_bound} \\nThis is upper bound: {problem3_upper_bound}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67721024",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put your explanation for part 4 below this line in this **cell**. Doubleclick to enter edit mode as before.\n",
    "\n",
    "\n",
    "### Explanation of assumptions for Part 4\n",
    "\n",
    "To construct a $95\\%$ confidence interval for the expected cost on the test data, Hoeffding’s inequality was used. This approach relies on the following assumptions:\n",
    "\n",
    "1. **Bounded per-sample cost**  \n",
    "   Each individual prediction incurs a finite cost. From the problem specification, the possible costs per sample are:\n",
    "   - True Negative: $0$\n",
    "   - True Positive: $100$\n",
    "   - False Positive: $120$\n",
    "   - False Negative: $600$  \n",
    "   Hence, the per-sample cost random variable is bounded in the interval $[0, 600]$.\n",
    "\n",
    "2. **Independent and identically distributed samples (i.i.d.)**  \n",
    "   The test data samples are assumed to be independent and drawn from the same underlying distribution. This is required for Hoeffding’s inequality to hold.\n",
    "\n",
    "3. **Fixed decision threshold**  \n",
    "   The threshold used to compute the test cost was selected using the validation data and is treated as fixed when evaluating performance on the test set. The uncertainty in threshold selection is therefore not accounted for in the confidence interval.\n",
    "\n",
    "4. **Average cost as a sample mean**  \n",
    "   The reported test cost is the empirical mean of the per-sample costs. Hoeffding’s inequality provides a confidence interval for this mean without making any assumptions about the underlying distribution of the costs.\n",
    "\n",
    "5. **Distribution-free guarantee**  \n",
    "   No assumptions such as normality of the cost distribution are made. Hoeffding’s inequality is distribution-free, but this also means that the resulting confidence interval may be conservative.\n",
    "\n",
    "Under these assumptions, the constructed interval contains the true expected test cost with probability at least $95\\%$.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
