{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9c5ac5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 16th of June 2025, 13.00-18.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7eeac84",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"0015-AOG\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84a6b3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380e9b3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_rejection` in order to produce samples from the below distribution using rejection sampling: (Hint: $F$ is the distribution function)\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-x^2-1}{e-2}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it takes too long (more than 10 sec) and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. \n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2(e^{x^2}-1) x}{e-2} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_rejection_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093addd",
   "metadata": {},
   "source": [
    "## Rejection sampling for the distribution with CDF\n",
    "We are given the distribution function\n",
    "$$\n",
    "F[x] =\n",
    "\\begin{cases}\n",
    "0, & x \\le 0, \\\\\n",
    "\\dfrac{e^{x^2} - x^2 - 1}{e - 2}, & 0 < x < 1, \\\\\n",
    "1, & x \\ge 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We want to sample from this distribution using rejection sampling.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Density $( f(x) )$ from $( F(x) )$\n",
    "\n",
    "On $(0 < x < 1)$,\n",
    "$$\n",
    "F(x) = \\frac{e^{x^2} - x^2 - 1}{e - 2}.\n",
    "$$\n",
    "\n",
    "Differentiate:\n",
    "- $(\\frac{d}{dx} e^{x^2} = 2x e^{x^2})$,\n",
    "- $(\\frac{d}{dx}(-x^2) = -2x)$,\n",
    "- $(\\frac{d}{dx}(-1) = 0)$.\n",
    "\n",
    "Thus\n",
    "$$\n",
    "f(x) = F'(x)\n",
    "= \\frac{2x e^{x^2} - 2x}{e - 2}\n",
    "= \\frac{2x\\big(e^{x^2} - 1\\big)}{e - 2}, \\quad 0 < x < 1.\n",
    "$$\n",
    "\n",
    "Outside $((0,1))$, the density is zero. So\n",
    "$$\n",
    "f(x) =\n",
    "\\begin{cases}\n",
    "\\dfrac{2x\\big(e^{x^2} - 1\\big)}{e - 2}, & 0 < x < 1, \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Unnormalized target density\n",
    "\n",
    "For rejection sampling we use an unnormalized target\n",
    "$(\\tilde f(x))$ proportional to $(f(x))$. A convenient choice is\n",
    "to drop the constant factor $(2/(e-2))$ and use\n",
    "$$\n",
    "\\tilde f(x) = x\\big(e^{x^2} - 1\\big), \\quad 0 < x < 1,\n",
    "$$\n",
    "and $(\\tilde f(x) = 0)$ otherwise.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Proposal distribution $(g(x))$\n",
    "\n",
    "We choose the proposal\n",
    "$$\n",
    "X \\sim \\text{Uniform}(0,1).\n",
    "$$\n",
    "\n",
    "The corresponding proposal density is\n",
    "$$\n",
    "g(x) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\le x \\le 1, \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Find $( M )$ such that $( \\tilde f(x) \\le M g(x) )$\n",
    "\n",
    "Since $(g(x) = 1)$ on $([0,1])$, we need\n",
    "$$\n",
    "\\tilde f(x) \\le M \\quad \\text{for all } x \\in [0,1].\n",
    "$$\n",
    "\n",
    "Recall\n",
    "$$\n",
    "\\tilde f(x) = x\\big(e^{x^2} - 1\\big).\n",
    "$$\n",
    "\n",
    "Differentiate:\n",
    "$$\n",
    "\\tilde f'(x) = \\big(e^{x^2} - 1\\big) + x \\cdot 2x e^{x^2}\n",
    "= \\big(e^{x^2} - 1\\big) + 2x^2 e^{x^2}.\n",
    "$$\n",
    "\n",
    "For $(0 < x \\le 1)$, both terms are positive, hence\n",
    "$(\\tilde f'(x) > 0)$ on $((0,1])$. Thus $(\\tilde f(x))$ is\n",
    "increasing on $([0,1])$, and its maximum on $([0,1])$ occurs at\n",
    "$(x = 1)$:\n",
    "$$\n",
    "\\tilde f(1) = 1 \\cdot (e^1 - 1) = e - 1.\n",
    "$$\n",
    "\n",
    "Therefore we can choose\n",
    "$$\n",
    "M = e - 1.\n",
    "$$\n",
    "Then, for all $(x \\in [0,1])$,\n",
    "$$\n",
    "\\tilde f(x) \\le e - 1 = M.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Acceptance probability\n",
    "\n",
    "The acceptance condition in rejection sampling is\n",
    "$$\n",
    "U \\le \\frac{\\tilde f(X)}{M g(X)},\n",
    "$$\n",
    "where $(U \\sim \\text{Uniform}(0,1))$.\n",
    "\n",
    "Here,\n",
    "- $(\\tilde f(x) = x(e^{x^2} - 1))$,\n",
    "- $(g(x) = 1)$ on $([0,1])$,\n",
    "- $(M = e - 1)$.\n",
    "\n",
    "Thus the acceptance probability is\n",
    "$$\n",
    "\\alpha(x) = \\frac{\\tilde f(x)}{M g(x)}\n",
    "= \\frac{x\\big(e^{x^2} - 1\\big)}{e - 1}.\n",
    "$$\n",
    "\n",
    "By construction, $(0 \\le \\alpha(x) \\le 1)$ for $(x \\in [0,1])$.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Rejection sampling algorithm\n",
    "\n",
    "To generate one sample from the target distribution:\n",
    "\n",
    "1. Draw $(X \\sim \\text{Uniform}(0,1))$.\n",
    "2. Compute\n",
    "   $$\n",
    "   w = \\frac{X\\big(e^{X^2} - 1\\big)}{e - 1}.\n",
    "   $$\n",
    "3. Draw $(U \\sim \\text{Uniform}(0,1))$.\n",
    "4. If $(U \\le w)$, accept $(X)$ as a sample.\n",
    "5. Otherwise, reject $(X)$ and return to step 1.\n",
    "\n",
    "To obtain $(n_{\\text{samples}})$ values, repeat this procedure\n",
    "until you have accepted $(n_{\\text{samples}})$ samples.\n",
    "\n",
    "No normalization constant from the original $(F(x))$ is needed;\n",
    "we work entirely with $(\\tilde f(x))$ and the bound $(M)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec8402",
   "metadata": {},
   "source": [
    "### The acceptance rate is always 1 / M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0b7d2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51da2507",
   "metadata": {},
   "source": [
    "# This is actually the correct way to solve it:\n",
    "\n",
    "## Rejection sampling — step by step (with derivations)\n",
    "\n",
    "We are given the CDF\n",
    "\n",
    "$$\n",
    "F(x)=\n",
    "\\begin{cases}\n",
    "0, & x \\le 0,\\\\[4pt]\n",
    "\\dfrac{e^{x^2}-x^2-1}{e-2}, & 0<x<1,\\\\[6pt]\n",
    "1, & x \\ge 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Our goal is to sample from this distribution using the Accept–Reject (rejection sampling) method.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Derive the PDF $f(x)$ from the CDF $F(x)$\n",
    "\n",
    "On the interval $0<x<1$, the density is the derivative of the CDF:\n",
    "\n",
    "$$\n",
    "f(x)=F'(x).\n",
    "$$\n",
    "\n",
    "Differentiate:\n",
    "\n",
    "$$\n",
    "F(x)=\\frac{e^{x^2}-x^2-1}{e-2}.\n",
    "$$\n",
    "\n",
    "The denominator $(e-2)$ is constant, so\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{d}{dx}\\left(\\frac{e^{x^2}-x^2-1}{e-2}\\right)\n",
    "=\\frac{1}{e-2}\\frac{d}{dx}\\left(e^{x^2}-x^2-1\\right).\n",
    "$$\n",
    "\n",
    "Now compute the derivative in the numerator:\n",
    "\n",
    "- $\\frac{d}{dx}e^{x^2}=e^{x^2}\\cdot 2x$\n",
    "- $\\frac{d}{dx}(-x^2)=-2x$\n",
    "- $\\frac{d}{dx}(-1)=0$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}\\left(e^{x^2}-x^2-1\\right)=2x e^{x^2}-2x = 2x(e^{x^2}-1).\n",
    "$$\n",
    "\n",
    "Therefore, for $0<x<1$,\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{2x(e^{x^2}-1)}{e-2}.\n",
    "$$\n",
    "\n",
    "And $f(x)=0$ outside $[0,1]$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Choose a proposal density $g(x)$\n",
    "\n",
    "A simple valid choice is the uniform distribution on $[0,1]$:\n",
    "\n",
    "$$\n",
    "g(x)=1,\\quad 0<x<1.\n",
    "$$\n",
    "\n",
    "Sampling from $g$ means: draw $X \\sim \\text{Uniform}(0,1)$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Find a valid constant $M$ such that $f(x)\\le M g(x)$\n",
    "\n",
    "Since $g(x)=1$, we need\n",
    "\n",
    "$$\n",
    "M \\ge \\max_{x\\in[0,1]} f(x).\n",
    "$$\n",
    "\n",
    "We check where $f(x)$ is maximized.\n",
    "\n",
    "Write\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{2}{e-2}\\, x(e^{x^2}-1).\n",
    "$$\n",
    "\n",
    "The factor $\\frac{2}{e-2}$ is constant, so it’s enough to maximize\n",
    "\n",
    "$$\n",
    "h(x)=x(e^{x^2}-1).\n",
    "$$\n",
    "\n",
    "Differentiate $h(x)$:\n",
    "\n",
    "$$\n",
    "h'(x)=\\frac{d}{dx}\\left(x(e^{x^2}-1)\\right)\n",
    "=(e^{x^2}-1) + x\\cdot \\frac{d}{dx}(e^{x^2}-1).\n",
    "$$\n",
    "\n",
    "But $\\frac{d}{dx}(e^{x^2}-1)=2x e^{x^2}$, so\n",
    "\n",
    "$$\n",
    "h'(x)=(e^{x^2}-1) + x(2x e^{x^2})\n",
    "=(e^{x^2}-1)+2x^2 e^{x^2}\n",
    "=e^{x^2}(1+2x^2)-1.\n",
    "$$\n",
    "\n",
    "For $x>0$, $e^{x^2}(1+2x^2)-1 > 0$, so $h'(x)>0$ on $(0,1]$.\n",
    "\n",
    "That means $h(x)$ is increasing on $(0,1]$, so the maximum is at $x=1$.\n",
    "\n",
    "Compute $f(1)$:\n",
    "\n",
    "$$\n",
    "f(1)=\\frac{2\\cdot 1\\cdot (e^{1}-1)}{e-2}\n",
    "=\\frac{2(e-1)}{e-2}.\n",
    "$$\n",
    "\n",
    "So we can choose\n",
    "\n",
    "$$\n",
    "M=\\frac{2(e-1)}{e-2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Derive the acceptance probability (the $\\alpha$ / ratio)\n",
    "\n",
    "The accept–reject algorithm uses:\n",
    "\n",
    "$$\n",
    "\\text{accept if } U \\le \\frac{f(X)}{M g(X)},\n",
    "$$\n",
    "\n",
    "where $U\\sim\\text{Uniform}(0,1)$.\n",
    "\n",
    "Here $g(X)=1$, so\n",
    "\n",
    "$$\n",
    "\\alpha(X)=\\frac{f(X)}{M}.\n",
    "$$\n",
    "\n",
    "Plug in $f(X)$ and $M$:\n",
    "\n",
    "$$\n",
    "\\alpha(x)\n",
    "=\\frac{\\frac{2x(e^{x^2}-1)}{e-2}}{\\frac{2(e-1)}{e-2}}\n",
    "=\\frac{2x(e^{x^2}-1)}{e-2}\\cdot \\frac{e-2}{2(e-1)}\n",
    "=\\frac{x(e^{x^2}-1)}{e-1}.\n",
    "$$\n",
    "\n",
    "So the final acceptance rule is:\n",
    "\n",
    "$$\n",
    "\\text{accept if } U \\le \\frac{x(e^{x^2}-1)}{e-1}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5: Final rejection sampler (matches your code)\n",
    "\n",
    "Algorithm:\n",
    "\n",
    "1. Repeat until you have $n$ samples:\n",
    "   - Draw $X \\sim \\text{Uniform}(0,1)$\n",
    "   - Draw $U \\sim \\text{Uniform}(0,1)$\n",
    "   - Compute $\\alpha(X)=\\frac{X(e^{X^2}-1)}{e-1}$\n",
    "   - If $U \\le \\alpha(X)$, accept $X$\n",
    "\n",
    "Code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def problem1_rejection(n_samples):\n",
    "    samples = []\n",
    "    while len(samples) < n_samples:\n",
    "        x = np.random.uniform(0, 1)   # proposal sample from g\n",
    "        u = np.random.uniform(0, 1)   # uniform for accept/reject\n",
    "\n",
    "        alpha = x * (np.exp(x**2) - 1) / (np.e - 1)  # f(x)/(M*g(x))\n",
    "\n",
    "        if u <= alpha:\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918d2b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53ddf095",
   "metadata": {},
   "source": [
    "# This is how to choose a better gx:\n",
    "\n",
    "## How to choose a better proposal $g(x)$ and derive $M$ (step by step)\n",
    "\n",
    "We want to sample from the target density $f(x)$ on $0<x<1$, given by the CDF\n",
    "\n",
    "$$\n",
    "F(x)=\\frac{e^{x^2}-x^2-1}{e-2},\\quad 0<x<1.\n",
    "$$\n",
    "\n",
    "### 1) Derive the target PDF $f(x)$\n",
    "Differentiate $F(x)$:\n",
    "\n",
    "$$\n",
    "f(x)=F'(x)=\\frac{1}{e-2}\\frac{d}{dx}\\left(e^{x^2}-x^2-1\\right).\n",
    "$$\n",
    "\n",
    "Compute the derivative inside:\n",
    "\n",
    "$$\n",
    "\\frac{d}{dx}(e^{x^2})=2x e^{x^2},\\quad \\frac{d}{dx}(-x^2)=-2x,\\quad \\frac{d}{dx}(-1)=0.\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{1}{e-2}\\left(2x e^{x^2}-2x\\right)=\\frac{2x(e^{x^2}-1)}{e-2},\\quad 0<x<1.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Why Uniform is not ideal\n",
    "If we pick $g(x)=1$ (Uniform$(0,1)$), the density $f(x)$ is heavily increasing and puts most mass near $x=1$.\n",
    "Uniform wastes many proposals in regions where $f$ is small, leading to more rejections.\n",
    "\n",
    "So we want a proposal $g(x)$ that looks more like $f(x)$: increasing on $(0,1)$ and concentrating mass near 1.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Choose a better $g(x)$ by matching the behavior near $x=0$\n",
    "\n",
    "A common and effective technique:\n",
    "- Expand $f(x)$ near $x=0$ using a Taylor approximation.\n",
    "- Pick a proposal $g(x)$ with the same leading-order behavior.\n",
    "\n",
    "Use the series:\n",
    "\n",
    "$$\n",
    "e^{x^2}-1 = x^2 + O(x^4).\n",
    "$$\n",
    "\n",
    "Insert into $f(x)$:\n",
    "\n",
    "$$\n",
    "f(x)=\\frac{2x(e^{x^2}-1)}{e-2}\n",
    "=\\frac{2x(x^2+O(x^4))}{e-2}\n",
    "=\\frac{2x^3}{e-2}+O(x^5).\n",
    "$$\n",
    "\n",
    "So near $x=0$,\n",
    "\n",
    "$$\n",
    "f(x)\\propto x^3.\n",
    "$$\n",
    "\n",
    "That suggests choosing a proposal that behaves like $x^3$ on $[0,1]$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Pick a proposal density $g(x)$ that matches $x^3$\n",
    "\n",
    "A simple valid PDF on $(0,1)$ with this shape is:\n",
    "\n",
    "$$\n",
    "g(x)=4x^3,\\quad 0<x<1.\n",
    "$$\n",
    "\n",
    "This is exactly the Beta$(4,1)$ distribution, since Beta$(a,b)$ has PDF proportional to $x^{a-1}(1-x)^{b-1}$.\n",
    "Here $a-1=3 \\Rightarrow a=4$, and $b=1$.\n",
    "\n",
    "Check it integrates to 1:\n",
    "\n",
    "$$\n",
    "\\int_0^1 4x^3\\,dx = 4\\cdot \\frac{1}{4}=1.\n",
    "$$\n",
    "\n",
    "So $g$ is a valid proposal density.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Compute the rejection constant $M$\n",
    "\n",
    "In rejection sampling, we need a constant $M$ such that\n",
    "\n",
    "$$\n",
    "f(x) \\le M g(x)\\quad \\text{for all } x\\in(0,1).\n",
    "$$\n",
    "\n",
    "Equivalently,\n",
    "\n",
    "$$\n",
    "M \\ge \\max_{x\\in(0,1)} \\frac{f(x)}{g(x)}.\n",
    "$$\n",
    "\n",
    "Compute the ratio:\n",
    "\n",
    "$$\n",
    "\\frac{f(x)}{g(x)}\n",
    "=\\frac{\\frac{2x(e^{x^2}-1)}{e-2}}{4x^3}\n",
    "=\\frac{e^{x^2}-1}{2(e-2)x^2}.\n",
    "$$\n",
    "\n",
    "Call this ratio $R(x)$:\n",
    "\n",
    "$$\n",
    "R(x)=\\frac{e^{x^2}-1}{2(e-2)x^2}.\n",
    "$$\n",
    "\n",
    "To find $M$, we need the maximum of $R(x)$ on $(0,1)$.\n",
    "\n",
    "A key observation: $R(x)$ is increasing on $(0,1)$, so its maximum is at $x=1$.\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "M = R(1).\n",
    "$$\n",
    "\n",
    "Evaluate at $x=1$:\n",
    "\n",
    "$$\n",
    "M=\\frac{e^{1}-1}{2(e-2)\\cdot 1^2}=\\frac{e-1}{2(e-2)}.\n",
    "$$\n",
    "\n",
    "So a valid choice is\n",
    "\n",
    "$$\n",
    "M=\\frac{e-1}{2(e-2)} \\approx 1.196.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Derive the acceptance probability $\\alpha(x)$\n",
    "\n",
    "Accept–reject uses:\n",
    "\n",
    "$$\n",
    "\\alpha(x)=\\frac{f(x)}{M g(x)}.\n",
    "$$\n",
    "\n",
    "We already have:\n",
    "\n",
    "$$\n",
    "\\frac{f(x)}{g(x)}=\\frac{e^{x^2}-1}{2(e-2)x^2},\\quad\n",
    "M=\\frac{e-1}{2(e-2)}.\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\alpha(x)=\\frac{\\frac{f(x)}{g(x)}}{M}\n",
    "=\\frac{\\frac{e^{x^2}-1}{2(e-2)x^2}}{\\frac{e-1}{2(e-2)}}\n",
    "=\\frac{e^{x^2}-1}{(e-1)x^2}.\n",
    "$$\n",
    "\n",
    "Thus the accept rule is:\n",
    "\n",
    "$$\n",
    "\\text{accept if } U \\le \\frac{e^{X^2}-1}{(e-1)X^2},\n",
    "$$\n",
    "\n",
    "where $U\\sim\\text{Uniform}(0,1)$ and $X\\sim g$ (Beta$(4,1)$).\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Why this is better (acceptance rate intuition)\n",
    "\n",
    "In accept–reject, the average acceptance rate is approximately $1/M$ if $M$ is tight.\n",
    "\n",
    "Here:\n",
    "\n",
    "$$\n",
    "\\text{acceptance} \\approx \\frac{1}{M}=\\frac{2(e-2)}{e-1}\\approx 0.836.\n",
    "$$\n",
    "\n",
    "So we expect about **84%** acceptance, much better than Uniform$(0,1)$ (about 21%).\n",
    "\n",
    "---\n",
    "\n",
    "## Final result (summary)\n",
    "\n",
    "- Target density:\n",
    "  $$\n",
    "  f(x)=\\frac{2x(e^{x^2}-1)}{e-2}.\n",
    "  $$\n",
    "- Better proposal:\n",
    "  $$\n",
    "  g(x)=4x^3 \\quad (\\text{Beta}(4,1)).\n",
    "  $$\n",
    "- Rejection constant:\n",
    "  $$\n",
    "  M=\\frac{e-1}{2(e-2)}.\n",
    "  $$\n",
    "- Acceptance probability:\n",
    "  $$\n",
    "  \\alpha(x)=\\frac{e^{x^2}-1}{(e-1)x^2}.\n",
    "  $$\n",
    "\n",
    "\n",
    "### This results in this code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def problem1_rejection(n_samples):\n",
    "    samples = []\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        # Proposal from g(x) = 4x^3  (Beta(4,1))\n",
    "        u = np.random.uniform(0, 1)\n",
    "        x = u ** 0.25\n",
    "\n",
    "        # Uniform for accept/reject\n",
    "        v = np.random.uniform(0, 1)\n",
    "\n",
    "        # Acceptance probability\n",
    "        alpha = (np.exp(x**2) - 1) / ((np.e - 1) * x**2)\n",
    "\n",
    "        if v <= alpha:\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254b76f4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 1\n",
    "import numpy as np\n",
    "\n",
    "def problem1_rejection(n_samples=1):\n",
    "    \"\"\"\n",
    "    Rejection sampling for the distribution with CDF\n",
    "        F[x] = 0,                           x <= 0\n",
    "        F[x] = (e^{x^2} - x^2 - 1)/(e - 2), 0 < x < 1\n",
    "        F[x] = 1,                           x >= 1\n",
    "\n",
    "    We use:\n",
    "        tilde f(x) = x * (e^{x^2} - 1)  on (0,1),\n",
    "        proposal g(x) = Uniform(0,1),\n",
    "        M = e - 1.\n",
    "\n",
    "    Acceptance probability:\n",
    "        alpha(x) = tilde f(x) / (M * g(x))\n",
    "                  = x * (e^{x^2} - 1) / (e - 1).\n",
    "    \"\"\"\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        # 1. Sample from the proposal: Uniform(0, 1)\n",
    "        x = np.random.uniform(0.0, 1.0)\n",
    "\n",
    "        # 2. Compute the acceptance weight:\n",
    "        #    w = tilde f(x) / M = x * (e^{x^2} - 1) / (e - 1)\n",
    "        w = x * (np.exp(x**2) - 1.0) / (np.e - 1.0)\n",
    "\n",
    "        # 3. Sample U ~ Uniform(0,1) for acceptance\n",
    "        u = np.random.uniform(0.0, 1.0)\n",
    "\n",
    "        # 4. Accept if u <= w\n",
    "        if u <= w:\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0337cb",
   "metadata": {},
   "source": [
    "2. [2p] Produce 100000 samples (**use fewer if it takes too long (more than 10 sec) and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c66f4862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Part 2: Generate samples and plot histogram with true density ---\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Produce 100000 samples\n",
    "problem1_samples = problem1_rejection(n_samples=100000)\n",
    "\n",
    "# 2. True density f(x) = 2x(e^{x^2} - 1)/(e - 2)\n",
    "def true_density(x):\n",
    "    return 2 * x * (np.exp(x**2) - 1) / (np.e - 2)\n",
    "\n",
    "# 3. Plot histogram + true density\n",
    "x_grid = np.linspace(0, 1, 400)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(problem1_samples, bins=100, range=(0, 1), density=True,\n",
    "         alpha=0.55, label=\"Sample histogram\")\n",
    "\n",
    "plt.plot(x_grid, true_density(x_grid), 'r', linewidth=2,\n",
    "         label=\"True density\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Rejection Sampling: Histogram vs True Density\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae81bef",
   "metadata": {},
   "source": [
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2(e^{x^2}-1) x}{e-2} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e3e83",
   "metadata": {},
   "source": [
    "### Part 3 – Monte Carlo approximation of the integral\n",
    "\n",
    "We want to approximate the integral  \n",
    "$$\n",
    "I = \\int_0^{1} \\sin(x)\\,\\frac{2(e^{x^2}-1)x}{e-2}\\,dx.\n",
    "$$\n",
    "\n",
    "From Part 1–2, we know that  \n",
    "$$\n",
    "f(x) = \\frac{2(e^{x^2}-1)x}{e-2}, \\quad 0 < x < 1\n",
    "$$  \n",
    "is the **density** of the distribution from which our samples `problem1_samples` are drawn.\n",
    "\n",
    "So if  \n",
    "$$\n",
    "X \\sim f(x),\n",
    "$$  \n",
    "then the integral can be written as an **expectation**:\n",
    "$$\n",
    "I = \\int_0^{1} \\sin(x) f(x)\\, dx = \\mathbb{E}[\\sin(X)].\n",
    "$$\n",
    "\n",
    "We can approximate this expectation using the **sample mean** of $(\\sin(X_i))$, where $(X_i)$ are our simulated samples:\n",
    "\n",
    "1. We already have $(X_1, \\dots, X_n)$ stored in `problem1_samples`, with $(n = 100000)$.\n",
    "2. Compute $(\\sin(X_i))$ for each sample.\n",
    "3. Take the average:\n",
    "   $$\n",
    "   \\hat{I} = \\frac{1}{n} \\sum_{i=1}^n \\sin(X_i).\n",
    "   $$\n",
    "4. Store this approximation in the variable `problem1_integral`.\n",
    "\n",
    "Below is the commented Python code that implements this:\n",
    "\n",
    "```python\n",
    "# Part 3: Monte Carlo approximation of the integral\n",
    "# Integral:\n",
    "#   ∫_0^1 sin(x) * [2 (e^{x^2} - 1) x / (e - 2)] dx\n",
    "#\n",
    "# If X has density f(x) = 2 (e^{x^2} - 1) x / (e - 2) on (0,1),\n",
    "# then the integral equals E[sin(X)].\n",
    "# We approximate this expectation using the samples in `problem1_samples`\n",
    "# generated in Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee469d6",
   "metadata": {},
   "source": [
    "### Monte Carlo integration using rejection samples\n",
    "\n",
    "The samples stored in `problem1_samples` are already drawn from the target density\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{2x(e^{x^2}-1)}{e-2}, \\quad x \\in [0,1].\n",
    "$$\n",
    "\n",
    "The integral we want to compute is\n",
    "\n",
    "$$\n",
    "\\int_0^1 \\sin(x)\\, f(x)\\, dx.\n",
    "$$\n",
    "\n",
    "By definition, this integral is the **expectation of $\\sin(X)$** when  \n",
    "$X \\sim f$:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_f[\\sin(X)].\n",
    "$$\n",
    "\n",
    "Since Monte Carlo integration approximates expectations by sample averages,\n",
    "and the samples are already distributed according to $f$, we **must not**\n",
    "multiply by the density again.\n",
    "\n",
    "Therefore, the correct Monte Carlo estimator is\n",
    "\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^n \\sin(x_i),\n",
    "$$\n",
    "\n",
    "which in code becomes:\n",
    "```python\n",
    "problem1_integral = np.mean(np.sin(problem1_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb7b40f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.7229557819365732)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# problem1_samples is assumed to be already created in Part 2\n",
    "# problem1_samples = problem1_rejection(n_samples=100000)\n",
    "\n",
    "# Compute sin(X_i) for each sample X_i in problem1_samples\n",
    "sin_values = np.sin(problem1_samples)\n",
    "\n",
    "# Monte Carlo estimate of the integral: mean of sin(X_i)\n",
    "problem1_integral = np.mean(sin_values)\n",
    "\n",
    "problem1_integral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176adb46",
   "metadata": {},
   "source": [
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2750d74",
   "metadata": {},
   "source": [
    "### Part 4 – 95% confidence interval using Hoeffding’s inequality\n",
    "\n",
    "From Part 3, we have approximated the integral\n",
    "$$\n",
    "I = \\int_0^{1} \\sin(x)\\,\\frac{2(e^{x^2}-1)x}{e-2}\\,dx\n",
    "= \\mathbb{E}[\\sin(X)],\n",
    "$$\n",
    "where $(X)$ has density\n",
    "$$\n",
    "f(x) = \\frac{2(e^{x^2}-1)x}{e-2}, \\quad 0 < x < 1.\n",
    "$$\n",
    "\n",
    "We estimated this integral using\n",
    "$$\n",
    "\\hat{I} = \\frac{1}{n} \\sum_{i=1}^n \\sin(X_i),\n",
    "$$\n",
    "where $(X_1, \\dots, X_n)$ are the samples in `problem1_samples`, and `problem1_integral` is this Monte Carlo estimate:\n",
    "$$\n",
    "\\hat{I} \\approx I.\n",
    "$$\n",
    "\n",
    "To get a **95% confidence interval** using **Hoeffding’s inequality**, we use that  \n",
    "$(Y_i = \\sin(X_i))$ is bounded.  \n",
    "For $(x \\in [0,1])$, we have\n",
    "$$\n",
    "0 \\leq \\sin(x) \\leq 1,\n",
    "$$\n",
    "so we can take the bounds\n",
    "$$\n",
    "a = 0, \\quad b = 1.\n",
    "$$\n",
    "\n",
    "**Hoeffding’s inequality** for the sample mean $(\\bar{Y} = \\frac{1}{n}\\sum_{i=1}^n Y_i)$ says:\n",
    "$$\n",
    "\\mathbb{P}\\left( |\\bar{Y} - \\mathbb{E}[Y]| \\ge \\varepsilon \\right)\n",
    "\\le 2 \\exp\\left( -\\frac{2 n \\varepsilon^2}{(b-a)^2} \\right).\n",
    "$$\n",
    "\n",
    "We want a **95%** confidence interval, so we set\n",
    "$$\n",
    "\\delta = 0.05,\n",
    "$$\n",
    "and choose $(\\varepsilon)$ such that\n",
    "$$\n",
    "2 \\exp\\left( -\\frac{2 n \\varepsilon^2}{(b-a)^2} \\right) = \\delta.\n",
    "$$\n",
    "\n",
    "Solving for $(\\varepsilon)$:\n",
    "$$\n",
    "\\varepsilon\n",
    "= \\sqrt{ \\frac{(b-a)^2}{2n} \\ln\\left( \\frac{2}{\\delta} \\right) }.\n",
    "$$\n",
    "\n",
    "Since $(a = 0)$ and $(b = 1)$, we get\n",
    "$$\n",
    "\\varepsilon\n",
    "= \\sqrt{ \\frac{1}{2n} \\ln\\left( \\frac{2}{\\delta} \\right) }.\n",
    "$$\n",
    "\n",
    "With $(\\delta = 0.05)$, this becomes\n",
    "$$\n",
    "\\varepsilon\n",
    "= \\sqrt{ \\frac{1}{2n} \\ln(40) }.\n",
    "$$\n",
    "\n",
    "Finally, using our estimate $(\\hat{I} = \\texttt{problem1\\_integral})$, the **Hoeffding 95% confidence interval** is\n",
    "$$\n",
    "\\left[\\, \\hat{I} - \\varepsilon,\\; \\hat{I} + \\varepsilon \\,\\right].\n",
    "$$\n",
    "\n",
    "In code, we:\n",
    "1. Set $(n = \\texttt{len(problem1\\_samples)})$.\n",
    "2. Set $(\\delta = 0.05)$.\n",
    "3. Compute $(\\varepsilon)$ using the formula above.\n",
    "4. Form the tuple\n",
    "   $$\n",
    "   \\texttt{problem1\\_interval} = (\\hat{I} - \\varepsilon,\\; \\hat{I} + \\varepsilon).\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc01e0d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.7186610878531058), np.float64(0.7272504760200406))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 4: 95% Hoeffding confidence interval for the integral\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# We assume:\n",
    "# - problem1_samples already exists (from Part 2)\n",
    "# - problem1_integral already exists (from Part 3) and is the sample mean of sin(X)\n",
    "\n",
    "n = len(problem1_samples)   # number of samples used in the Monte Carlo estimate\n",
    "delta = 0.05                # 1 - confidence level = 0.05 for 95% confidence\n",
    "\n",
    "# Bounds for Y_i = sin(X_i) when X_i in [0, 1]:\n",
    "a = 0.0\n",
    "b = 1.0\n",
    "\n",
    "# Hoeffding epsilon:\n",
    "# epsilon = sqrt( ((b - a)^2 / (2n)) * log(2 / delta) )\n",
    "epsilon = np.sqrt(((b - a)**2 / (2.0 * n)) * np.log(2.0 / delta))\n",
    "\n",
    "# Construct the 95% confidence interval around the Monte Carlo estimate\n",
    "lower_bound = problem1_integral - epsilon\n",
    "upper_bound = problem1_integral + epsilon\n",
    "\n",
    "# Store as a tuple, as requested\n",
    "problem1_interval = (lower_bound, upper_bound)\n",
    "\n",
    "problem1_interval\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e80e36",
   "metadata": {},
   "source": [
    "5. [4p] Fill in the remaining part of the function `problem1_rejection_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be568fd",
   "metadata": {},
   "source": [
    "### Part 5 – Rejection sampling for the second distribution\n",
    "\n",
    "We are given the distribution with CDF\n",
    "$$\n",
    "F(x) =\n",
    "\\begin{cases}\n",
    "0, & x \\le 0 \\\\\n",
    "20x e^{20 - 1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "1, & x \\ge \\frac{1}{20}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "We want to construct a rejection sampler `problem1_rejection_2` that generates samples from this distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Find the density $( f(x) )$\n",
    "\n",
    "For $(0 < x < 1/20)$,\n",
    "$$\n",
    "F(x) = 20x e^{20 - 1/x}.\n",
    "$$\n",
    "\n",
    "Differentiate to get the density:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(x) &= \\frac{d}{dx} \\Big( 20x e^{20 - 1/x} \\Big) \\\\\n",
    "     &= 20 e^{20 - 1/x} + 20x e^{20 - 1/x} \\cdot \\frac{d}{dx}(20 - 1/x) \\\\\n",
    "     &= 20 e^{20 - 1/x} + 20x e^{20 - 1/x} \\cdot \\frac{1}{x^2} \\\\\n",
    "     &= 20 e^{20 - 1/x} + 20 e^{20 - 1/x} \\cdot \\frac{1}{x} \\\\\n",
    "     &= 20 e^{20 - 1/x} \\left( 1 + \\frac{1}{x} \\right).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So\n",
    "$$\n",
    "f(x) = 20 e^{20 - 1/x} \\left( 1 + \\frac{1}{x} \\right), \\quad 0 < x < \\frac{1}{20}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Choose a clever proposal distribution $( g(x) )$\n",
    "\n",
    "We want a proposal $(g(x))$ that:\n",
    "\n",
    "- has the same support $((0, 1/20))$,\n",
    "- is easy to **sample from**,\n",
    "- and makes the ratio $(f(x)/g(x))$ bounded by a small constant $(M)$.\n",
    "\n",
    "Consider the density\n",
    "$$\n",
    "g(x) = \\frac{e^{20 - 1/x}}{x^2}, \\quad 0 < x < \\frac{1}{20}.\n",
    "$$\n",
    "\n",
    "First check it is a valid density by integrating:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int_0^{1/20} g(x)\\,dx \n",
    "&= \\int_0^{1/20} \\frac{e^{20 - 1/x}}{x^2} \\, dx \\\\\n",
    "&= e^{20} \\int_0^{1/20} \\frac{e^{-1/x}}{x^2} \\, dx.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Use the substitution $(t = 1/x)$, so $(dt = -\\frac{1}{x^2} dx)$, hence\n",
    "$$\n",
    "\\int_0^{1/20} \\frac{e^{-1/x}}{x^2} dx\n",
    "= \\int_{\\infty}^{20} -e^{-t} dt\n",
    "= \\int_{20}^{\\infty} e^{-t} dt\n",
    "= e^{-20}.\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "$$\n",
    "\\int_0^{1/20} g(x)\\,dx\n",
    "= e^{20} \\cdot e^{-20} = 1,\n",
    "$$\n",
    "so $(g(x))$ is indeed a valid density.\n",
    "\n",
    "Now compute its CDF:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G(x)\n",
    "&= \\int_0^{x} g(u)\\,du \\\\\n",
    "&= e^{20} \\int_0^x \\frac{e^{-1/u}}{u^2} du \\\\\n",
    "&= e^{20} \\int_{\\infty}^{1/x} -e^{-t} dt \\\\\n",
    "&= e^{20} \\int_{1/x}^{\\infty} e^{-t} dt \\\\\n",
    "&= e^{20} \\cdot e^{-1/x} \\\\\n",
    "&= e^{20 - 1/x}, \\quad 0 < x < \\frac{1}{20}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So the proposal distribution has CDF\n",
    "$$\n",
    "G(x) = e^{20 - 1/x}.\n",
    "$$\n",
    "\n",
    "This is **very convenient** because we can invert it explicitly:\n",
    "\n",
    "Let $(U \\sim \\text{Uniform}(0, 1))$. Then to sample from $(g)$, we solve\n",
    "$$\n",
    "U = G(x) = e^{20 - 1/x}.\n",
    "$$\n",
    "\n",
    "Take logs:\n",
    "$$\n",
    "\\ln U = 20 - \\frac{1}{x}\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\frac{1}{x} = 20 - \\ln U\n",
    "\\quad \\Rightarrow \\quad\n",
    "x = \\frac{1}{20 - \\ln U}.\n",
    "$$\n",
    "\n",
    "Thus, the proposal sampling step is:\n",
    "- Draw $(U \\sim \\text{Uniform}(0, 1))$,\n",
    "- Set\n",
    "  $$\n",
    "  X_{\\text{prop}} = \\frac{1}{20 - \\ln U}.\n",
    "  $$\n",
    "\n",
    "This always lies in $((0, 1/20])$.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Compute the ratio $( \\frac{f(x)}{g(x)} )$ and find $(M)$\n",
    "\n",
    "We have\n",
    "$$\n",
    "f(x) = 20 e^{20 - 1/x} \\left( 1 + \\frac{1}{x} \\right),\n",
    "\\quad\n",
    "g(x) = \\frac{e^{20 - 1/x}}{x^2}.\n",
    "$$\n",
    "\n",
    "Then\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{f(x)}{g(x)}\n",
    "&= \\frac{20 e^{20 - 1/x} \\left( 1 + \\frac{1}{x} \\right)}{e^{20 - 1/x} / x^2} \\\\\n",
    "&= 20 x^2 \\left( 1 + \\frac{1}{x} \\right) \\\\\n",
    "&= 20 x^2 + 20 x.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Define\n",
    "$$\n",
    "h(x) = 20 x^2 + 20 x, \\quad 0 < x \\le \\frac{1}{20}.\n",
    "$$\n",
    "\n",
    "This function is increasing on $((0, 1/20])$, so its maximum is at $(x = 1/20)$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "h\\left(\\frac{1}{20}\\right)\n",
    "&= 20 \\left(\\frac{1}{20}\\right)^2 + 20 \\cdot \\frac{1}{20} \\\\\n",
    "&= 20 \\cdot \\frac{1}{400} + 1 \\\\\n",
    "&= \\frac{20}{400} + 1 \\\\\n",
    "&= \\frac{1}{20} + 1 \\\\\n",
    "&= \\frac{21}{20}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus we can take\n",
    "$$\n",
    "M = \\frac{21}{20}.\n",
    "$$\n",
    "\n",
    "The acceptance probability is\n",
    "$$\n",
    "\\alpha(x) = \\frac{f(x)}{M g(x)} = \\frac{20x^2 + 20x}{M}.\n",
    "$$\n",
    "\n",
    "With $(M = 21/20)$, this is\n",
    "$$\n",
    "\\alpha(x) = \\frac{20x^2 + 20x}{21/20}\n",
    "= \\frac{400x^2 + 400x}{21},\n",
    "$$\n",
    "which is always $(\\le 1)$ on $((0, 1/20])$.\n",
    "\n",
    "The **expected acceptance rate** is approximately $(1/M = 20/21 \\approx 0.95)$, so this is a very efficient rejection sampler (matching the hint).\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Algorithm for `problem1_rejection_2`\n",
    "\n",
    "To generate $(n)$ samples:\n",
    "\n",
    "1. Initialize an empty list `samples`.\n",
    "2. While `len(samples) < n_samples`:\n",
    "   - Draw $(U_1 \\sim \\text{Uniform}(0, 1))$.\n",
    "   - Compute proposal\n",
    "     $$\n",
    "     x = \\frac{1}{20 - \\ln(U_1)}.\n",
    "     $$\n",
    "   - Compute the acceptance weight:\n",
    "     $$\n",
    "     w = \\frac{20x^2 + 20x}{M}, \\quad M = \\frac{21}{20}.\n",
    "     $$\n",
    "   - Draw $(U_2 \\sim \\text{Uniform}(0, 1))$.\n",
    "   - If $(U_2 \\le w)$, **accept** and append `x` to `samples`.\n",
    "3. Return the samples as a NumPy array.\n",
    "\n",
    "This implements rejection sampling from the target density $(f(x))$ with a proposal $(g(x))$ that is very close in shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef73e41",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def problem1_rejection_2(n_samples=1):\n",
    "    \"\"\"\n",
    "    Rejection sampling for the distribution with CDF\n",
    "        F[x] = 0,                         x <= 0\n",
    "        F[x] = 20 x e^{20 - 1/x},         0 < x < 1/20\n",
    "        F[x] = 1,                         x >= 1/20\n",
    "\n",
    "    Target density on (0, 1/20):\n",
    "        f(x) = 20 * exp(20 - 1/x) * (1 + 1/x).\n",
    "\n",
    "    Proposal density g(x) on (0, 1/20):\n",
    "        g(x) = exp(20 - 1/x) / x^2,\n",
    "    with CDF\n",
    "        G(x) = exp(20 - 1/x).\n",
    "\n",
    "    Sampling from g:\n",
    "        If U ~ Uniform(0,1), then\n",
    "        X = 1 / (20 - log(U))  ~ g.\n",
    "\n",
    "    Ratio:\n",
    "        f(x) / g(x) = 20 * x^2 + 20 * x.\n",
    "\n",
    "    We choose M = 21/20 >= sup_x f(x)/g(x).\n",
    "    Acceptance probability:\n",
    "        alpha(x) = f(x) / (M * g(x))\n",
    "                  = (20 * x**2 + 20 * x) / M.\n",
    "    \"\"\"\n",
    "\n",
    "    samples = []\n",
    "    M = 21.0 / 20.0  # rejection constant\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        # 1. Sample from proposal g via inverse CDF\n",
    "        u1 = np.random.uniform(0.0, 1.0)\n",
    "        # Avoid log(0); u1 in (0,1) anyway for continuous Uniform\n",
    "        x = 1.0 / (20.0 - np.log(u1))\n",
    "\n",
    "        # 2. Compute acceptance weight w = f(x) / (M * g(x))\n",
    "        #    but we use the simplified ratio: f(x)/g(x) = 20x^2 + 20x\n",
    "        ratio = 20.0 * x**2 + 20.0 * x\n",
    "        w = ratio / M  # in [0,1]\n",
    "\n",
    "        # 3. Accept/reject\n",
    "        u2 = np.random.uniform(0.0, 1.0)\n",
    "        if u2 <= w:\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "\n",
    "\n",
    "#420.0\n",
    "#10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77cd1aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63520631",
   "metadata": {},
   "source": [
    "## Problem 1.5 — how to choose a *better* proposal $g$\n",
    "\n",
    "We are given the CDF\n",
    "$$\n",
    "F(x)=\n",
    "\\begin{cases}\n",
    "0, & x \\le 0, \\\\\n",
    "20x e^{20-1/x}, & 0 < x < \\frac{1}{20}, \\\\\n",
    "1, & x \\ge \\frac{1}{20}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 1) First convert the CDF to a PDF\n",
    "For $0 < x < \\frac{1}{20}$,\n",
    "$$\n",
    "f_X(x) = F'(x).\n",
    "$$\n",
    "Differentiate:\n",
    "$$\n",
    "F(x) = 20x e^{20-1/x}.\n",
    "$$\n",
    "Using the product rule,\n",
    "$$\n",
    "f_X(x)=20e^{20-1/x} + 20x e^{20-1/x}\\cdot \\frac{1}{x^2}\n",
    "      = 20 e^{20-1/x}\\left(1+\\frac{1}{x}\\right).\n",
    "$$\n",
    "\n",
    "### 2) Why Uniform $(0,1/20)$ is not great\n",
    "If we choose $g_X(x)=20$ on $(0,1/20)$ (Uniform proposal), then\n",
    "$$\n",
    "\\frac{f_X(x)}{g_X(x)} = e^{20-1/x}\\left(1+\\frac{1}{x}\\right).\n",
    "$$\n",
    "This ratio is maximized at $x=1/20$:\n",
    "$$\n",
    "e^{20-20}(1+20)=21,\n",
    "$$\n",
    "so we must take $M=21$, giving acceptance rate about $1/21 \\approx 4.8\\%$ (slow).\n",
    "\n",
    "### 3) The trick: transform variables to make the distribution easy\n",
    "Notice the term $e^{20-1/x}$ contains $1/x$, so let\n",
    "$$\n",
    "Y=\\frac{1}{X}.\n",
    "$$\n",
    "Then $Y \\in (20,\\infty)$ since $0<X<1/20$.\n",
    "\n",
    "Use change-of-variables:\n",
    "$$\n",
    "f_Y(y) = f_X(1/y)\\left|\\frac{d(1/y)}{dy}\\right| = f_X(1/y)\\cdot \\frac{1}{y^2}.\n",
    "$$\n",
    "Compute $f_X(1/y)$:\n",
    "- $e^{20-1/(1/y)} = e^{20-y}$\n",
    "- $1+\\frac{1}{1/y} = 1+y$\n",
    "\n",
    "So\n",
    "$$\n",
    "f_Y(y)=20 e^{20-y}(1+y)\\cdot\\frac{1}{y^2}\n",
    "      =20 e^{20-y}\\left(\\frac{1}{y}+\\frac{1}{y^2}\\right),\\quad y>20.\n",
    "$$\n",
    "Rewrite $e^{20-y}=e^{-(y-20)}$:\n",
    "$$\n",
    "f_Y(y)=20 e^{-(y-20)}\\left(\\frac{1}{y}+\\frac{1}{y^2}\\right),\\quad y>20.\n",
    "$$\n",
    "\n",
    "### 4) Choose a proposal $g_Y$ that matches the main shape\n",
    "The main shape is the exponential term $e^{-(y-20)}$, so choose:\n",
    "$$\n",
    "g_Y(y)=e^{-(y-20)},\\quad y\\ge 20,\n",
    "$$\n",
    "which is exactly a shifted exponential: $Y = 20 + Z$ where $Z\\sim \\mathrm{Exp}(1)$.\n",
    "\n",
    "Now the ratio is:\n",
    "$$\n",
    "\\frac{f_Y(y)}{g_Y(y)} = 20\\left(\\frac{1}{y}+\\frac{1}{y^2}\\right).\n",
    "$$\n",
    "This decreases as $y$ increases, so the supremum is at $y=20$:\n",
    "$$\n",
    "M = 20\\left(\\frac{1}{20}+\\frac{1}{20^2}\\right)\n",
    "  = 20(0.05 + 0.0025)\n",
    "  = 1.05.\n",
    "$$\n",
    "So the acceptance rate is about $1/1.05 \\approx 95\\%$ (fast).\n",
    "\n",
    "### 5) Sampling algorithm\n",
    "1. Propose $Y = 20 + \\mathrm{Exp}(1)$ (i.e., $Y = 20 - \\ln U$ for $U\\sim \\mathrm{Unif}(0,1)$).\n",
    "2. Accept with probability\n",
    "$$\n",
    "\\alpha(Y) = \\frac{f_Y(Y)}{M g_Y(Y)}\n",
    "          = \\frac{20\\left(\\frac{1}{Y}+\\frac{1}{Y^2}\\right)}{1.05}.\n",
    "$$\n",
    "3. If accepted, output $X = 1/Y$.\n",
    "\n",
    "---\n",
    "\n",
    "## How do I find a better $g$ in general?\n",
    "\n",
    "A practical method:\n",
    "\n",
    "1. **Convert to a PDF** (if you are given a CDF) so you know the true target density $f$.\n",
    "2. **Look at the “hard part” of $f$** (usually the tail behavior):\n",
    "   - If you see $e^{-y}$-type decay, try exponential/gamma proposals.\n",
    "   - If you see $e^{-y^2}$, try a normal proposal.\n",
    "   - If you see $1/x$, $\\log x$, or $e^{-1/x}$, try a substitution like $y=1/x$ or $y=-\\log x$.\n",
    "3. **Use a change of variables** to simplify the density into something recognizable.\n",
    "4. **Pick $g$ to match the dominant shape factor** of the transformed density.\n",
    "5. **Compute or upper-bound** $M=\\sup f/g$.\n",
    "   If $M$ is close to $1$, your proposal is excellent.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Why does the factor $1/y^2$ appear in the change of variables?\n",
    "\n",
    "Let $X$ have density $f_X(x)$ and define the transformation\n",
    "$$\n",
    "Y = \\frac{1}{X}.\n",
    "$$\n",
    "This transformation is one-to-one for $x>0$. Solving for $x$ in terms of $y$ gives the inverse\n",
    "$$\n",
    "x = g^{-1}(y) = \\frac{1}{y}.\n",
    "$$\n",
    "\n",
    "The change-of-variables formula for densities states:\n",
    "$$\n",
    "f_Y(y) = f_X\\!\\big(g^{-1}(y)\\big)\\left|\\frac{d}{dy}g^{-1}(y)\\right|.\n",
    "$$\n",
    "\n",
    "Differentiating the inverse transformation,\n",
    "$$\n",
    "\\frac{d}{dy}\\left(\\frac{1}{y}\\right) = -\\frac{1}{y^2}.\n",
    "$$\n",
    "Taking the absolute value gives\n",
    "$$\n",
    "\\left|\\frac{d}{dy}\\left(\\frac{1}{y}\\right)\\right| = \\frac{1}{y^2}.\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "f_Y(y) = f_X(1/y)\\cdot \\frac{1}{y^2}.\n",
    "$$\n",
    "\n",
    "This factor accounts for how the transformation stretches or compresses probability mass and ensures that the transformed density integrates to one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Problem 1.5\n",
    "# Rejection sampling for the second distribution (fast version)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def problem1_rejection_2(n_samples):\n",
    "    # We sample Y = 1/X instead of X directly.\n",
    "    # Proposal: Y = 20 + Exp(1)  (i.e., shifted exponential)\n",
    "    # Then accept/reject in Y-space and transform back: X = 1/Y.\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    M = 1.05  # sup_y f_Y(y)/g_Y(y) occurs at y=20\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        # propose y ~ 20 + Exp(1)\n",
    "        u1 = np.random.uniform(0.0, 1.0)\n",
    "        y = 20.0 - np.log(u1)\n",
    "\n",
    "        # acceptance probability alpha(y) = f_Y(y) / (M g_Y(y))\n",
    "        # with g_Y(y) = exp(-(y-20)) and f_Y(y) = 20 exp(-(y-20)) (1/y + 1/y^2)\n",
    "        alpha = (20.0 * (1.0 / y + 1.0 / (y**2))) / M\n",
    "\n",
    "        u2 = np.random.uniform(0.0, 1.0)\n",
    "        if u2 <= alpha:\n",
    "            x = 1.0 / y\n",
    "            samples.append(x)\n",
    "\n",
    "    return np.array(samples)\n",
    "\n",
    "n_samples = 100000\n",
    "samples = problem1_rejection_2(n_samples)\n",
    "print(len(samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfe919",
   "metadata": {},
   "source": [
    "So I tried many different distributions for g(x), but this is as close as I get to 2 seconds. I tried uniform, exponential and beta and beta seems to be the best. I tried with many different values for a and b, but I never get lower than roughly 4,5 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702c210",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29831136",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_rejection returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Good, your problem1_rejection_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1052c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df5824d4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "2. [4p] A page loads in $\\text{Exp}(3)$ (Exponentially distributed with mean $1/3$) seconds if not preloaded and loads with $\\text{Exp}(20)$ (Exponentially distributed with mean $1/20$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $8$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to the stationary distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5c6b5f4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25       0.12096774 0.13709678 0.11290322 0.06451613 0.16129032\n",
      " 0.12096774 0.         0.         0.03225806]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Part 1: 3 points\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"data/websites.csv\")\n",
    "#This problem is very similar to jan 2025 problem 2! \n",
    "\n",
    "# Load the data from the file data/websites.csv and estimate the transition matrix of the Markov chain\n",
    "# Store the estimated transition matrix in the variable problem2_transition_matrix below\n",
    "\n",
    "#This is very ugly code, but it does what it is supposed to do. Since there are 10 pages (0-9),\n",
    "# the matrix becomes 10X10\n",
    "array = [[0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0], \n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0 ,0]]# These values will now be filled\n",
    "\n",
    "for index, row in data.iterrows(): #Iterate through all rows\n",
    "    array[row[\"source\"] - 1][row[\"destination\"] - 1] += 1\n",
    "array = np.array(array)\n",
    "array = array.astype(np.float32) #Convert to float so that we can use divison\n",
    "\n",
    "#print(array.dtype)\n",
    "i = 0\n",
    "while i < array.shape[0]: # go through every row again\n",
    "    summa = np.sum(array[i])\n",
    "    #print(summa)\n",
    "    array[i] = array[i]/summa #Now the probabilities are generated\n",
    "    i+=1\n",
    "print(array[8])\n",
    "print(np.sum(array[8])) # To make sure that the transition matrix of one row = 1\n",
    "problem2_transition_matrix = array # A numpy array of shape (problem2_n_states, problem2_n_states)\n",
    "# Store the number of states in the variable problem2_n_states below\n",
    "problem2_n_states = 10 # An integer, I selected 10 because there are 10 pages, so 10 states in the markov chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e050b",
   "metadata": {},
   "source": [
    "2. [4p] A page loads in $\\text{Exp}(3)$ (Exponentially distributed with mean $1/3$) seconds if not preloaded and loads with $\\text{Exp}(20)$ (Exponentially distributed with mean $1/20$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $8$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "\n",
    "\n",
    "I ASSUME: It says \"Given that we start in page $8$ simulate $10000$ load times from page $1$ (that is, only a single step)\", so I think that there has been a typo. I will assume that we start from page and take one step from page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3a185d17",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average load time for problem2_page_load_times_top:  0.26200565415176974\n",
      "Average load time for problem2_page_load_times_two:  0.21949883881770044\n",
      "Shape of problem2_page_load_times_top:  (10000,)\n",
      "Shape of problem2_page_load_times_two:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Part 2: 4 points\n",
    "\n",
    "# Simulate the website load times for the next page of 10000 users that are currently on page 8 (recall indexing starts at 0) when we only preload the most likely page.\n",
    "# Store the simulated page load times in the variable problem2_page_load_times_top below\n",
    "choices = [0,1,2,3,4,5,6,7,8,9] # all of the pages \n",
    "prob_matrix = problem2_transition_matrix[8] # Index 8 is the transition matrix for page 8\n",
    "time_array = [] #array all of the times taken\n",
    "#print(np.where(prob_matrix == np.max(prob_matrix))[0])\n",
    "for i in range(10000): #10000 tries\n",
    "     destination = np.random.choice(a=choices, p = prob_matrix)   #select a random page from our set of pages, with transition matrix as prob\n",
    "     if  destination ==  np.where(prob_matrix == np.max(prob_matrix))[0]: # If the most popular destination is sampled:\n",
    "          time_array.append(np.random.exponential(1/20))\n",
    "     else: # Otherwise:\n",
    "          time_array.append(np.random.exponential(1/3))\n",
    "\n",
    "problem2_page_load_times_top = np.array(time_array) # A numpy array of shape (10000,)\n",
    "\n",
    "time_array2 = []\n",
    "for i in range(10000):\n",
    "     destination = np.random.choice(a=choices, p = prob_matrix)   \n",
    "     if  destination == 0 or destination == 5: #Could use np.where again, but im too lazy so I just looked at the array and saw the top 2 most popular\n",
    "          time_array2.append(np.random.exponential(1/20))\n",
    "     else:\n",
    "          time_array2.append(np.random.exponential(1/3))\n",
    "# Repeat the simulation of load times for the next page of 10000 users that are currently on page 1 when we load the two most likely pages.\n",
    "# Store the simulated page load times in the variable problem2_page_load_times_two below\n",
    "problem2_page_load_times_two = np.array(time_array2) # A numpy array of shape (10000,)\n",
    "\n",
    "print(\"Average load time for problem2_page_load_times_top: \", np.sum(problem2_page_load_times_top)/10000) \n",
    "print(\"Average load time for problem2_page_load_times_two: \", np.sum(problem2_page_load_times_two)/10000)\n",
    "print(\"Shape of problem2_page_load_times_top: \", np.shape(problem2_page_load_times_top))\n",
    "print(\"Shape of problem2_page_load_times_two: \", np.shape(problem2_page_load_times_two))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481678d",
   "metadata": {},
   "source": [
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29888c75",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "# Part 3: 3 points\n",
    "\n",
    "# Calculate the true expected load time for loading a page without pre-loading the next page and store it in the variable below\n",
    "problem2_avg = 1/3 # A float\n",
    "\n",
    "# Is the average load time for loading a page without pre-loading the next page larger than the average load time for loading a page after pre-loading the next most likely page?\n",
    "problem2_comparison = True # True / False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40571f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put the explanation for **part 3** of how you made the decision about `problem2_comparison` below this line in this **cell**. In order to enter edit mode you can doubleclick this cell or select it and press enter.\n",
    "\n",
    "I am assuming that problem2_page_load_times_top is used, not problem2_page_load_times_two.\n",
    "But both are calculated above.\n",
    "The average time time is simply the mean of the samples of time. It therefore becomes quite small: 0.2648629205627815 seconds\n",
    "(Average load time for problem2_page_load_times_two:  0.21635340436426223)\n",
    "\n",
    "But the average loading time wihout any pre-loading would become 1/3 seconds. This is because 1/3 is the mean of the distribution. So in theory, if we simulated with infinity and not 10000 and use no pre-loading, we would land at 1/3 seconds on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf5cd0",
   "metadata": {},
   "source": [
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to the stationary distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e96e0d40",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2952085558881719\n"
     ]
    }
   ],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "# Begin by calculating the stationary distribution of the Markov chain and store it in the variable below\n",
    "# WARNING: Since the transition matrix is not symmetric, numpy might make the output of the eigenvectors complex, you can use np.real() to get the real part of the eigenvectors\n",
    "# Store the stationary distribution in the variable below called problem2_stationary_distribution\n",
    "matrix = problem2_transition_matrix\n",
    "#print(np.sum(matrix))\n",
    "vector = np.array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "for i in range(1000):\n",
    "    #Calculate matrix vector multiplication\n",
    "    vector = np.dot(matrix.T, vector)\n",
    "    \n",
    "problem2_stationary_distribution = vector / np.sum(vector) # A numpy array of shape (problem2_n_states,)\n",
    "#print(np.sum(problem2_stationary_distribution))\n",
    "\n",
    "\n",
    "# Now use the above stationary distribution to calculate the average load time for loading a page after pre-loading the next most likely page according to the stationary distribution\n",
    "# Store the average load time in the variable below\n",
    "time_array3 = []\n",
    "for i in range(10000): # Go with 10000 again\n",
    "     destination = np.random.choice(a=choices, p = problem2_stationary_distribution)# use the stationary dist as the transiton matrix   \n",
    "     if  destination ==  np.where(problem2_stationary_distribution == np.max(problem2_stationary_distribution))[0]:\n",
    "          time_array3.append(np.random.exponential(1/20))\n",
    "     else:\n",
    "          time_array3.append(np.random.exponential(1/3))\n",
    "\n",
    "problem2_avg_stationary = np.mean(np.array(time_array3)) # A float\n",
    "print(problem2_avg_stationary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e0950",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "38670590",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem2_transition_matrix is a numpy array\n",
      "Good, your problem2_n_states is an integer\n",
      "Good, your problem2_transition_matrix has the correct shape\n",
      "Good, your problem2_page_load_times_top is a numpy array of shape (10000,)\n",
      "Good, your problem2_page_load_times_two is a numpy array of shape (10000,)\n",
      "Good, your problem2_avg is a float\n",
      "Good, your problem2_comparison is a boolean\n",
      "Good, your problem2_stationary_distribution is a numpy array of shape (problem2_n_states,)\n",
      "Good, your problem2_avg_stationary is a float\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert isinstance(problem2_transition_matrix, np.ndarray)\n",
    "except:\n",
    "    print(\"Try again. your problem2_transition_matrix is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem2_transition_matrix is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_n_states, int)\n",
    "except:\n",
    "    print(\"Try again. your problem2_n_states is not an integer\")\n",
    "else:\n",
    "    print(\"Good, your problem2_n_states is an integer\")\n",
    "\n",
    "try:\n",
    "    assert problem2_transition_matrix.shape == (problem2_n_states, problem2_n_states)\n",
    "except:\n",
    "    print(\"Try again. your problem2_transition_matrix does not have the correct shape\")\n",
    "else:\n",
    "    print(\"Good, your problem2_transition_matrix has the correct shape\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_page_load_times_top, np.ndarray), \"problem2_page_load_times_top is not a numpy array\"\n",
    "    assert problem2_page_load_times_top.shape == (10000,), \"problem2_page_load_times_top does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_page_load_times_top is a numpy array of shape (10000,)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_page_load_times_two, np.ndarray), \"problem2_page_load_times_two is not a numpy array\"\n",
    "    assert problem2_page_load_times_two.shape == (10000,), \"problem2_page_load_times_two does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_page_load_times_two is a numpy array of shape (10000,)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_avg, float), \"problem2_avg is not a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_avg is a float\")\n",
    "try:\n",
    "    assert isinstance(problem2_comparison, bool), \"problem2_comparison is not a boolean\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_comparison is a boolean\")\n",
    "try:\n",
    "    assert isinstance(problem2_stationary_distribution, np.ndarray), \"problem2_stationary_distribution is not a numpy array\"\n",
    "    assert problem2_stationary_distribution.shape == (problem2_n_states,), \"problem2_stationary_distribution does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_stationary_distribution is a numpy array of shape (problem2_n_states,)\")\n",
    "try:\n",
    "    assert isinstance(problem2_avg_stationary, float), \"problem2_avg_stationary is not a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_avg_stationary is a float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27550db",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50e8fe1b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n",
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n",
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n",
    "3. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34ce125b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RUN THIS CELL TO GET THE DATA\n",
    "\n",
    "# We start by loading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PROBLEM3_DF = pd.read_csv('data/fraud.csv')\n",
    "Y = PROBLEM3_DF['Class'].values\n",
    "X = PROBLEM3_DF[['V%d' % i for i in range(1,5)]+['Amount']].values\n",
    "\n",
    "# We will split the data into training, testing and validation sets\n",
    "from Utils import train_test_validation\n",
    "PROBLEM3_X_train, PROBLEM3_X_test, PROBLEM3_X_val, PROBLEM3_y_train, PROBLEM3_y_test, PROBLEM3_y_val = train_test_validation(X,Y,shuffle=True,random_state=1)\n",
    "\n",
    "# From this we will train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(PROBLEM3_X_train,PROBLEM3_y_train)\n",
    "\n",
    "# THE FOLLOWING CODE WILL PRODUCE THE ARRAYS YOU NEED FOR THE PROBLEM\n",
    "\n",
    "PROBLEM3_y_pred_proba_val = lr.predict_proba(PROBLEM3_X_val)[:,1]\n",
    "PROBLEM3_y_true_val = PROBLEM3_y_val\n",
    "\n",
    "PROBLEM3_y_pred_proba_test = lr.predict_proba(PROBLEM3_X_test)[:,1]\n",
    "PROBLEM3_y_true_test = PROBLEM3_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad4596b4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Part 1: 3 points\n",
    "# Implement the following function that calculates the cost of a binary classifier according to\n",
    "# the specification in the problem statement\n",
    "# See the comments inside the function for details of the parameters\n",
    "print(Y)\n",
    "def cost(y_true,y_predict_proba,threshold):\n",
    "    # y_true is a numpy array of shape (n_samples,) with binary labels\n",
    "    # y_predict_proba is a numpy array of shape (n_samples,) with predicted probabilities\n",
    "    # threshold is a float between 0 and 1\n",
    "    predictions = (y_predict_proba >= threshold).astype(int) #If prediction is higher than threshold, then 1\n",
    "    i = 0\n",
    "    cost = [] # where i store the cost so we can get average later\n",
    "    while i < len(y_true):# Going through the list\n",
    "        if y_true[i] == 1 and predictions[i] == 1: # true positive\n",
    "            cost.append(100) # append with the cost\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 0: # true  negative\n",
    "            cost.append(0)\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 1: # false positive\n",
    "            cost.append(120)\n",
    "            \n",
    "        if y_true[i] == 1 and predictions[i] == 0: # false negative\n",
    "            cost.append(600)\n",
    "        i+=1\n",
    "    \n",
    "    cost = np.array(cost)\n",
    "    avg_cost = np.mean(cost)# Just take the mean\n",
    "    #Start by converting \n",
    "    \n",
    "    # When returning the cost, you should return the average cost per sample\n",
    "    # thus it should be a value\n",
    "\n",
    "    return avg_cost # A float\n",
    "\n",
    "\n",
    "# Provide the code below to plot the cost as a function of the threshold\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# The plot should be between 0 and 1 with 0.01 increments\n",
    "# The y-axis should be the cost and the x-axis should be the threshold\n",
    "thresholds = np.linspace(0, 1, 100) # Array consisting of different thresholds\n",
    "threshold = 0 # Starting\n",
    "array_to_plot = []\n",
    "while threshold <= 1:\n",
    "    array_to_plot.append(cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, threshold))\n",
    "    threshold += 0.01\n",
    "# plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(thresholds,array_to_plot, 'o') \n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7590f92",
   "metadata": {},
   "source": [
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5801de45",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold:  0.2\n",
      "Lowest cost:  43.15492957746479\n",
      "Shape of problem3_y_pred_val: (1065,)\n"
     ]
    }
   ],
   "source": [
    "# Part 2: 2.5 points\n",
    "\n",
    "# Use the cost function you just implemented above to find the threshold that minimizes the cost\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the threshold in the variable below\n",
    "\n",
    "#This code sucks and is highly ineffective, but it works. I tried another method which did not work.\n",
    "threshold = 0 # Starting\n",
    "array_with_avg_costs = [] #store cost per threshold, wher the indexing is like this, threshold = index * 0.01\n",
    "while threshold <= 1:\n",
    "    array_with_avg_costs.append(cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, threshold))\n",
    "    threshold += 0.01\n",
    "problem3_threshold = array_with_avg_costs.index(np.min(array_with_avg_costs))*0.01 # Here I look at the array, find the index of the smallest cost, and multiply with 0.01 to get the threshold\n",
    "#np.min(cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, thresholds )) # A float between 0 and 1\n",
    "print(\"Best threshold: \", problem3_threshold)\n",
    "# Now calculate the cost of the classifier using the validation data and the threshold you just found\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the cost in the variable below\n",
    "problem3_cost_val = np.min(array_with_avg_costs) # A float\n",
    "print(\"Lowest cost: \", problem3_cost_val)\n",
    "# Using the threshold you just found, calculate the predicted labels of the classifier on the validation data\n",
    "# put the predicted labels in the variable below\n",
    "problem3_y_pred_val =  (PROBLEM3_y_pred_proba_val >= problem3_threshold).astype(int) # A numpy array of shape (n_samples,) with values 0 or 1\n",
    "print(\"Shape of problem3_y_pred_val:\", problem3_y_pred_val.shape)\n",
    "# Calculate the precision and recall of the classifier of class 1 using the threshold you just found\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "list_of_preds = [0, 0, 0, 0]\n",
    "#simple array ,where index 0 is amount of TP, index 1 = amount of TN, index 2 = aomunt of FP, index 3 = amount of FN\n",
    "\n",
    "i = 0\n",
    "#I use the same algorithm as in the cost function, except I now modify a list\n",
    "while i < len(PROBLEM3_y_true_val):# Going through the list\n",
    "        if PROBLEM3_y_true_val[i] == 1 and problem3_y_pred_val[i] == 1: # true positive\n",
    "            list_of_preds[0] += 1 # add to TP\n",
    "            \n",
    "        if PROBLEM3_y_true_val[i] == 0 and problem3_y_pred_val[i] == 0: # true  negative\n",
    "            list_of_preds[1] += 1 # Add to TN\n",
    "            \n",
    "        if PROBLEM3_y_true_val[i] == 0 and problem3_y_pred_val[i] == 1: # false positive\n",
    "           list_of_preds[2] += 1 #Add to FP\n",
    "            \n",
    "        if PROBLEM3_y_true_val[i] == 1 and problem3_y_pred_val[i] == 0: # false negative\n",
    "            list_of_preds[3] += 1 #Add to FN\n",
    "        i+=1\n",
    "\n",
    "\n",
    "\n",
    "problem3_precision_1 = list_of_preds[0]/(list_of_preds[0] + list_of_preds[2])  # A float between 0 and 1\n",
    "#Precision = True positives / (True positive+ False positive)\n",
    "problem3_recall_1 = list_of_preds[0]/(list_of_preds[0] + list_of_preds[3]) # A float between 0 and 1\n",
    "#Recall = #True positives / (True positive+ False Negative)\n",
    "\n",
    "# Calculate the precision and recall of the classifier of class 0 using the threshold you just found\n",
    "# using the validation data, specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "\n",
    "#Here i will just take the inverse of above. It is basically the precision and recall of Negative, so I just invert\n",
    "\n",
    "problem3_precision_0 = list_of_preds[1]/(list_of_preds[1] + list_of_preds[3]) # A float between 0 and 1\n",
    "#Precision = True Negatives / (True Negatives+ False Negatives)\n",
    "\n",
    "problem3_recall_0 = list_of_preds[1]/(list_of_preds[1] + list_of_preds[2]) # A float between 0 and 1\n",
    "#Recall = #True Negatives / (True Negatives+ False Positives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90123e8e",
   "metadata": {},
   "source": [
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb9d7fdd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6900000000000001\n",
      "54.08450704225352\n",
      "43.15492957746479\n",
      "10.929577464788728\n"
     ]
    }
   ],
   "source": [
    "# Part 3: 2.5 points\n",
    "\n",
    "#Just copy the cost function but change very few things to make it zero one\n",
    "def zero_one_loss(y_true,y_predict_proba,threshold):\n",
    "    # y_true is a numpy array of shape (n_samples,) with binary labels\n",
    "    # y_predict_proba is a numpy array of shape (n_samples,) with predicted probabilities\n",
    "    # threshold is a float between 0 and 1\n",
    "    predictions = (y_predict_proba >= threshold).astype(int) #If prediction is higher than threshold, then 1\n",
    "    i = 0\n",
    "    cost = [] # where i store the cost so we can get average later\n",
    "    while i < len(y_true):# Going through the list\n",
    "        if y_true[i] == 1 and predictions[i] == 1: # true positive\n",
    "            cost.append(0) # append with the cost\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 0: # true  negative\n",
    "            cost.append(0)\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 1: # false positive\n",
    "            cost.append(1)\n",
    "            \n",
    "        if y_true[i] == 1 and predictions[i] == 0: # false negative\n",
    "            cost.append(1)\n",
    "        i+=1\n",
    "    \n",
    "    cost = np.array(cost)\n",
    "    avg_cost = np.mean(cost)# Just take the mean\n",
    "    #Start by converting \n",
    "    \n",
    "    # When returning the cost, you should return the average cost per sample\n",
    "    # thus it should be a value\n",
    "\n",
    "    return avg_cost # A float\n",
    "\n",
    "\n",
    "\n",
    "# Find the threshold that minimizes the $0-1$ loss using the validation data\n",
    "# specifically the arrays PROBLEM3_y_true_val and PROBLEM3_y_pred_proba_val.\n",
    "# Store the threshold in the variable below\n",
    "\n",
    "threshold = 0 # Starting\n",
    "array_with_avg_costs = [] #store loss per threshold, wher the indexing is like this, threshold = index * 0.01\n",
    "while threshold <= 1:\n",
    "    array_with_avg_costs.append(zero_one_loss(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, threshold))\n",
    "    threshold += 0.01\n",
    "problem3_threshold_01 = array_with_avg_costs.index(np.min(array_with_avg_costs))*0.01 # Here I look at the array, find the index of the smallest cost, and multiply with 0.01 to get the threshold\n",
    " # A float between 0 and 1\n",
    "print(problem3_threshold_01)\n",
    "\n",
    "# Now calculate the difference in cost (using the cost function you implemented in step 1) between the optimal one chosen in part 2 and the one chosen in part 3 by taking the cost with the threshold found in part 3 and subtracting the cost with the threshold found in part 2 to get a positive value\n",
    "problem3_cost_difference = cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold_01) -  cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold)# A float\n",
    "print(cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold_01))\n",
    "print(cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold))\n",
    "print(problem3_cost_difference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3645e321",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 42.70422535211268\n",
      "95% Confidence interval: (34.55561625766896, 50.8528344465564)\n"
     ]
    }
   ],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "# Using the threshold problem3_threshold use Hoeffdings inequality to provide a confidence interval \n",
    "# for the cost of the classifier with 95 % confidence using the test data.\n",
    "# Specifically the arrays PROBLEM3_y_true_test and PROBLEM3_y_pred_proba_test.\n",
    "# Store the lower and upper bounds of the confidence interval in the variables below\n",
    "\n",
    "\n",
    "# Hoeffding's inequality bounds\n",
    "def cost_as_array(y_true,y_predict_proba,threshold):\n",
    "    # y_true is a numpy array of shape (n_samples,) with binary labels\n",
    "    # y_predict_proba is a numpy array of shape (n_samples,) with predicted probabilities\n",
    "    # threshold is a float between 0 and 1\n",
    "    predictions = (y_predict_proba >= threshold).astype(int) #If prediction is higher than threshold, then 1\n",
    "    i = 0\n",
    "    cost = [] # where i store the cost so we can get average later\n",
    "    while i < len(y_true):# Going through the list\n",
    "        if y_true[i] == 1 and predictions[i] == 1: # true positive\n",
    "            cost.append(100) # append with the cost\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 0: # true  negative\n",
    "            cost.append(0)\n",
    "            \n",
    "        if y_true[i] == 0 and predictions[i] == 1: # false positive\n",
    "            cost.append(120)\n",
    "            \n",
    "        if y_true[i] == 1 and predictions[i] == 0: # false negative\n",
    "            cost.append(600)\n",
    "        i+=1\n",
    "    \n",
    "    cost = np.array(cost)\n",
    "    avg_cost = cost# Just take the mean\n",
    "    #Start by converting \n",
    "    \n",
    "    # When returning the cost, you should return the average cost per sample\n",
    "    # thus it should be a value\n",
    "\n",
    "    return avg_cost # A float\n",
    "\n",
    "a = np.min(cost_as_array(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold))\n",
    "b = np.max(cost_as_array(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold))\n",
    "\n",
    "delta = 0.05\n",
    "bound = np.sqrt(((b - a)**2 * np.log(2 / delta)) / (2 * n))\n",
    "\n",
    "problem1_interval = (cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold) - bound, cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold) + bound)\n",
    "\n",
    "print(\"Estimate:\", cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold))\n",
    "print(\"95% Confidence interval:\", problem1_interval)\n",
    "\n",
    "\n",
    "problem3_lower_bound = cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold) - bound # A float\n",
    "problem3_upper_bound = cost(PROBLEM3_y_true_test, PROBLEM3_y_pred_proba_test, problem3_threshold) + bound # A float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660e3fb",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put your explanation for part 4 below this line in this **cell**. Doubleclick to enter edit mode as before.\n",
    "\n",
    "\n",
    "I am using the same method for calculating the confidence interval as in Problem 1.\n",
    "I created a new function to get the cost as an array, instead of just the average. This allowed me to ge the highest and lowest values.\n",
    "I then continued using the same method as in Problem 1 to get the confidence interval of 95%. I assumed the estimate to be the average cost for that threshold. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7044e1d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7ed08c8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your cost is a function\n",
      "Good, your PROBLEM3_y_pred_proba_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\n",
      "Good, your PROBLEM3_y_true_val is a numpy array of shape (len(PROBLEM3_y_pred_proba_val),)\n",
      "Good, your PROBLEM3_y_pred_proba_test is a numpy array of shape (len(PROBLEM3_y_true_test),)\n",
      "Good, your PROBLEM3_y_true_test is a numpy array of shape (len(PROBLEM3_y_pred_proba_test),)\n",
      "Good, your cost function returns a float\n",
      "Good, your cost function returns the correct value for the test case\n",
      "Good, your problem3_threshold is a float between 0 and 1\n",
      "Good, your problem3_cost_val is a float that is non-negative\n",
      "Good, your problem3_y_pred_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\n",
      "Good, your problem3_y_pred_val contains only 0s and 1s\n",
      "Good, your problem3_precision_1 is a float between 0 and 1\n",
      "Good, your problem3_recall_1 is a float between 0 and 1\n",
      "Good, your problem3_precision_0 is a float between 0 and 1\n",
      "Good, your problem3_recall_0 is a float between 0 and 1\n",
      "Good, your problem3_threshold_01 is a float between 0 and 1\n",
      "Good, your problem3_cost_difference is a float that is non-negative\n",
      "Good, your problem3_lower_bound is a float that is non-negative\n",
      "Good, your problem3_upper_bound is a float that is non-negative\n"
     ]
    }
   ],
   "source": [
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert callable(cost), \"cost is not a function\"\n",
    "except:\n",
    "    print(\"Try again. your cost is not a function\")\n",
    "else:\n",
    "    print(\"Good, your cost is a function\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_pred_proba_val, np.ndarray), \"PROBLEM3_y_pred_proba_val is not a numpy array\"\n",
    "    assert PROBLEM3_y_pred_proba_val.shape == (len(PROBLEM3_y_true_val),), \"PROBLEM3_y_pred_proba_val does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_pred_proba_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_true_val, np.ndarray), \"PROBLEM3_y_true_val is not a numpy array\"\n",
    "    assert PROBLEM3_y_true_val.shape == (len(PROBLEM3_y_pred_proba_val),), \"PROBLEM3_y_true_val does not have the correct shape\"\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_true_val is a numpy array of shape (len(PROBLEM3_y_pred_proba_val),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_pred_proba_test, np.ndarray), \"PROBLEM3_y_pred_proba_test is not a numpy array\"\n",
    "    assert PROBLEM3_y_pred_proba_test.shape == (len(PROBLEM3_y_true_test),), \"PROBLEM3_y_pred_proba_test does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_pred_proba_test is a numpy array of shape (len(PROBLEM3_y_true_test),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_true_test, np.ndarray), \"PROBLEM3_y_true_test is not a numpy array\"\n",
    "    assert PROBLEM3_y_true_test.shape == (len(PROBLEM3_y_pred_proba_test),), \"PROBLEM3_y_true_test does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_true_test is a numpy array of shape (len(PROBLEM3_y_pred_proba_test),)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(cost(np.array([1,1,0,0]),np.array([0.9,0.8,0.1,0.2]),0.5), float), \"cost does not return a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your cost function returns a float\")\n",
    "try:\n",
    "    assert cost(np.array([1,1,0,0]),np.array([0.9,0.8,0.1,0.2]),0.5) == 50.0, \"cost does not return the correct value for the test case\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your cost function returns the correct value for the test case\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem3_threshold, float), \"problem3_threshold is not a float\"\n",
    "    assert 0 <= problem3_threshold <= 1, \"problem3_threshold is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_threshold is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_cost_val, float), \"problem3_cost_val is not a float\"\n",
    "    assert problem3_cost_val >= 0, \"problem3_cost_val is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_cost_val is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_y_pred_val, np.ndarray), \"problem3_y_pred_val is not a numpy array\"\n",
    "    assert problem3_y_pred_val.shape == (len(PROBLEM3_y_true_val),), \"problem3_y_pred_val does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_y_pred_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\")\n",
    "try:\n",
    "    assert np.all(np.isin(problem3_y_pred_val, [0, 1])), \"problem3_y_pred_val does not contain only 0s and 1s\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_y_pred_val contains only 0s and 1s\")\n",
    "try:\n",
    "    assert isinstance(problem3_precision_1, float), \"problem3_precision_1 is not a float\"\n",
    "    assert 0 <= problem3_precision_1 <= 1, \"problem3_precision_1 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_precision_1 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_recall_1, float), \"problem3_recall_1 is not a float\"\n",
    "    assert 0 <= problem3_recall_1 <= 1, \"problem3_recall_1 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_recall_1 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_precision_0, float), \"problem3_precision_0 is not a float\"\n",
    "    assert 0 <= problem3_precision_0 <= 1, \"problem3_precision_0 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_precision_0 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_recall_0, float), \"problem3_recall_0 is not a float\"\n",
    "    assert 0 <= problem3_recall_0 <= 1, \"problem3_recall_0 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_recall_0 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_threshold_01, float), \"problem3_threshold_01 is not a float\"\n",
    "    assert 0 <= problem3_threshold_01 <= 1, \"problem3_threshold_01 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_threshold_01 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_cost_difference, float), \"problem3_cost_difference is not a float\"\n",
    "    assert problem3_cost_difference >= 0, \"problem3_cost_difference is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_cost_difference is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_lower_bound, float), \"problem3_lower_bound is not a float\"\n",
    "    assert problem3_lower_bound >= 0, \"problem3_lower_bound is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_lower_bound is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_upper_bound, float), \"problem3_upper_bound is not a float\"\n",
    "    assert problem3_upper_bound >= 0, \"problem3_upper_bound is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_upper_bound is a float that is non-negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
