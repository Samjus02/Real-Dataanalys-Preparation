{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9c5ac5",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# Exam 16th of June 2025, 13.00-18.00 for the course 1MS041 (Introduction to Data Science / Introduktion till dataanalys)\n",
    "\n",
    "## Instructions:\n",
    "1. Complete the problems by following instructions.\n",
    "2. When done, submit this file with your solutions saved, following the instruction sheet.\n",
    "\n",
    "This exam has 3 problems for a total of 40 points, to pass you need\n",
    "20 points. The bonus will be added to the score of the exam and rounded afterwards.\n",
    "\n",
    "## Some general hints and information:\n",
    "* Try to answer all questions even if you are uncertain.\n",
    "* Comment your code, so that if you get the wrong answer I can understand how you thought\n",
    "this can give you some points even though the code does not run.\n",
    "* Follow the instruction sheet rigorously.\n",
    "* This exam is partially autograded, but your code and your free text answers are manually graded anonymously.\n",
    "* If there are any questions, please ask the exam guards, they will escalate it to me if necessary.\n",
    "\n",
    "## Tips for free text answers\n",
    "* Be VERY clear with your reasoning, there should be zero ambiguity in what you are referring to.\n",
    "* If you want to include math, you can write LaTeX in the Markdown cells, for instance `$f(x)=x^2$` will be rendered as $f(x)=x^2$ and `$$f(x) = x^2$$` will become an equation line, as follows\n",
    "$$f(x) = x^2$$\n",
    "Another example is `$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$` which renders as\n",
    "$$f_{Y \\mid X}(y,x) = P(Y = y \\mid X = x) = \\exp(\\alpha \\cdot x + \\beta)$$\n",
    "\n",
    "## Finally some rules:\n",
    "* You may not communicate with others during the exam, for example:\n",
    "    * You cannot ask for help in Stack-Overflow or other such help forums during the Exam.\n",
    "    * You may not communicate with AI's, for instance ChatGPT.\n",
    "    * Your on-line and off-line activity is being monitored according to the examination rules.\n",
    "\n",
    "## Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7eeac84",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Insert your anonymous exam ID as a string in the variable below\n",
    "examID=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4881d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b84a6b3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 1\n",
    "Maximum Points = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380e9b3",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_rejection` in order to produce samples from the below distribution using rejection sampling: (Hint: $F$ is the distribution function)\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-x^2-1}{e-2}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "2. [2p] Produce 100000 samples (**use fewer if it takes too long (more than 10 sec) and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. \n",
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2(e^{x^2}-1) x}{e-2} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n",
    "\n",
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n",
    "\n",
    "5. [4p] Fill in the remaining part of the function `problem1_rejection_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b38d273",
   "metadata": {},
   "source": [
    "-----\n",
    "In this problem you will do rejection sampling from complicated distributions, you will also be using your samples to compute certain integrals, a method known as Monte Carlo integration: (Keep in mind that choosing a good sampling distribution is often key to avoid too much rejection)\n",
    "\n",
    "1. [4p] Fill in the remaining part of the function `problem1_rejection` in order to produce samples from the below distribution using rejection sampling: (Hint: $F$ is the distribution function)\n",
    "\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        \\frac{e^{x^2}-x^2-1}{e-2}, & 0 < x < 1 \\\\\n",
    "        1, & x \\geq 1\n",
    "    \\end{cases}\n",
    "$$\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a661e0",
   "metadata": {},
   "source": [
    "### Derivation of $( f(x) )$, choice of $( g(x) )$, and determination of $( M )$\n",
    "\n",
    "We are given the cumulative distribution function\n",
    "$$\n",
    "F(x) =\n",
    "\\begin{cases}\n",
    "0, & x \\le 0, \\\\\n",
    "\\dfrac{e^{x^2} - x^2 - 1}{e - 2}, & 0 < x < 1, \\\\\n",
    "1, & x \\ge 1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Deriving the density $( f(x) )$\n",
    "\n",
    "To obtain the probability density function, we differentiate $(F(x))$ on the interval $((0,1))$:\n",
    "$$\n",
    "f(x) = F'(x).\n",
    "$$\n",
    "\n",
    "Differentiating the numerator term by term:\n",
    "$$\n",
    "\\frac{d}{dx}(e^{x^2}) = 2x e^{x^2}, \\quad\n",
    "\\frac{d}{dx}(-x^2) = -2x, \\quad\n",
    "\\frac{d}{dx}(-1) = 0.\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "$$\n",
    "f(x) = \\frac{2x e^{x^2} - 2x}{e - 2}\n",
    "     = \\frac{2x\\big(e^{x^2} - 1\\big)}{e - 2},\n",
    "\\quad 0 < x < 1.\n",
    "$$\n",
    "\n",
    "Outside $([0,1])$, the density is zero.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Choice of proposal distribution $( g(x) )$\n",
    "\n",
    "We choose the proposal distribution\n",
    "$$\n",
    "g(x) = 1, \\quad x \\in [0,1],\n",
    "$$\n",
    "which corresponds to a Uniform $((0,1))$ distribution. This choice is valid because\n",
    "$$\n",
    "\\int_0^1 g(x)\\,dx = 1,\n",
    "$$\n",
    "so $(g(x))$ is a proper probability density.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Determination of the constant $( M )$\n",
    "\n",
    "In rejection sampling, we must choose a constant $(M)$ such that\n",
    "$$\n",
    "f(x) \\le M g(x) \\quad \\text{for all } x \\in [0,1].\n",
    "$$\n",
    "Since $(g(x)=1)$, this reduces to\n",
    "$$\n",
    "f(x) \\le M \\quad \\text{for all } x \\in [0,1].\n",
    "$$\n",
    "\n",
    "We therefore choose $(M)$ as the **maximum value of $(f(x))$ on the interval $([0,1])$**.\n",
    "\n",
    "The function\n",
    "$$\n",
    "f(x) = \\frac{2x(e^{x^2}-1)}{e-2}\n",
    "$$\n",
    "is increasing on $([0,1])$, so its maximum occurs at the endpoint $(x=1)$. Evaluating $(f(x))$ at this point gives\n",
    "$$\n",
    "M = f(1) = \\frac{2( e - 1 )}{e - 2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Final result for rejection sampling\n",
    "\n",
    "- Target density:\n",
    "$$\n",
    "f(x) = \\frac{2x(e^{x^2}-1)}{e-2}, \\quad x \\in [0,1].\n",
    "$$\n",
    "\n",
    "- Proposal density:\n",
    "$$\n",
    "g(x) = 1, \\quad x \\in [0,1].\n",
    "$$\n",
    "\n",
    "- Bounding constant:\n",
    "$$\n",
    "M = \\frac{2(e-1)}{e-2}.\n",
    "$$\n",
    "\n",
    "With these choices, the rejection sampling acceptance probability is\n",
    "$$\n",
    "\\frac{f(x)}{M g(x)} = \\frac{f(x)}{M}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254b76f4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is M:  4.784422382354666\n",
      "The actual M is also:  4.784422382354666\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Problem 1\n",
    "# Rejection sampling + Monte Carlo integration\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def problem1_rejection(n_samples):\n",
    "    # Distribution from part 1\n",
    "    # Write the code in this function to produce samples from the distribution in the assignment.\n",
    "    # Make sure you choose a good sampling distribution to avoid unnecessary rejections.\n",
    "    samples = []\n",
    "    # Return a numpy array of length n_samples\n",
    "    while (len(samples) < n_samples):\n",
    "        x = np.random.uniform(0,1)\n",
    "        U = np.random.uniform(0, 1)\n",
    "        fx = (2*x*(np.exp(x**2) - 1) / (np.e - 2))\n",
    "        gx = 1\n",
    "        actual_M = 2*(np.e-1) / (np.e - 2)\n",
    "        \n",
    "        acceptance_rate = fx / (gx * actual_M)\n",
    "        if U <= acceptance_rate:\n",
    "            samples.append(x)\n",
    "    \n",
    "    \n",
    "    return np.array(samples)\n",
    "\n",
    "gx = 1\n",
    "\n",
    "def f(x):\n",
    "    return (2*x*(np.exp(x**2) - 1) / (np.e - 2))\n",
    "    \n",
    "x = np.linspace(0,1,10000)\n",
    "    \n",
    "ratio = (f(x) / gx)\n",
    "\n",
    "M_est = ratio.max()\n",
    "    \n",
    "print(\"This is M: \", M_est)\n",
    "\n",
    "\n",
    "actual_M = 2*(np.e-1) / (np.e - 2)\n",
    "print(\"The actual M is also: \", actual_M)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0337cb",
   "metadata": {},
   "source": [
    "2. [2p] Produce 100000 samples (**use fewer if it takes too long (more than 10 sec) and you cannot find a solution**) and put the answer in `problem1_samples` from the above distribution and plot the histogram together with the true density. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29d77ef6",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Problem 1.2\n",
    "# Produce samples and plot histogram together with the true density\n",
    "# ------------------------------------------------------------\n",
    "n_samples = 100000\n",
    "problem1_samples = problem1_rejection(n_samples)\n",
    "\n",
    "# Plotting a basic histogram\n",
    "plt.hist(problem1_samples, bins=50, density=True, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density of the samples')\n",
    "plt.title('BHistogram of the rejection samples')\n",
    "\n",
    "x_values = np.linspace(0, 1, 500)\n",
    "fx = (2*x_values*(np.exp(x_values**2) - 1) / (np.e - 2))\n",
    "\n",
    "plt.plot(x_values, fx, color='r', label='True fx')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae81bef",
   "metadata": {},
   "source": [
    "3. [2p] Use the above 100000 samples (`problem1_samples`) to approximately compute the integral\n",
    "\n",
    "$$\n",
    "    \\int_0^{1} \\sin(x) \\frac{2(e^{x^2}-1) x}{e-2} dx\n",
    "$$\n",
    "and store the result in `problem1_integral`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0231b73",
   "metadata": {},
   "source": [
    "-----\n",
    "### Monte Carlo approximation of the integral\n",
    "\n",
    "We want to approximate the integral\n",
    "$$\n",
    "\\int_0^{1} \\sin(x)\\,\\frac{2(e^{x^2}-1)x}{e-2}\\,dx.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Key observation\n",
    "\n",
    "From the earlier parts of the exercise, we have already constructed samples\n",
    "$$\n",
    "X_1, X_2, \\dots, X_n\n",
    "$$\n",
    "using rejection sampling such that each $(X_i)$ is distributed according to the density\n",
    "$$\n",
    "f(x) = \\frac{2(e^{x^2}-1)x}{e-2}, \\quad x \\in [0,1].\n",
    "$$\n",
    "\n",
    "This is crucial, because the integral we want to compute can be written as an **expectation with respect to this density**:\n",
    "$$\n",
    "\\int_0^1 \\sin(x)\\,f(x)\\,dx\n",
    "= \\mathbb{E}_{X \\sim f}[\\sin(X)].\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Monte Carlo principle\n",
    "\n",
    "For a random variable $(X \\sim f)$, the expectation\n",
    "$$\n",
    "\\mathbb{E}_{X \\sim f}[\\sin(X)]\n",
    "$$\n",
    "can be approximated using Monte Carlo integration by\n",
    "$$\n",
    "\\frac{1}{n}\\sum_{i=1}^n \\sin(X_i),\n",
    "$$\n",
    "where $(X_1,\\dots,X_n)$ are independent samples drawn from $(f)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Why we do **not** multiply by $(f(x))$ again\n",
    "\n",
    "A common mistake is to compute\n",
    "$$\n",
    "\\sin(X_i)\\,f(X_i),\n",
    "$$\n",
    "but this would be incorrect here. The reason is that the **sampling distribution is already $(f(x))$**.\n",
    "\n",
    "- If we were sampling from a *different* distribution (for example Uniform $((0,1)))$, then we would need to include importance weights.\n",
    "- In this problem, we are sampling **directly from the density appearing in the integral**, so the density is already accounted for by how the samples were generated.\n",
    "\n",
    "Multiplying by $(f(x))$ again would effectively weight the density twice and approximate the wrong quantity.\n",
    "\n",
    "---\n",
    "\n",
    "### Final Monte Carlo estimator\n",
    "\n",
    "Therefore, the correct Monte Carlo approximation of the integral is simply:\n",
    "$$\n",
    "\\int_0^1 \\sin(x)\\,f(x)\\,dx\n",
    "\\;\\approx\\;\n",
    "\\frac{1}{n}\\sum_{i=1}^n \\sin(X_i),\n",
    "$$\n",
    "\n",
    "which in code corresponds to:\n",
    "```python\n",
    "np.mean(np.sin(problem1_samples))\n",
    "```\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceb7b40f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of x is:  100000\n",
      "Monte Carlo approximation of the integral: 0.7229103519143282\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Problem 1.3\n",
    "# Monte Carlo approximation of the integral using problem1_samples\n",
    "# ------------------------------------------------------------\n",
    "x = problem1_samples\n",
    "print(\"Length of x is: \", len(x))\n",
    "\n",
    "problem1_integral = np.mean(np.sin(x))\n",
    "\n",
    "print(\"Monte Carlo approximation of the integral:\", problem1_integral)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176adb46",
   "metadata": {},
   "source": [
    "4. [2p] Use Hoeffdings inequality to produce a 95\\% confidence interval of the integral above and store the result as a tuple in the variable `problem1_interval`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41762b66",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Hoeffding confidence interval (Problem 1.4)\n",
    "\n",
    "To quantify the uncertainty of the Monte Carlo estimate of the integral, Hoeffding’s inequality is used.\n",
    "\n",
    "Let\n",
    "$$\n",
    "Y_i = \\sin(X_i),\n",
    "$$\n",
    "where $X_i$ are the samples drawn from the distribution on $[0,1]$. The Monte Carlo estimator of the integral is\n",
    "$$\n",
    "\\widehat{I}_n = \\frac{1}{n}\\sum_{i=1}^n Y_i.\n",
    "$$\n",
    "\n",
    "Since $X_i \\in [0,1]$ and the function $\\sin(x)$ is increasing on this interval, the random variables $Y_i$ are bounded by\n",
    "$$\n",
    "0 \\le Y_i \\le \\sin(1).\n",
    "$$\n",
    "Thus we may choose\n",
    "$$\n",
    "a = 0, \\qquad b = \\sin(1).\n",
    "$$\n",
    "\n",
    "Hoeffding’s inequality states that for i.i.d. random variables $Y_i \\in [a,b]$,\n",
    "$$\n",
    "\\mathbb{P}\\!\\left(\\left|\\widehat{I}_n - \\mathbb{E}[Y]\\right| \\ge \\varepsilon\\right)\n",
    "\\le 2 \\exp\\!\\left(-\\frac{2n\\varepsilon^2}{(b-a)^2}\\right).\n",
    "$$\n",
    "\n",
    "To construct a two-sided $95\\%$ confidence interval, we set the right-hand side equal to $\\delta = 0.05$:\n",
    "$$\n",
    "2 \\exp\\!\\left(-\\frac{2n\\varepsilon^2}{(b-a)^2}\\right) = 0.05.\n",
    "$$\n",
    "Solving for $\\varepsilon$ gives\n",
    "$$\n",
    "\\varepsilon\n",
    "= (b-a)\\sqrt{\\frac{\\ln(2/\\delta)}{2n}}\n",
    "= (b-a)\\sqrt{\\frac{\\ln(40)}{2n}}.\n",
    "$$\n",
    "\n",
    "The resulting $95\\%$ confidence interval for the integral is therefore\n",
    "$$\n",
    "\\left[\\widehat{I}_n - \\varepsilon,\\; \\widehat{I}_n + \\varepsilon\\right].\n",
    "$$\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc01e0d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the interval for the Hoeffding Inequality:  (np.float64(0.7192964914544643), np.float64(0.7265242123741921))\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Problem 1.4\n",
    "# 95% confidence interval using Hoeffding's inequality\n",
    "# Store as a tuple in problem1_interval\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "a = 0\n",
    "b = np.sin(1.0)\n",
    "\n",
    "# This is the number of samples we used for the previous exercise, which will be our n in the Hoeffding inequality\n",
    "n_samples = 100000\n",
    "epsilon = (b-a)*np.sqrt((np.log(0.05/2) / (-2*n_samples)))\n",
    "\n",
    "lower_bound = problem1_integral - epsilon\n",
    "upper_bound = problem1_integral + epsilon\n",
    "\n",
    "problem1_interval = (lower_bound, upper_bound)\n",
    "print(\"This is the interval for the Hoeffding Inequality: \", problem1_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e80e36",
   "metadata": {},
   "source": [
    "5. [4p] Fill in the remaining part of the function `problem1_rejection_2` in order to produce samples from the below distribution using rejection sampling:\n",
    "$$\n",
    "    F[x] = \n",
    "    \\begin{cases}\n",
    "        0, & x \\leq 0 \\\\\n",
    "        20xe^{20-1/x}, & 0 < x < \\frac{1}{20} \\\\\n",
    "        1, & x \\geq \\frac{1}{20}\n",
    "    \\end{cases}\n",
    "$$\n",
    "Hint: this is tricky because if you choose the wrong sampling distribution you reject at least 9 times out of 10. You will get points based on how long your code takes to create a certain number of samples, if you choose the correct sampling distribution you can easily create 100000 samples within 2 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29643004",
   "metadata": {},
   "source": [
    "-----\n",
    "## Step-by-step solution for Problem 1.5 using the transformation $Y=\\frac{1}{X}$\n",
    "\n",
    "We want to sample from the distribution with CDF\n",
    "$$\n",
    "F_X(x)=\n",
    "\\begin{cases}\n",
    "0, & x\\le 0\\\\[4pt]\n",
    "20x e^{20-1/x}, & 0<x<\\frac{1}{20}\\\\[4pt]\n",
    "1, & x\\ge \\frac{1}{20}.\n",
    "\\end{cases}\n",
    "$$\n",
    "The hard part is that the distribution is *very concentrated* near $x=\\frac{1}{20}$, so a naive proposal like $\\text{Uniform}(0,1/20)$ leads to many rejections.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Differentiate the CDF to get the PDF $f_X(x)$\n",
    "\n",
    "For $0<x<\\frac{1}{20}$:\n",
    "$$\n",
    "F_X(x) = 20x e^{20-1/x}.\n",
    "$$\n",
    "Differentiate using product rule:\n",
    "$$\n",
    "f_X(x)=\\frac{d}{dx}\\left(20x e^{20-1/x}\\right)\n",
    "=20 e^{20-1/x} + 20x\\frac{d}{dx}\\left(e^{20-1/x}\\right).\n",
    "$$\n",
    "Chain rule:\n",
    "$$\n",
    "\\frac{d}{dx}\\left(e^{20-1/x}\\right)=e^{20-1/x}\\cdot \\frac{d}{dx}(20-1/x).\n",
    "$$\n",
    "Since\n",
    "$$\n",
    "\\frac{d}{dx}(-1/x)=\\frac{1}{x^2},\n",
    "$$\n",
    "we get\n",
    "$$\n",
    "\\frac{d}{dx}(20-1/x)=\\frac{1}{x^2}.\n",
    "$$\n",
    "So:\n",
    "$$\n",
    "f_X(x)=20 e^{20-1/x}+20x\\cdot e^{20-1/x}\\cdot \\frac{1}{x^2}\n",
    "=20 e^{20-1/x}\\left(1+\\frac{1}{x}\\right),\n",
    "\\quad 0<x<\\frac{1}{20}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 2) The key trick: transform $Y=\\frac{1}{X}$\n",
    "\n",
    "The expression contains $1/x$, so we remove that “bad” term by defining:\n",
    "$$\n",
    "Y=\\frac{1}{X}.\n",
    "$$\n",
    "\n",
    "### Support after the transform\n",
    "If $0<X<\\frac{1}{20}$ then\n",
    "$$\n",
    "Y=\\frac{1}{X} > 20.\n",
    "$$\n",
    "So $Y\\in(20,\\infty)$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Why the absolute value in the formula appears\n",
    "\n",
    "When you change variables, densities must stay nonnegative and probabilities must be preserved. The rule is:\n",
    "$$\n",
    "f_Y(y)=f_X(x)\\left|\\frac{dx}{dy}\\right|\n",
    "\\quad \\text{where } x=h(y).\n",
    "$$\n",
    "\n",
    "### What does the “absolute value sign” mean?\n",
    "The symbol\n",
    "$$\n",
    "\\left|\\frac{dx}{dy}\\right|\n",
    "$$\n",
    "means “take the derivative $\\frac{dx}{dy}$ and then take its absolute value”.\n",
    "\n",
    "Why? Because $\\frac{dx}{dy}$ can be negative (as it is here), but a density must be nonnegative, so we use the absolute value (this is the 1D version of the Jacobian determinant).\n",
    "\n",
    "---\n",
    "\n",
    "## 4) Compute $\\left|\\frac{dx}{dy}\\right|$\n",
    "\n",
    "We have:\n",
    "$$\n",
    "y=\\frac{1}{x}\n",
    "\\quad\\Longleftrightarrow\\quad\n",
    "x=\\frac{1}{y}.\n",
    "$$\n",
    "Differentiate:\n",
    "$$\n",
    "\\frac{dx}{dy} = \\frac{d}{dy}\\left(\\frac{1}{y}\\right)=-\\frac{1}{y^2}.\n",
    "$$\n",
    "Therefore:\n",
    "$$\n",
    "\\left|\\frac{dx}{dy}\\right|=\\left|-\\frac{1}{y^2}\\right|=\\frac{1}{y^2}.\n",
    "$$\n",
    "\n",
    "This is exactly what your picture shows:\n",
    "$$\n",
    "f_Y(y)=f_X(1/y)\\cdot \\frac{1}{y^2}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5) Compute the density $f_Y(y)$\n",
    "\n",
    "Start from:\n",
    "$$\n",
    "f_Y(y)=f_X(1/y)\\cdot \\frac{1}{y^2}.\n",
    "$$\n",
    "\n",
    "We already have:\n",
    "$$\n",
    "f_X(x)=20 e^{20-1/x}\\left(1+\\frac{1}{x}\\right).\n",
    "$$\n",
    "\n",
    "Substitute $x=\\frac{1}{y}$:\n",
    "- $e^{20-1/x} \\to e^{20-y}$\n",
    "- $\\left(1+\\frac{1}{x}\\right)\\to (1+y)$\n",
    "\n",
    "So:\n",
    "$$\n",
    "f_X(1/y)=20 e^{20-y}(1+y).\n",
    "$$\n",
    "Thus:\n",
    "$$\n",
    "f_Y(y)=20 e^{20-y}(1+y)\\cdot \\frac{1}{y^2},\n",
    "\\quad y>20.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 6) Choose a fast proposal distribution for $Y$\n",
    "\n",
    "Notice $f_Y(y)$ contains the factor $e^{20-y}$, which is the same shape as an exponential tail.\n",
    "\n",
    "Choose the proposal:\n",
    "$$\n",
    "g_Y(y)=e^{-(y-20)}, \\quad y\\ge 20,\n",
    "$$\n",
    "which is the density of:\n",
    "$$\n",
    "Y = 20 + Z,\\quad Z\\sim \\text{Exp}(1).\n",
    "$$\n",
    "\n",
    "This proposal is easy to sample and matches the important exponential decay of the target.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Compute the rejection ratio and the constant $M$\n",
    "\n",
    "Compute:\n",
    "$$\n",
    "\\frac{f_Y(y)}{g_Y(y)}\n",
    "=\n",
    "\\frac{20 e^{20-y}(1+y)/y^2}{e^{-(y-20)}}.\n",
    "$$\n",
    "But\n",
    "$$\n",
    "e^{-(y-20)} = e^{20-y},\n",
    "$$\n",
    "so the exponentials cancel perfectly:\n",
    "$$\n",
    "\\frac{f_Y(y)}{g_Y(y)} = 20\\frac{1+y}{y^2}.\n",
    "$$\n",
    "\n",
    "We need a constant $M$ such that\n",
    "$$\n",
    "\\frac{f_Y(y)}{g_Y(y)}\\le M \\quad \\text{for all } y\\ge 20.\n",
    "$$\n",
    "\n",
    "For $y\\ge 20$, the function $20(1+y)/y^2$ is decreasing, so the maximum is at $y=20$:\n",
    "$$\n",
    "M=20\\frac{1+20}{20^2} = 20\\cdot\\frac{21}{400}=\\frac{420}{400}=1.05.\n",
    "$$\n",
    "\n",
    "So the acceptance probability is:\n",
    "$$\n",
    "\\alpha(y)=\\frac{f_Y(y)}{M g_Y(y)}\n",
    "=\\frac{20(1+y)/y^2}{1.05}.\n",
    "$$\n",
    "\n",
    "This is close to 1 near $y=20$, so rejection is rare (fast).\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Convert accepted $Y$ back to $X$\n",
    "\n",
    "If a proposed $y$ is accepted, set:\n",
    "$$\n",
    "x=\\frac{1}{y}.\n",
    "$$\n",
    "Those $x$ values are samples from the original target distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of the algorithm\n",
    "1. Propose $y = 20 + \\text{Exp}(1)$.\n",
    "2. Accept with probability $\\alpha(y)=\\dfrac{20(1+y)/y^2}{1.05}$.\n",
    "3. If accepted, output $x=1/y$.\n",
    "4. Repeat until you have $n$ samples.\n",
    "\n",
    "This method is fast because the proposal matches the exponential shape of the target in the transformed variable.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef73e41",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def problem1_rejection_2(n_samples):\n",
    "    \"\"\"\n",
    "    Rejection sampling for the distribution with CDF\n",
    "\n",
    "        F(x) = 20 x e^{20 - 1/x},   0 < x < 1/20\n",
    "\n",
    "    Strategy (high level):\n",
    "    ----------------------\n",
    "    1) The target density is extremely concentrated near x = 1/20.\n",
    "       Sampling uniformly on (0, 1/20) would cause many rejections.\n",
    "\n",
    "    2) Introduce the change of variables Y = 1 / X.\n",
    "       This moves the support to Y > 20 and turns the difficult term\n",
    "       e^{20 - 1/x} into a simple exponential decay e^{20 - y}.\n",
    "\n",
    "    3) Sample Y from a shifted exponential distribution:\n",
    "           Y = 20 + Z,  where Z ~ Exp(1)\n",
    "\n",
    "    4) Use rejection sampling in the Y–space with a small rejection\n",
    "       constant M = 1.05.\n",
    "\n",
    "    5) Convert accepted Y values back to X by X = 1 / Y.\n",
    "    \"\"\"\n",
    "\n",
    "    samples = []           # will store accepted X samples\n",
    "    M = 1.05               # rejection constant (tight upper bound)\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 1: Propose a value Y from the proposal distribution g_Y\n",
    "        #         g_Y(y) = exp(-(y - 20)),  y >= 20\n",
    "        #\n",
    "        #         This is equivalent to:\n",
    "        #             Y = 20 + Z,  Z ~ Exp(1)\n",
    "        # ------------------------------------------------------------\n",
    "        y = 20.0 + np.random.exponential(scale=1.0)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 2: Compute the acceptance probability\n",
    "        #\n",
    "        # From the derivation:\n",
    "        #     f_Y(y) / g_Y(y) = 20 * (1 + y) / y^2\n",
    "        #\n",
    "        # The acceptance probability is:\n",
    "        #     alpha(y) = f_Y(y) / (M * g_Y(y))\n",
    "        # ------------------------------------------------------------\n",
    "        accept_prob = (20.0 * (1.0 + y) / (y * y)) / M\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 3: Accept or reject the proposal\n",
    "        #\n",
    "        # Draw U ~ Uniform(0,1). If U <= alpha(y), accept Y.\n",
    "        # ------------------------------------------------------------\n",
    "        u = np.random.uniform(0.0, 1.0)\n",
    "\n",
    "        if u <= accept_prob:\n",
    "            # --------------------------------------------------------\n",
    "            # Step 4: Convert back to X\n",
    "            #\n",
    "            # Recall the transformation:\n",
    "            #     Y = 1 / X   ->   X = 1 / Y\n",
    "            #\n",
    "            # This X now follows the original target distribution.\n",
    "            # --------------------------------------------------------\n",
    "            x = 1.0 / y\n",
    "            samples.append(x)\n",
    "\n",
    "    # Return the samples as a NumPy array\n",
    "    return np.array(samples)\n",
    "  \n",
    "# test = problem1_rejection_2(100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cfe919",
   "metadata": {},
   "source": [
    "So I tried many different distributions for g(x), but this is as close as I get to 2 seconds. I tried uniform, exponential and beta and beta seems to be the best. I tried with many different values for a and b, but I never get lower than roughly 4,5 seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702c210",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 1\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29831136",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "1",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_rejection returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Good, your problem1_rejection_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection returns a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float)) \n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval, tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "try:\n",
    "    assert(isinstance(problem1_rejection_2(10), np.ndarray)) \n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_rejection_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_rejection_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1052c",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 2\n",
    "Maximum Points = 14"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df5824d4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "2. [4p] A page loads in $\\text{Exp}(3)$ (Exponentially distributed with mean $1/3$) seconds if not preloaded and loads with $\\text{Exp}(20)$ (Exponentially distributed with mean $1/20$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $8$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to the stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1bbf8",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "In this problem we have data consisting of user behavior on a website. The pages of the website are just numbers in the dataset $0,1,2,\\ldots$ and each row consists of a user, a source and a destination page. This signifies that the user was on the source page and clicked a link leading them to the destination page. The goal is to improve the user experience by decreasing load time of the next page visited, as such we need a good estimate for the next site likely to be visited. We will model this using a homogeneous Markov chain, each row in the data-file then corresponds to a single realization of a transition. \n",
    "\n",
    "1. [3p] Load the data in the file `data/websites.csv` and construct a matrix of size `n_pages x n_pages` which is the maximum likelihood estimate of the true transition matrix for the Markov chain. Here the ordering of the states are exactly the ones in the data-file, that is page $0$ has index $0$ in the matrix.\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f42764",
   "metadata": {},
   "source": [
    "### How the transition-count loop works (4×4 example summary)\n",
    "\n",
    "Assume we have a website with **4 pages**, labeled $0, 1, 2, 3$.  \n",
    "We therefore construct a **$4 \\times 4$ transition-count matrix** called `counts`, initialized with zeros:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{counts} &= \n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Each row in the dataset corresponds to **one observed transition** from a *source page* to a *destination page*.\n",
    "\n",
    "The loop\n",
    "\n",
    "```python\n",
    "for _, row in data.iterrows():\n",
    "    i = int(row[\"source\"])\n",
    "    j = int(row[\"destination\"])\n",
    "    counts[i, j] += 1\n",
    "```\n",
    "\n",
    "works as follows:\n",
    "\n",
    "- The loop iterates through the dataset **row by row**\n",
    "- For each row:\n",
    "  - $i$ is the current page (value in `source`)\n",
    "  - $j$ is the next page (value in `destination`)\n",
    "  - The matrix entry `counts[i, j]` is increased by $1$\n",
    "\n",
    "This means:\n",
    "- **Rows** represent the current page\n",
    "- **Columns** represent the next page\n",
    "- `counts[i, j]` stores how many times the transition $i \\rightarrow j$ was observed\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose the dataset contains the following transitions:\n",
    "\n",
    "$1 \\rightarrow 3$  \n",
    "$1 \\rightarrow 2$  \n",
    "$3 \\rightarrow 2$  \n",
    "$1 \\rightarrow 3$\n",
    "\n",
    "After processing all rows, the count matrix becomes:\n",
    "\n",
    "$$\n",
    "\\text{counts} =\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 2 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This tells us:\n",
    "- From page $1$, users moved to page $2$ once and to page $3$ twice\n",
    "- From page $3$, users moved to page $2$ once\n",
    "\n",
    "This count matrix is then **row-normalized** to obtain the **maximum likelihood estimate of the Markov transition matrix**, where each row represents a probability distribution over the next page given the current page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5c6b5f4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the problem2_n_states:  10\n",
      "Counts: \n",
      " [[ 0. 22.  0. 10.  4.  1.  7.  9. 13. 17.]\n",
      " [13.  0. 12. 27.  2. 30. 16. 18.  4.  6.]\n",
      " [19. 12.  0. 11. 14. 16.  2.  0.  4. 14.]\n",
      " [ 1. 10. 21.  0.  8.  7. 15. 21.  0. 23.]\n",
      " [13. 12.  8. 10.  0.  7. 12.  4.  2.  4.]\n",
      " [ 1. 19.  3.  6. 16.  0. 16.  2. 18. 21.]\n",
      " [ 4.  7. 20.  9.  0. 16.  0. 16. 27. 16.]\n",
      " [15.  5.  1. 12.  8.  3. 20.  0. 16. 13.]\n",
      " [12. 10. 12.  4.  6. 14.  7.  8.  0. 11.]\n",
      " [ 4. 31. 15. 17. 14.  8. 20. 15.  0.  0.]]\n",
      "This is the correct transition matrix with correct probabilities: \n",
      " [[0.         0.26506024 0.         0.12048193 0.04819277 0.01204819\n",
      "  0.08433735 0.10843373 0.15662651 0.20481928]\n",
      " [0.1015625  0.         0.09375    0.2109375  0.015625   0.234375\n",
      "  0.125      0.140625   0.03125    0.046875  ]\n",
      " [0.20652174 0.13043478 0.         0.11956522 0.15217391 0.17391304\n",
      "  0.02173913 0.         0.04347826 0.15217391]\n",
      " [0.00943396 0.09433962 0.19811321 0.         0.0754717  0.06603774\n",
      "  0.14150943 0.19811321 0.         0.21698113]\n",
      " [0.18055556 0.16666667 0.11111111 0.13888889 0.         0.09722222\n",
      "  0.16666667 0.05555556 0.02777778 0.05555556]\n",
      " [0.00980392 0.18627451 0.02941176 0.05882353 0.15686275 0.\n",
      "  0.15686275 0.01960784 0.17647059 0.20588235]\n",
      " [0.03478261 0.06086957 0.17391304 0.07826087 0.         0.13913043\n",
      "  0.         0.13913043 0.23478261 0.13913043]\n",
      " [0.16129032 0.05376344 0.01075269 0.12903226 0.08602151 0.03225806\n",
      "  0.21505376 0.         0.17204301 0.13978495]\n",
      " [0.14285714 0.11904762 0.14285714 0.04761905 0.07142857 0.16666667\n",
      "  0.08333333 0.0952381  0.         0.13095238]\n",
      " [0.03225806 0.25       0.12096774 0.13709677 0.11290323 0.06451613\n",
      "  0.16129032 0.12096774 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 1: Maximum Likelihood Estimation of a Markov chain\n",
    "# ------------------------------------------------------------\n",
    "# We model user navigation on a website as a homogeneous Markov chain.\n",
    "# Each page is a state, and each row in the dataset corresponds to\n",
    "# one observed transition from a source page to a destination page.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Load the dataset\n",
    "# ------------------------------------------------------------\n",
    "# The CSV file contains three columns:\n",
    "#   - user        : user identifier (NOT used in the Markov model)\n",
    "#   - source      : page the user is currently on\n",
    "#   - destination : page the user clicks next\n",
    "#\n",
    "# Each row corresponds to exactly ONE observed transition:\n",
    "#     source -> destination\n",
    "#\n",
    "# Since the Markov chain is assumed to be homogeneous, the transition\n",
    "# probabilities depend ONLY on the current page, not on the user.\n",
    "# Therefore, we completely ignore the \"user\" column.\n",
    "data = pd.read_csv(\"data/websites.csv\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Determine how many states (pages) exist\n",
    "# ------------------------------------------------------------\n",
    "# Pages are labeled as integers: 0, 1, 2, ...\n",
    "#\n",
    "# If the largest page ID appearing in the data is M,\n",
    "# then the total number of states is M + 1.\n",
    "#\n",
    "# We must check BOTH the \"source\" and \"destination\" columns:\n",
    "# - A page might appear only as a destination and still be a valid state.\n",
    "max_page_id = max(data[\"source\"].max(), data[\"destination\"].max())\n",
    "problem2_n_states = int(max_page_id + 1)\n",
    "\n",
    "# This tells us the size of the transition matrix:\n",
    "# problem2_n_states x problem2_n_states\n",
    "print(\"This is the problem2_n_states: \", problem2_n_states)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Create a transition count matrix\n",
    "# ------------------------------------------------------------\n",
    "# counts[i, j] will store how many times we observed a transition:\n",
    "#     page i  ->  page j\n",
    "#\n",
    "# Initially, we set all counts to zero.\n",
    "counts = np.zeros((problem2_n_states, problem2_n_states), dtype=float)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Count transitions from the dataset\n",
    "# ------------------------------------------------------------\n",
    "# We loop through each row of the dataset.\n",
    "# For each observed transition:\n",
    "#   - i = source page\n",
    "#   - j = destination page\n",
    "# we increment counts[i, j] by 1.\n",
    "#\n",
    "# After this loop, counts[i, j] equals the total number of times\n",
    "# users moved from page i to page j in the data.\n",
    "for _, row in data.iterrows():\n",
    "    i = int(row[\"source\"])        # current page (state i)\n",
    "    j = int(row[\"destination\"])   # next page (state j)\n",
    "    counts[i, j] += 1             # record one observed transition i -> j\n",
    "\n",
    "# Display the raw transition counts\n",
    "print(\"Counts: \\n\", counts)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Convert counts to transition probabilities (MLE)\n",
    "# ------------------------------------------------------------\n",
    "# For a Markov chain, the maximum likelihood estimator (MLE) is:\n",
    "#\n",
    "#   P_hat[i, j] = counts[i, j] / sum_j counts[i, j]\n",
    "#\n",
    "# That is:\n",
    "# - Each row is normalized so it sums to 1\n",
    "# - Each row becomes a probability distribution over next pages\n",
    "#\n",
    "# IMPORTANT EDGE CASE:\n",
    "# If a page i never appears as a source in the dataset, then\n",
    "#   sum_j counts[i, j] = 0\n",
    "# In that case, division by zero is impossible.\n",
    "# We handle this by leaving that entire row as zeros.\n",
    "problem2_transition_matrix = np.zeros_like(counts)\n",
    "\n",
    "for i in range(problem2_n_states):\n",
    "    # Total number of observed outgoing transitions from page i\n",
    "    row_sum = counts[i].sum()\n",
    "\n",
    "    if row_sum > 0:\n",
    "        # Normalize the row so probabilities sum to 1\n",
    "        problem2_transition_matrix[i, :] = counts[i, :] / row_sum\n",
    "    else:\n",
    "        # No observed transitions leaving page i\n",
    "        # We leave the row as all zeros\n",
    "        problem2_transition_matrix[i, :] = 0.0\n",
    "\n",
    "# Print the estimated transition matrix\n",
    "print(\"This is the correct transition matrix with correct probabilities: \\n\",\n",
    "      problem2_transition_matrix)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# (Optional) 6) Sanity check\n",
    "# ------------------------------------------------------------\n",
    "# For a valid transition matrix:\n",
    "# - Rows with outgoing transitions should sum to 1\n",
    "# - Rows with no outgoing transitions should sum to 0\n",
    "#\n",
    "# This line ONLY computes the row sums; it does not change anything.\n",
    "# Uncomment it if you want to verify correctness.\n",
    "# print(problem2_transition_matrix.sum(axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e050b",
   "metadata": {},
   "source": [
    "2. [4p] A page loads in $\\text{Exp}(3)$ (Exponentially distributed with mean $1/3$) seconds if not preloaded and loads with $\\text{Exp}(20)$ (Exponentially distributed with mean $1/20$) seconds if preloaded and we only preload the most likely next site. Given that we start in page $8$ simulate $10000$ load times from page $1$ (that is, only a single step), store the result in the variable indicated in the cell.\n",
    "Repeat the experiment but this time preload the two most likely pages and store the result in the indicated variable.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4566e275",
   "metadata": {},
   "source": [
    "## Part 2 — Simulate page load times with preloading (one-step from page 8)\n",
    "\n",
    "### Given (from the problem)\n",
    "- We start at page (state) **8**.\n",
    "- We simulate **one single step** of the Markov chain (i.e., we only care about the next page).\n",
    "- If the next page is **not preloaded**, load time $\\sim \\mathrm{Exp}(3)$, mean $1/3$ seconds.\n",
    "- If the next page **is preloaded**, load time $\\sim \\mathrm{Exp}(20)$, mean $1/20$ seconds.\n",
    "- We simulate **10,000** load times.\n",
    "- We do two experiments:\n",
    "  1. Preload the **single most likely** next page (top-1).\n",
    "  2. Preload the **two most likely** next pages (top-2).\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1) Identify the transition probabilities from page 8\n",
    "Let $\\hat P$ be the estimated transition matrix from Part 1.\n",
    "\n",
    "The one-step transition probabilities from page 8 are the **row 8** of $\\hat P$:\n",
    "$$\n",
    "p_j = P(X_{t+1}=j \\mid X_t=8) = \\hat P_{8j}.\n",
    "$$\n",
    "In code, this is:\n",
    "- `p_next = problem2_transition_matrix[8, :]`\n",
    "\n",
    "This probability vector is used to sample which next page each user visits.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2) Find which pages to preload (top-1 and top-2)\n",
    "From the probability vector `p_next`, we sort pages by probability (largest first):\n",
    "- **Top-1 page** = the index with the largest probability in `p_next`\n",
    "- **Top-2 pages** = the two indices with the largest probabilities in `p_next`\n",
    "\n",
    "In code, this is typically done with:\n",
    "- `sorted_pages = np.argsort(p_next)[::-1]`\n",
    "- `top1_page = sorted_pages[0]`\n",
    "- `top2_pages = sorted_pages[:2]`\n",
    "\n",
    "These are the pages we assume we will preload.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3) Simulate the next page for each of 10,000 users\n",
    "For each user, we sample exactly one next page:\n",
    "$$\n",
    "X_{t+1} \\sim \\text{Categorical}(p_0,\\ldots,p_{n-1}).\n",
    "$$\n",
    "In NumPy, this is:\n",
    "- `next_pages = np.random.choice(problem2_n_states, size=10000, p=p_next)`\n",
    "\n",
    "This produces an array `next_pages` of length 10,000 with the realized next page for each user.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4) Convert “preloaded or not” into load times\n",
    "### Load time distributions\n",
    "- Not preloaded: $\\mathrm{Exp}(3)$ has mean $1/3$\n",
    "- Preloaded: $\\mathrm{Exp}(20)$ has mean $1/20$\n",
    "\n",
    "Important NumPy detail:\n",
    "- `np.random.exponential(scale=...)` uses `scale = mean`.\n",
    "\n",
    "So we generate load times using:\n",
    "- not preloaded: `np.random.exponential(scale=1/3, size=10000)`\n",
    "- preloaded: `np.random.exponential(scale=1/20, size=10000)`\n",
    "\n",
    "Then we pick the correct time per user using a boolean mask and `np.where(...)`.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 5) Experiment A — preload only the most likely next page (top-1)\n",
    "1. Sample `next_pages_top` from `p_next`.\n",
    "2. Mark preloaded users:\n",
    "   - `is_preloaded_top = (next_pages_top == top1_page)`\n",
    "3. Generate load times (fast and slow).\n",
    "4. Combine them:\n",
    "   - If `is_preloaded_top[i]` is True, user i gets a fast time (Exp(20))\n",
    "   - Otherwise, user i gets a slow time (Exp(3))\n",
    "\n",
    "Store the resulting 10,000 simulated times in:\n",
    "- `problem2_page_load_times_top`\n",
    "\n",
    "---\n",
    "\n",
    "## Step 6) Experiment B — preload the two most likely pages (top-2)\n",
    "1. Sample `next_pages_two` from `p_next` (new independent simulation).\n",
    "2. Mark preloaded users:\n",
    "   - `is_preloaded_two = np.isin(next_pages_two, top2_pages)`\n",
    "3. Generate load times (fast and slow) again.\n",
    "4. Combine them with `np.where(...)`.\n",
    "\n",
    "Store the resulting 10,000 simulated times in:\n",
    "- `problem2_page_load_times_two`\n",
    "\n",
    "---\n",
    "\n",
    "## What you should end up with\n",
    "- `problem2_page_load_times_top`: NumPy array of length 10,000 (top-1 preloading)\n",
    "- `problem2_page_load_times_two`: NumPy array of length 10,000 (top-2 preloading)\n",
    "\n",
    "Each array contains simulated one-step load times starting from page 8 under the given preloading strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a185d17",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start page: 7\n",
      "Top-1 preloaded page: 6\n",
      "Top-2 preloaded pages: [6 8]\n",
      "Mean load time (top-1 preloaded): 0.2734820326103514\n",
      "Mean load time (top-2 preloaded): 0.22838273971559164\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 2: Simulate page load times for ONE STEP starting from page 8\n",
    "# ------------------------------------------------------------\n",
    "# We do exactly ONE Markov transition:\n",
    "#   1) We start at a fixed page: current_page = 7\n",
    "#   2) We sample the next page using the estimated transition probabilities:\n",
    "#        next_page ~ Categorical( problem2_transition_matrix[7, :] )\n",
    "#\n",
    "# Then we simulate the *load time* for that next page depending on whether it was preloaded:\n",
    "# - If the realized next page IS preloaded:\n",
    "#       load time ~ Exp(20)  -> mean = 1/20 seconds (fast)\n",
    "# - If the realized next page is NOT preloaded:\n",
    "#       load time ~ Exp(3)   -> mean = 1/3 seconds (slow)\n",
    "#\n",
    "# IMPORTANT NUMPY NOTE:\n",
    "# np.random.exponential(scale=...) uses \"scale\" = mean of the exponential distribution.\n",
    "# So:\n",
    "#   Exp(3)  (rate=3)  => mean = 1/3  => scale = 1/3\n",
    "#   Exp(20) (rate=20) => mean = 1/20 => scale = 1/20\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# -----------------------------\n",
    "# Settings\n",
    "# -----------------------------\n",
    "n_users = 10000          # We simulate 10,000 independent \"users\"/trials\n",
    "current_page = 7         # We start from page 8 (0-indexed)\n",
    "\n",
    "# Probability distribution over next pages given we are currently on page 8.\n",
    "# This is the 8th row of the transition matrix:\n",
    "#   p_next[j] = P(next_page = j | current_page = 7)\n",
    "p_next = problem2_transition_matrix[current_page, :]\n",
    "\n",
    "# -----------------------------\n",
    "# Find the most likely next pages\n",
    "# -----------------------------\n",
    "# We want to know which next page(s) are most probable from page 8,\n",
    "# because those are the ones we will preload.\n",
    "#\n",
    "# np.argsort(p_next) gives indices sorted from smallest prob to largest prob.\n",
    "# Reversing [::-1] gives largest to smallest.\n",
    "sorted_pages = np.argsort(p_next)[::-1]\n",
    "\n",
    "top1_page = sorted_pages[0]      # single most likely next page from page 8\n",
    "top2_pages = sorted_pages[:2]    # two most likely next pages from page 8\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Preloading ONLY the most likely page (top-1)\n",
    "# -----------------------------\n",
    "# Experiment idea:\n",
    "# - For each of the 10,000 trials:\n",
    "#     * sample which next page happens (using p_next)\n",
    "#     * if that next page equals top1_page => it was preloaded => faster Exp(20)\n",
    "#     * otherwise => not preloaded => slower Exp(3)\n",
    "\n",
    "# Sample next pages for 10,000 users using the categorical distribution p_next\n",
    "next_pages_top = np.random.choice(\n",
    "    problem2_n_states,   # possible page labels: 0, 1, ..., n_states-1\n",
    "    size=n_users,        # number of independent samples\n",
    "    p=p_next             # probability for each page\n",
    ")\n",
    "\n",
    "# Boolean array: True if the sampled next page is the one we preloaded (top-1), else False\n",
    "is_preloaded_top = (next_pages_top == top1_page)\n",
    "\n",
    "# Draw load times for BOTH cases (vectorized):\n",
    "# - one array of \"slow\" times (not preloaded), Exp(3)\n",
    "# - one array of \"fast\" times (preloaded), Exp(20)\n",
    "#\n",
    "# We draw n_users values for each, then select elementwise with np.where.\n",
    "load_times_not_preloaded = np.random.exponential(scale=1/3, size=n_users)   # Exp(3)\n",
    "load_times_preloaded     = np.random.exponential(scale=1/20, size=n_users)  # Exp(20)\n",
    "\n",
    "# For each user:\n",
    "# - if preloaded -> take the fast sample\n",
    "# - else         -> take the slow sample\n",
    "problem2_page_load_times_top = np.where(\n",
    "    is_preloaded_top,\n",
    "    load_times_preloaded,\n",
    "    load_times_not_preloaded\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Preloading the TWO most likely pages (top-2)\n",
    "# -----------------------------\n",
    "# Same idea, but now we preload TWO pages: the two largest-probability destinations.\n",
    "# A trial is \"preloaded\" if its sampled next page is in top2_pages.\n",
    "\n",
    "# Sample next pages again for a new independent experiment\n",
    "next_pages_two = np.random.choice(\n",
    "    problem2_n_states,\n",
    "    size=n_users,\n",
    "    p=p_next\n",
    ")\n",
    "\n",
    "# Boolean array: True if the next page is either of the two preloaded pages\n",
    "is_preloaded_two = np.isin(next_pages_two, top2_pages)\n",
    "\n",
    "# Draw load times again (fresh samples for this second experiment)\n",
    "load_times_not_preloaded = np.random.exponential(scale=1/3, size=n_users)   # Exp(3)\n",
    "load_times_preloaded     = np.random.exponential(scale=1/20, size=n_users)  # Exp(20)\n",
    "\n",
    "# Select fast vs slow times depending on whether the realized page was preloaded\n",
    "problem2_page_load_times_two = np.where(\n",
    "    is_preloaded_two,\n",
    "    load_times_preloaded,\n",
    "    load_times_not_preloaded\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Optional sanity-check outputs\n",
    "# -----------------------------\n",
    "# These prints are just to help you see what the code is doing.\n",
    "# They are not required unless the assignment asks for output.\n",
    "print(\"Start page:\", current_page)\n",
    "print(\"Top-1 preloaded page:\", top1_page)\n",
    "print(\"Top-2 preloaded pages:\", top2_pages)\n",
    "print(\"Mean load time (top-1 preloaded):\", problem2_page_load_times_top.mean())\n",
    "print(\"Mean load time (top-2 preloaded):\", problem2_page_load_times_two.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481678d",
   "metadata": {},
   "source": [
    "3. [3p] Compare the average (empirical) load time from part 2 with the theoretical one of no pre-loading. Does the load time improve, how did you come to this conclusion? (Explain in the free text field).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ef430",
   "metadata": {},
   "source": [
    "## Part 3 — Comparison of average load times\n",
    "\n",
    "### 1) Average load time without preloading\n",
    "If no page is preloaded, the load time always follows an exponential distribution\n",
    "$\\mathrm{Exp}(3)$.\n",
    "\n",
    "For an exponential distribution with rate $\\lambda$, the expected value is:\n",
    "$$\n",
    "\\mathbb{E}[T] = \\frac{1}{\\lambda}.\n",
    "$$\n",
    "\n",
    "Therefore, the true expected load time without preloading is:\n",
    "$$\n",
    "\\mathbb{E}[T_{\\text{no preload}}] = \\frac{1}{3}.\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Empirical average load time with top-1 preloading\n",
    "From Part 2, we simulated load times when preloading the most likely next page.\n",
    "These simulated values are stored in the variable:\n",
    "\n",
    "`problem2_page_load_times_top`\n",
    "\n",
    "The empirical average load time is computed as the sample mean of this array.\n",
    "\n",
    "---\n",
    "\n",
    "### 3) Comparison and conclusion\n",
    "To answer the question  \n",
    "“Is the average load time without preloading larger than the average load time with top-1 preloading?”  \n",
    "\n",
    "we compare:\n",
    "$$\n",
    "\\frac{1}{3} \\quad \\text{with} \\quad \\overline{T}_{\\text{top-1}}.\n",
    "$$\n",
    "\n",
    "If the empirical mean load time with top-1 preloading is smaller than $1/3$,\n",
    "then preloading improves the average load time.\n",
    "\n",
    "Since preloading increases the probability that the fast distribution\n",
    "$\\mathrm{Exp}(20)$ (mean $1/20$) is used instead of $\\mathrm{Exp}(3)$,\n",
    "the average load time is reduced. Therefore, preloading the most likely next page\n",
    "leads to an improvement in load time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29888c75",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 3: 3 points\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# True expected load time with NO preloading:\n",
    "# load time ~ Exp(3) => mean = 1/3\n",
    "problem2_avg = 1/3  # A float\n",
    "\n",
    "# Compare to the empirical mean from Part 2 (top-1 preloading)\n",
    "problem2_comparison = problem2_avg > float(np.mean(problem2_page_load_times_top))  # True / False\n",
    "problem2_comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d40571f",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put the explanation for **part 3** of how you made the decision about `problem2_comparison` below this line in this **cell**. In order to enter edit mode you can doubleclick this cell or select it and press enter.\n",
    "\n",
    "I am assuming that problem2_page_load_times_top is used, not problem2_page_load_times_two.\n",
    "But both are calculated above.\n",
    "The average time time is simply the mean of the samples of time. It therefore becomes quite small: 0.2648629205627815 seconds\n",
    "(Average load time for problem2_page_load_times_two:  0.21635340436426223)\n",
    "\n",
    "But the average loading time wihout any pre-loading would become 1/3 seconds. This is because 1/3 is the mean of the distribution. So in theory, if we simulated with infinity and not 10000 and use no pre-loading, we would land at 1/3 seconds on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbf5cd0",
   "metadata": {},
   "source": [
    "4. [4p] Calculate the stationary distribution of the Markov chain and calculate the expected load time with respect to the stationary distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f43a3",
   "metadata": {},
   "source": [
    "## Part 4 — Stationary distribution and expected load time under stationarity\n",
    "\n",
    "### Goal\n",
    "1) Compute the stationary distribution $\\pi$ of the Markov chain with transition matrix $\\hat P$.\n",
    "2) Use $\\pi$ to compute the expected load time when we preload the **single most likely next page** from each current page.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1) Stationary distribution\n",
    "A stationary distribution $\\pi$ satisfies:\n",
    "$$\n",
    "\\pi \\hat P = \\pi,\n",
    "$$\n",
    "meaning that if the current page is distributed as $\\pi$, then the next page is also distributed as $\\pi$.\n",
    "\n",
    "Equivalently, $\\pi^T$ is an eigenvector of $\\hat P^T$ with eigenvalue $1$:\n",
    "$$\n",
    "\\hat P^T \\pi^T = 1 \\cdot \\pi^T.\n",
    "$$\n",
    "So we compute eigenvalues/eigenvectors of $\\hat P^T$, pick the eigenvector whose eigenvalue is closest to $1$, take the real part (numerical routines may produce tiny imaginary parts), and normalize it so it sums to $1$.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2) Expected load time from a given page i (top-1 preloading)\n",
    "From each page $i$, we preload the single most likely next page:\n",
    "$$\n",
    "j^*(i) = \\arg\\max_j \\hat P_{ij}.\n",
    "$$\n",
    "\n",
    "Let:\n",
    "$$\n",
    "p_i = \\hat P_{i, j^*(i)}\n",
    "$$\n",
    "be the probability that the realized next page is exactly the preloaded one.\n",
    "\n",
    "Load times:\n",
    "- Preloaded: $\\mathrm{Exp}(20)$ with mean $1/20$\n",
    "- Not preloaded: $\\mathrm{Exp}(3)$ with mean $1/3$\n",
    "\n",
    "So the conditional expected load time given current page $i$ is:\n",
    "$$\n",
    "\\mathbb{E}[T \\mid X_t=i] = \\frac{1}{20} \\, p_i + \\frac{1}{3} (1 - p_i).\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3) Expected load time under the stationary distribution\n",
    "Under stationarity, the current page equals $i$ with probability $\\pi_i$. Therefore:\n",
    "$$\n",
    "\\mathbb{E}[T] = \\sum_i \\pi_i \\, \\mathbb{E}[T \\mid X_t=i].\n",
    "$$\n",
    "\n",
    "In code this is a dot product between the stationary distribution vector and the vector of conditional expected times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96e0d40",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary distribution:\n",
      " [0.08212278 0.12810291 0.09219365 0.10612032 0.0721337  0.10215028\n",
      " 0.11517528 0.09308925 0.08396098 0.12495085]\n",
      "Stationary expected loading time: 0.27094210390432294\n"
     ]
    }
   ],
   "source": [
    "# Part 4: 4 points\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 4.1: Stationary distribution via eigenvector of P^T\n",
    "# ------------------------------------------------------------\n",
    "# A stationary distribution pi satisfies:\n",
    "#   pi P = pi\n",
    "# Equivalently, pi^T is a right eigenvector of P^T with eigenvalue 1.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "P = problem2_transition_matrix\n",
    "n = problem2_n_states\n",
    "\n",
    "# Compute eigenvalues/eigenvectors of P^T\n",
    "eigvals, eigvecs = np.linalg.eig(P.T)\n",
    "\n",
    "# Find eigenvalue closest to 1\n",
    "idx = np.argmin(np.abs(eigvals - 1.0))\n",
    "\n",
    "# Corresponding eigenvector (take real part if complex due to numerical noise)\n",
    "pi = np.real(eigvecs[:, idx])\n",
    "\n",
    "# Fix arbitrary sign (eigenvectors can be multiplied by -1)\n",
    "if pi.sum() < 0:\n",
    "    pi = -pi\n",
    "\n",
    "# Clamp tiny negatives from numerical noise, then normalize to sum to 1\n",
    "pi = np.maximum(pi, 0.0)\n",
    "pi = pi / pi.sum()\n",
    "\n",
    "problem2_stationary_distribution = pi  # shape (n,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Part 4.2: Expected load time under stationary distribution\n",
    "# ------------------------------------------------------------\n",
    "# From each current page i, we preload the single most likely next page.\n",
    "# Let p_preloaded[i] be the probability that the next page is that preloaded page.\n",
    "# Then:\n",
    "#   E[T | i] = (1/20)*p_preloaded[i] + (1/3)*(1 - p_preloaded[i])\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Most likely next page from each page i\n",
    "top_next = np.argmax(P, axis=1)  # shape (n,)\n",
    "\n",
    "# Probability that the next page equals the preloaded page\n",
    "p_preloaded = P[np.arange(n), top_next]  # shape (n,)\n",
    "\n",
    "# Conditional expected load time given current page i\n",
    "expected_time_given_i = (1/20) * p_preloaded + (1/3) * (1 - p_preloaded)  # shape (n,)\n",
    "\n",
    "# Expected load time under stationary distribution\n",
    "problem2_avg_stationary = float(problem2_stationary_distribution @ expected_time_given_i)\n",
    "\n",
    "# Optional prints for inspection\n",
    "print(\"Stationary distribution:\\n\", problem2_stationary_distribution)\n",
    "print(\"Stationary expected loading time:\", problem2_avg_stationary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e0950",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 2\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38670590",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "2",
    "lx_problem_points": "14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem2_transition_matrix is a numpy array\n",
      "Good, your problem2_n_states is an integer\n",
      "Good, your problem2_transition_matrix has the correct shape\n",
      "Good, your problem2_page_load_times_top is a numpy array of shape (10000,)\n",
      "Good, your problem2_page_load_times_two is a numpy array of shape (10000,)\n",
      "Good, your problem2_avg is a float\n",
      "Good, your problem2_comparison is a boolean\n",
      "Good, your problem2_stationary_distribution is a numpy array of shape (problem2_n_states,)\n",
      "Good, your problem2_avg_stationary is a float\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert isinstance(problem2_transition_matrix, np.ndarray)\n",
    "except:\n",
    "    print(\"Try again. your problem2_transition_matrix is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem2_transition_matrix is a numpy array\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_n_states, int)\n",
    "except:\n",
    "    print(\"Try again. your problem2_n_states is not an integer\")\n",
    "else:\n",
    "    print(\"Good, your problem2_n_states is an integer\")\n",
    "\n",
    "try:\n",
    "    assert problem2_transition_matrix.shape == (problem2_n_states, problem2_n_states)\n",
    "except:\n",
    "    print(\"Try again. your problem2_transition_matrix does not have the correct shape\")\n",
    "else:\n",
    "    print(\"Good, your problem2_transition_matrix has the correct shape\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_page_load_times_top, np.ndarray), \"problem2_page_load_times_top is not a numpy array\"\n",
    "    assert problem2_page_load_times_top.shape == (10000,), \"problem2_page_load_times_top does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_page_load_times_top is a numpy array of shape (10000,)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_page_load_times_two, np.ndarray), \"problem2_page_load_times_two is not a numpy array\"\n",
    "    assert problem2_page_load_times_two.shape == (10000,), \"problem2_page_load_times_two does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_page_load_times_two is a numpy array of shape (10000,)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem2_avg, float), \"problem2_avg is not a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_avg is a float\")\n",
    "try:\n",
    "    assert isinstance(problem2_comparison, bool), \"problem2_comparison is not a boolean\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_comparison is a boolean\")\n",
    "try:\n",
    "    assert isinstance(problem2_stationary_distribution, np.ndarray), \"problem2_stationary_distribution is not a numpy array\"\n",
    "    assert problem2_stationary_distribution.shape == (problem2_n_states,), \"problem2_stationary_distribution does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_stationary_distribution is a numpy array of shape (problem2_n_states,)\")\n",
    "try:\n",
    "    assert isinstance(problem2_avg_stationary, float), \"problem2_avg_stationary is not a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem2_avg_stationary is a float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27550db",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "## Exam vB, PROBLEM 3\n",
    "Maximum Points = 12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50e8fe1b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n",
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n",
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n",
    "3. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49474851",
   "metadata": {},
   "source": [
    "-----\n",
    "## Explanation of variables produced by `train_test_validation`\n",
    "\n",
    "The function `train_test_validation(X, Y, shuffle=True, random_state=1)` splits the dataset into **three disjoint parts**: training, validation, and test data. Each part contains feature vectors and their corresponding labels.\n",
    "\n",
    "### Training set\n",
    "- **`PROBLEM3_X_train`**  \n",
    "  Feature matrix for the **training set**.  \n",
    "  Shape: $(n_{\\text{train}}, d)$, where $d$ is the number of features.  \n",
    "  Used to **fit (train)** the logistic regression model.\n",
    "\n",
    "- **`PROBLEM3_y_train`**  \n",
    "  Label vector for the **training set**.  \n",
    "  Shape: $(n_{\\text{train}},)$.  \n",
    "  Contains the true class labels used during training.\n",
    "\n",
    "### Validation set\n",
    "- **`PROBLEM3_X_val`**  \n",
    "  Feature matrix for the **validation set**.  \n",
    "  Shape: $(n_{\\text{val}}, d)$.  \n",
    "  Used for **model selection**, in particular for choosing the decision threshold.\n",
    "\n",
    "- **`PROBLEM3_y_val`**  \n",
    "  Label vector for the **validation set**.  \n",
    "  Shape: $(n_{\\text{val}},)$.  \n",
    "  Used to evaluate cost, precision, recall, and 0–1 loss when selecting thresholds.\n",
    "\n",
    "- **`PROBLEM3_y_true_val`**  \n",
    "  Same as `PROBLEM3_y_val`, stored under a clearer name to emphasize that these are the **true labels** for the validation set.\n",
    "\n",
    "- **`PROBLEM3_y_pred_proba_val`**  \n",
    "  Predicted probabilities $P(Y=1 \\mid X)$ for the **validation set**, produced by the trained logistic regression model.  \n",
    "  Used to:\n",
    "  - compute cost as a function of the threshold,\n",
    "  - find the optimal threshold,\n",
    "  - compute precision and recall on validation data.\n",
    "\n",
    "### Test set\n",
    "- **`PROBLEM3_X_test`**  \n",
    "  Feature matrix for the **test set**.  \n",
    "  Shape: $(n_{\\text{test}}, d)$.  \n",
    "  Used **only for final evaluation**, after all thresholds and decisions are fixed.\n",
    "\n",
    "- **`PROBLEM3_y_test`**  \n",
    "  Label vector for the **test set**.  \n",
    "  Shape: $(n_{\\text{test}},)$.  \n",
    "  Contains the true class labels for final evaluation.\n",
    "\n",
    "- **`PROBLEM3_y_true_test`**  \n",
    "  Same as `PROBLEM3_y_test`, emphasizing that these are the **true labels** for the test set.\n",
    "\n",
    "- **`PROBLEM3_y_pred_proba_test`**  \n",
    "  Predicted probabilities $P(Y=1 \\mid X)$ for the **test set**.  \n",
    "  Used to compute the final cost and construct a confidence interval.\n",
    "\n",
    "### Summary\n",
    "- **Training set**: used to learn model parameters  \n",
    "- **Validation set**: used to choose thresholds and compare decision rules  \n",
    "- **Test set**: used to estimate final performance and uncertainty  \n",
    "\n",
    "This separation prevents information leakage and ensures an unbiased evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ce125b",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# RUN THIS CELL TO GET THE DATA\n",
    "\n",
    "# We start by loading the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "PROBLEM3_DF = pd.read_csv('data/fraud.csv')\n",
    "Y = PROBLEM3_DF['Class'].values\n",
    "X = PROBLEM3_DF[['V%d' % i for i in range(1,5)]+['Amount']].values\n",
    "\n",
    "# We will split the data into training, testing and validation sets\n",
    "from Utils import train_test_validation\n",
    "PROBLEM3_X_train, PROBLEM3_X_test, PROBLEM3_X_val, PROBLEM3_y_train, PROBLEM3_y_test, PROBLEM3_y_val = train_test_validation(X,Y,shuffle=True,random_state=1)\n",
    "\n",
    "# From this we will train a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(PROBLEM3_X_train,PROBLEM3_y_train)\n",
    "\n",
    "# THE FOLLOWING CODE WILL PRODUCE THE ARRAYS YOU NEED FOR THE PROBLEM\n",
    "\n",
    "PROBLEM3_y_pred_proba_val = lr.predict_proba(PROBLEM3_X_val)[:,1]\n",
    "PROBLEM3_y_true_val = PROBLEM3_y_val\n",
    "\n",
    "PROBLEM3_y_pred_proba_test = lr.predict_proba(PROBLEM3_X_test)[:,1]\n",
    "PROBLEM3_y_true_test = PROBLEM3_y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9733ab",
   "metadata": {},
   "source": [
    "-----\n",
    "In this problem we are interested in fraud detection in an e-commerce system. In this problem we are given the outputs of a classifier that predicts the probabilities of fraud, your goal is to explore the threshold choice as in individual assignment 4. The costs associated with the predictions are:\n",
    "\n",
    "* **True Positive (TP)**: Detecting fraud and blocking the transaction costs the company 100 (manual review etc.)\n",
    "* **True Negative (TN)**: Allowing a legitimate transaction has no cost.\n",
    "* **False Positive (FP)**: Incorrectly classifying a legitimate transaction as fraudulent costs 120 (customer dissatisfaction plus operational expenses for reversing the decision).\n",
    "* **False Negative (FN)**: Missing a fraudulent transaction costs the company 600 (e.g., fraud loss plus potential reputational damage or penalties).\n",
    "\n",
    "**The code cells contain more detailed instructions, THE FIRST CODE CELL INITIALIZES YOUR VARIABLES**\n",
    "\n",
    "1. [3p] Complete filling the function `cost` to compute the average cost of a prediction model under a certain prediction threshold. Plot the cost as a function of the threshold (using the validation data provided in the first code cell of this problem), between 0 and 1 with 0.01 increments.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad4596b4",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1: 3 points\n",
    "\n",
    "# Implement the following function that calculates the cost of a binary classifier\n",
    "# according to the specification in the problem statement.\n",
    "# The function evaluates how expensive a given threshold choice is.\n",
    "def cost(y_true, y_predict_proba, threshold):\n",
    "    # y_true: numpy array of shape (n_samples,)\n",
    "    #         Contains the true binary labels (0 = legitimate, 1 = fraud)\n",
    "    #\n",
    "    # y_predict_proba: numpy array of shape (n_samples,)\n",
    "    #                  Contains predicted probabilities of fraud\n",
    "    #\n",
    "    # threshold: float in [0, 1]\n",
    "    #            Probabilities >= threshold are classified as fraud (1),\n",
    "    #            otherwise as legitimate (0)\n",
    "\n",
    "    # Convert predicted probabilities into binary predictions\n",
    "    # Fraud (1) if probability >= threshold, otherwise legitimate (0)\n",
    "    y_pred = (y_predict_proba >= threshold).astype(int)\n",
    "    \n",
    "    \n",
    "    # Compute confusion matrix components by counting outcomes\n",
    "    # True Positives: fraud correctly detected\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    \n",
    "    # True Negatives: legitimate transactions correctly allowed\n",
    "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    \n",
    "    # False Positives: legitimate transactions incorrectly blocked\n",
    "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    \n",
    "    # False Negatives: fraud that was missed\n",
    "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    \n",
    "    # Compute the total cost according to the problem specification\n",
    "    # TP  -> cost 100\n",
    "    # TN  -> cost 0\n",
    "    # FP  -> cost 120\n",
    "    # FN  -> cost 600\n",
    "    total_cost = (\n",
    "        100 * TP +     # Cost for detecting fraud (manual review, etc.)\n",
    "        0   * TN +     # No cost for correct legitimate transactions\n",
    "        120 * FP +     # Cost for wrongly blocking legitimate users\n",
    "        600 * FN       # High cost for missed fraud\n",
    "    )\n",
    "    \n",
    "    # Compute the average cost per sample\n",
    "    # This makes the cost comparable across datasets of different sizes\n",
    "    avg_cost = total_cost / len(y_true)\n",
    "    \n",
    "    return avg_cost\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot the cost as a function of the threshold\n",
    "# using validation data\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Create thresholds from 0 to 1 (inclusive) with step size 0.01\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# Compute the average cost for each threshold value\n",
    "# using the validation labels and predicted probabilities\n",
    "costs = [\n",
    "    cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, t)\n",
    "    for t in thresholds\n",
    "]\n",
    "\n",
    "# Plot cost vs threshold\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, costs)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Average cost\")\n",
    "plt.title(\"Cost as a function of threshold (validation data)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7590f92",
   "metadata": {},
   "source": [
    "2. [2.5p] Find the threshold that minimizes the cost and calculate the cost at that threshold on the validation data. Also calculate the precision and recall at the optimal threshold on the validation data on class 1 and 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5801de45",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold (min cost): 0.2\n",
      "Validation cost at optimal threshold: 43.15492957746479\n",
      "Class 1 (fraud) precision: 0.7961165048543689\n",
      "Class 1 (fraud) recall: 0.9144981412639405\n",
      "Class 0 (legitimate) precision: 0.9695767195767195\n",
      "Class 0 (legitimate) recall: 0.9208542713567839\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Part 2: Find best threshold (min cost) on validation set\n",
    "# ----------------------------\n",
    "\n",
    "# 1) Define candidate thresholds from 0 to 1 with step size 0.01\n",
    "# These are the thresholds we will evaluate\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# 2) Compute the average cost for each threshold\n",
    "# Uses the cost() function implemented in Part 1\n",
    "costs = np.array([\n",
    "    cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, t)\n",
    "    for t in thresholds\n",
    "])\n",
    "\n",
    "# 3) Find the index of the threshold that minimizes the cost\n",
    "min_idx = np.argmin(costs)\n",
    "\n",
    "# Extract the optimal threshold as a float\n",
    "problem3_threshold = float(thresholds[min_idx])  # Value in [0, 1]\n",
    "\n",
    "# 4) Compute the cost at the optimal threshold on the validation data\n",
    "problem3_cost_val = float(\n",
    "    cost(PROBLEM3_y_true_val, PROBLEM3_y_pred_proba_val, problem3_threshold)\n",
    ")\n",
    "\n",
    "# 5) Generate binary predictions on the validation set\n",
    "# using the optimal threshold\n",
    "problem3_y_pred_val = (PROBLEM3_y_pred_proba_val >= problem3_threshold).astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Precision & Recall for class 1 and class 0\n",
    "# Computed explicitly from confusion-matrix counts\n",
    "# ----------------------------\n",
    "\n",
    "# Compute confusion matrix components\n",
    "TP = np.sum((PROBLEM3_y_true_val == 1) & (problem3_y_pred_val == 1))  # Fraud correctly detected\n",
    "TN = np.sum((PROBLEM3_y_true_val == 0) & (problem3_y_pred_val == 0))  # Legit correctly allowed\n",
    "FP = np.sum((PROBLEM3_y_true_val == 0) & (problem3_y_pred_val == 1))  # Legit incorrectly blocked\n",
    "FN = np.sum((PROBLEM3_y_true_val == 1) & (problem3_y_pred_val == 0))  # Fraud missed\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics for class 1 (fraud)\n",
    "# ----------------------------\n",
    "\n",
    "# Precision: fraction of predicted fraud that is actually fraud\n",
    "problem3_precision_1 = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "\n",
    "# Recall: fraction of actual fraud that is detected\n",
    "problem3_recall_1 = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics for class 0 (legitimate)\n",
    "# ----------------------------\n",
    "\n",
    "# Precision: fraction of predicted legitimate that is actually legitimate\n",
    "problem3_precision_0 = TN / (TN + FN) if (TN + FN) > 0 else 0.0\n",
    "\n",
    "# Recall: fraction of actual legitimate that is correctly allowed\n",
    "problem3_recall_0 = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Print results\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Optimal threshold (min cost):\", problem3_threshold)\n",
    "print(\"Validation cost at optimal threshold:\", problem3_cost_val)\n",
    "\n",
    "print(\"Class 1 (fraud) precision:\", problem3_precision_1)\n",
    "print(\"Class 1 (fraud) recall:\", problem3_recall_1)\n",
    "\n",
    "print(\"Class 0 (legitimate) precision:\", problem3_precision_0)\n",
    "print(\"Class 0 (legitimate) recall:\", problem3_recall_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90123e8e",
   "metadata": {},
   "source": [
    "-----\n",
    "3. [2.5p] Repeat step 2, but this time find the best threshold to minimize the $0-1$ loss. Calculate the difference in cost between the threshold found in part 2 with the one just found in part 3.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9d7fdd",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold (0–1 loss): 0.6900000000000001\n",
      "0–1 loss at optimal threshold: 0.0647887323943662\n",
      "Cost at Part 2 (cost-optimal) threshold: 43.15492957746479\n",
      "Cost at Part 3 (0–1 loss-optimal) threshold: 54.08450704225352\n",
      "Difference in cost (Part 3 − Part 2): 10.929577464788728\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Part 3: Threshold minimizing 0–1 loss (validation set)\n",
    "# ----------------------------\n",
    "\n",
    "# 1) Define candidate thresholds from 0 to 1 with step size 0.01\n",
    "# These thresholds will be evaluated using the 0–1 loss criterion\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "\n",
    "# 2) Compute the 0–1 loss for each threshold\n",
    "# 0–1 loss is defined as the fraction of incorrect predictions:\n",
    "#\n",
    "#   0–1 loss = (1 / n) * sum( I(y_pred != y_true) )\n",
    "#\n",
    "# where I(.) is an indicator that equals 1 if the condition is true\n",
    "# and 0 otherwise.\n",
    "#\n",
    "# In NumPy, the expression (y_pred != y_true) produces a boolean array:\n",
    "#   - True  -> incorrect prediction\n",
    "#   - False -> correct prediction\n",
    "#\n",
    "# When taking the mean, True is treated as 1 and False as 0,\n",
    "# so np.mean(y_pred != y_true) directly computes the fraction\n",
    "# of misclassified samples.\n",
    "losses_01 = []\n",
    "\n",
    "for t in thresholds:\n",
    "    # Convert predicted probabilities to binary predictions\n",
    "    # Fraud (1) if probability >= threshold, otherwise legitimate (0)\n",
    "    y_pred = (PROBLEM3_y_pred_proba_val >= t).astype(int)\n",
    "    \n",
    "    # Compute 0–1 loss as the average number of incorrect predictions\n",
    "    # Using \"!=\" counts mistakes, which is exactly what 0–1 loss measures\n",
    "    loss = np.mean(y_pred != PROBLEM3_y_true_val)\n",
    "    \n",
    "    losses_01.append(loss)\n",
    "\n",
    "# Convert list to NumPy array for easier indexing\n",
    "losses_01 = np.array(losses_01)\n",
    "\n",
    "# 3) Find the threshold that minimizes the 0–1 loss\n",
    "# If multiple thresholds give the same minimum loss,\n",
    "# np.argmin selects the first one\n",
    "min_idx_01 = np.argmin(losses_01)\n",
    "\n",
    "# Extract the optimal threshold as a float\n",
    "problem3_threshold_01 = float(thresholds[min_idx_01])  # Value in [0, 1]\n",
    "\n",
    "# ----------------------------\n",
    "# Cost difference between Part 2 threshold and 0–1 loss threshold\n",
    "# ----------------------------\n",
    "\n",
    "# Cost at the threshold found in Part 2 (cost-minimizing threshold)\n",
    "# Computed on the validation set\n",
    "cost_part2 = cost(\n",
    "    PROBLEM3_y_true_val,\n",
    "    PROBLEM3_y_pred_proba_val,\n",
    "    problem3_threshold\n",
    ")\n",
    "\n",
    "# Cost at the threshold that minimizes 0–1 loss\n",
    "# Also computed on the validation set\n",
    "cost_part3 = cost(\n",
    "    PROBLEM3_y_true_val,\n",
    "    PROBLEM3_y_pred_proba_val,\n",
    "    problem3_threshold_01\n",
    ")\n",
    "\n",
    "# Difference in cost between the two thresholds\n",
    "# This preserves the sign:\n",
    "#   > 0  -> 0–1 loss threshold gives higher cost\n",
    "#   < 0  -> 0–1 loss threshold gives lower cost\n",
    "problem3_cost_difference = float(abs(cost_part3 - cost_part2))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Print results\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Optimal threshold (0–1 loss):\", problem3_threshold_01)\n",
    "print(\"0–1 loss at optimal threshold:\", losses_01[min_idx_01])\n",
    "\n",
    "print(\"Cost at Part 2 (cost-optimal) threshold:\", cost_part2)\n",
    "print(\"Cost at Part 3 (0–1 loss-optimal) threshold:\", cost_part3)\n",
    "\n",
    "print(\"Difference in cost (Part 3 − Part 2):\", problem3_cost_difference)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d388c20",
   "metadata": {},
   "source": [
    "-----\n",
    "4. [4p] Provide a confidence interval around the optimal cost (with $95\\%$ confidence) applied to the test data and explain all the assumption you made.\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec51bb",
   "metadata": {},
   "source": [
    "-----\n",
    "## Part 4: 95% confidence interval for the cost using Hoeffding's inequality\n",
    "\n",
    "We want a $95\\%$ confidence interval for the *expected* (average) cost of the classifier on the test distribution.\n",
    "Let $C_i$ be the random cost for test sample $i$ when we use the fixed threshold $problem3\\_threshold$.\n",
    "We estimate the expected cost by the empirical mean on the test set:\n",
    "$$\n",
    "\\hat{C} = \\frac{1}{n}\\sum_{i=1}^n C_i,\n",
    "$$\n",
    "where $n$ is the number of test samples.\n",
    "\n",
    "We use Hoeffding's inequality, which applies under the assumptions that:\n",
    "\n",
    "1. The test samples (and therefore $C_1,\\dots,C_n$) are independent and identically distributed (i.i.d.).\n",
    "2. The per-sample cost is bounded in an interval $[a,b]$.\n",
    "   In this problem the smallest possible cost is $a=0$ (true negative) and the largest possible cost is $b=600$ (false negative).\n",
    "\n",
    "Hoeffding's inequality states that for any $\\epsilon>0$,\n",
    "$$\n",
    "P(|\\hat{C} - \\mathbb{E}[C]| \\ge \\epsilon) \\le 2\\exp\\left(\\frac{-2n\\epsilon^2}{(b-a)^2}\\right).\n",
    "$$\n",
    "Setting the right-hand side to $\\alpha=0.05$ (for $95\\%$ confidence) and solving for $\\epsilon$ gives\n",
    "$$\n",
    "\\epsilon = (b-a)\\sqrt{\\frac{\\ln(2/\\alpha)}{2n}}.\n",
    "$$\n",
    "Thus a $95\\%$ confidence interval for the expected cost is\n",
    "$$\n",
    "[\\hat{C}-\\epsilon,\\ \\hat{C}+\\epsilon],\n",
    "$$\n",
    "where $\\hat{C}$ is computed from the test data using $problem3\\_threshold$ and $b-a=600$.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3645e321",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cost on test data: 42.70422535211268\n",
      "95% confidence interval for expected cost:\n",
      "[ 17.734792363077773 , 67.67365834114759 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Part 4: 95% confidence interval using Hoeffding's inequality\n",
    "# ----------------------------\n",
    "\n",
    "# Compute the average cost on the test data\n",
    "# using the optimal threshold found on the validation set (Part 2)\n",
    "#\n",
    "# This is the empirical estimate of the expected cost\n",
    "mean_cost_test = cost(\n",
    "    PROBLEM3_y_true_test,\n",
    "    PROBLEM3_y_pred_proba_test,\n",
    "    problem3_threshold\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Parameters for Hoeffding's inequality\n",
    "# ----------------------------\n",
    "\n",
    "# Significance level alpha = 0.05 corresponds to 95% confidence\n",
    "alpha = 0.05\n",
    "\n",
    "# Number of independent test samples\n",
    "n = len(PROBLEM3_y_true_test)\n",
    "\n",
    "# ----------------------------\n",
    "# Cost bounds\n",
    "# ----------------------------\n",
    "\n",
    "# The per-sample cost is bounded:\n",
    "#   Minimum cost = 0   (True Negative)\n",
    "#   Maximum cost = 600 (False Negative)\n",
    "#\n",
    "# Thus, b - a = 600\n",
    "cost_range = 600\n",
    "\n",
    "# ----------------------------\n",
    "# Hoeffding bound\n",
    "# ----------------------------\n",
    "\n",
    "# Hoeffding's inequality gives:\n",
    "#   P(|mean_cost_test - E[C]| >= epsilon) <= 2 * exp(-2n epsilon^2 / (b - a)^2)\n",
    "#\n",
    "# Solving for epsilon with confidence level (1 - alpha) gives:\n",
    "#   epsilon = (b - a) * sqrt( ln(2 / alpha) / (2n) )\n",
    "epsilon = np.sqrt(np.log(2 / alpha) / (2 * n)) * cost_range\n",
    "\n",
    "# ----------------------------\n",
    "# Confidence interval\n",
    "# ----------------------------\n",
    "\n",
    "# 95% confidence interval for the expected cost\n",
    "problem3_lower_bound = mean_cost_test - epsilon\n",
    "problem3_upper_bound = mean_cost_test + epsilon\n",
    "\n",
    "# Might need this for the above code:\n",
    "# problem3_lower_bound = max(0, mean_cost_test - epsilon)\n",
    "# problem3_upper_bound = min(cost_range, mean_cost_test + epsilon)\n",
    "\n",
    "# ----------------------------\n",
    "# Print results\n",
    "# ----------------------------\n",
    "\n",
    "print(\"Mean cost on test data:\", mean_cost_test)\n",
    "print(\"95% confidence interval for expected cost:\")\n",
    "print(\"[\", problem3_lower_bound, \",\", problem3_upper_bound, \"]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660e3fb",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "PROBLEM",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "\n",
    "## Free text answer\n",
    "\n",
    "Put your explanation for part 4 below this line in this **cell**. Doubleclick to enter edit mode as before.\n",
    "\n",
    "\n",
    "I am using the same method for calculating the confidence interval as in Problem 1.\n",
    "I created a new function to get the cost as an array, instead of just the average. This allowed me to ge the highest and lowest values.\n",
    "I then continued using the same method as in Problem 1 to get the confidence interval of 95%. I assumed the estimate to be the average cost for that threshold. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7044e1d",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "source": [
    "---\n",
    "#### Local Test for Exam vB, PROBLEM 3\n",
    "Evaluate cell below to make sure your answer is valid.                             You **should not** modify anything in the cell below when evaluating it to do a local test of                             your solution.\n",
    "You may need to include and evaluate code snippets from lecture notebooks in cells above to make the local test work correctly sometimes (see error messages for clues). This is meant to help you become efficient at recalling materials covered in lectures that relate to this problem. Such local tests will generally not be available in the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ed08c8",
   "metadata": {
    "deletable": false,
    "lx_assignment_number": "vB",
    "lx_assignment_type": "EXAM",
    "lx_assignment_type2print": "Exam",
    "lx_problem_cell_type": "Test",
    "lx_problem_number": "3",
    "lx_problem_points": "12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your cost is a function\n",
      "Good, your PROBLEM3_y_pred_proba_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\n",
      "Good, your PROBLEM3_y_true_val is a numpy array of shape (len(PROBLEM3_y_pred_proba_val),)\n",
      "Good, your PROBLEM3_y_pred_proba_test is a numpy array of shape (len(PROBLEM3_y_true_test),)\n",
      "Good, your PROBLEM3_y_true_test is a numpy array of shape (len(PROBLEM3_y_pred_proba_test),)\n",
      "Good, your cost function returns a float\n",
      "Good, your cost function returns the correct value for the test case\n",
      "Good, your problem3_threshold is a float between 0 and 1\n",
      "Good, your problem3_cost_val is a float that is non-negative\n",
      "Good, your problem3_y_pred_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\n",
      "Good, your problem3_y_pred_val contains only 0s and 1s\n",
      "Good, your problem3_precision_1 is a float between 0 and 1\n",
      "Good, your problem3_recall_1 is a float between 0 and 1\n",
      "Good, your problem3_precision_0 is a float between 0 and 1\n",
      "Good, your problem3_recall_0 is a float between 0 and 1\n",
      "Good, your problem3_threshold_01 is a float between 0 and 1\n",
      "Good, your problem3_cost_difference is a float that is non-negative\n",
      "Good, your problem3_lower_bound is a float that is non-negative\n",
      "Good, your problem3_upper_bound is a float that is non-negative\n"
     ]
    }
   ],
   "source": [
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert callable(cost), \"cost is not a function\"\n",
    "except:\n",
    "    print(\"Try again. your cost is not a function\")\n",
    "else:\n",
    "    print(\"Good, your cost is a function\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_pred_proba_val, np.ndarray), \"PROBLEM3_y_pred_proba_val is not a numpy array\"\n",
    "    assert PROBLEM3_y_pred_proba_val.shape == (len(PROBLEM3_y_true_val),), \"PROBLEM3_y_pred_proba_val does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_pred_proba_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_true_val, np.ndarray), \"PROBLEM3_y_true_val is not a numpy array\"\n",
    "    assert PROBLEM3_y_true_val.shape == (len(PROBLEM3_y_pred_proba_val),), \"PROBLEM3_y_true_val does not have the correct shape\"\n",
    "except Exception as e: \n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_true_val is a numpy array of shape (len(PROBLEM3_y_pred_proba_val),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_pred_proba_test, np.ndarray), \"PROBLEM3_y_pred_proba_test is not a numpy array\"\n",
    "    assert PROBLEM3_y_pred_proba_test.shape == (len(PROBLEM3_y_true_test),), \"PROBLEM3_y_pred_proba_test does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_pred_proba_test is a numpy array of shape (len(PROBLEM3_y_true_test),)\")\n",
    "try:\n",
    "    assert isinstance(PROBLEM3_y_true_test, np.ndarray), \"PROBLEM3_y_true_test is not a numpy array\"\n",
    "    assert PROBLEM3_y_true_test.shape == (len(PROBLEM3_y_pred_proba_test),), \"PROBLEM3_y_true_test does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your PROBLEM3_y_true_test is a numpy array of shape (len(PROBLEM3_y_pred_proba_test),)\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(cost(np.array([1,1,0,0]),np.array([0.9,0.8,0.1,0.2]),0.5), float), \"cost does not return a float\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your cost function returns a float\")\n",
    "try:\n",
    "    assert cost(np.array([1,1,0,0]),np.array([0.9,0.8,0.1,0.2]),0.5) == 50.0, \"cost does not return the correct value for the test case\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your cost function returns the correct value for the test case\")\n",
    "\n",
    "try:\n",
    "    assert isinstance(problem3_threshold, float), \"problem3_threshold is not a float\"\n",
    "    assert 0 <= problem3_threshold <= 1, \"problem3_threshold is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_threshold is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_cost_val, float), \"problem3_cost_val is not a float\"\n",
    "    assert problem3_cost_val >= 0, \"problem3_cost_val is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_cost_val is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_y_pred_val, np.ndarray), \"problem3_y_pred_val is not a numpy array\"\n",
    "    assert problem3_y_pred_val.shape == (len(PROBLEM3_y_true_val),), \"problem3_y_pred_val does not have the correct shape\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_y_pred_val is a numpy array of shape (len(PROBLEM3_y_true_val),)\")\n",
    "try:\n",
    "    assert np.all(np.isin(problem3_y_pred_val, [0, 1])), \"problem3_y_pred_val does not contain only 0s and 1s\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_y_pred_val contains only 0s and 1s\")\n",
    "try:\n",
    "    assert isinstance(problem3_precision_1, float), \"problem3_precision_1 is not a float\"\n",
    "    assert 0 <= problem3_precision_1 <= 1, \"problem3_precision_1 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_precision_1 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_recall_1, float), \"problem3_recall_1 is not a float\"\n",
    "    assert 0 <= problem3_recall_1 <= 1, \"problem3_recall_1 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_recall_1 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_precision_0, float), \"problem3_precision_0 is not a float\"\n",
    "    assert 0 <= problem3_precision_0 <= 1, \"problem3_precision_0 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_precision_0 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_recall_0, float), \"problem3_recall_0 is not a float\"\n",
    "    assert 0 <= problem3_recall_0 <= 1, \"problem3_recall_0 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_recall_0 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_threshold_01, float), \"problem3_threshold_01 is not a float\"\n",
    "    assert 0 <= problem3_threshold_01 <= 1, \"problem3_threshold_01 is not between 0 and 1\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_threshold_01 is a float between 0 and 1\")\n",
    "try:\n",
    "    assert isinstance(problem3_cost_difference, float), \"problem3_cost_difference is not a float\"\n",
    "    assert problem3_cost_difference >= 0, \"problem3_cost_difference is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_cost_difference is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_lower_bound, float), \"problem3_lower_bound is not a float\"\n",
    "    assert problem3_lower_bound >= 0, \"problem3_lower_bound is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_lower_bound is a float that is non-negative\")\n",
    "try:\n",
    "    assert isinstance(problem3_upper_bound, float), \"problem3_upper_bound is not a float\"\n",
    "    assert problem3_upper_bound >= 0, \"problem3_upper_bound is not non-negative\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem3_upper_bound is a float that is non-negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "lx_assignment_number": "vB",
  "lx_course_instance": "2024",
  "lx_course_name": "Introduction to Data Science",
  "lx_course_number": "1MS041"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
